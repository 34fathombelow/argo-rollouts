{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Argo Rollouts - Kubernetes Progressive Delivery Controller \u00b6 What is Argo Rollouts? \u00b6 Argo Rollouts is a Kubernetes controller and set of CRDs which provide advanced deployment capabilities such as blue-green, canary, canary analysis, experimentation, and progressive delivery features to Kubernetes. Argo Rollouts (optionally) integrates with ingress controllers and service meshes, leveraging their traffic shaping abilities to gradually shift traffic to the new version during an update. Additionally, Rollouts can query and interpret metrics from various providers to verify key KPIs and drive automated promotion or rollback during an update. Why Argo Rollouts? \u00b6 Kubernetes Deployments provides the RollingUpdate strategy which provide a basic set of safety guarantees (readiness probes) during an update. However the rolling update strategy faces many limitations: Few controls over the speed of the rollout Inability to control traffic flow to the new version Readiness probes are unsuitable for deeper, stress, or one-time checks No ability to query external metrics to verify an update Can halt the progression, but unable to automatically abort and rollback the update For these reasons, in large scale high-volume production environments, a rolling update is often considered too risky of an update procedure since it provides no control over the blast radius, may rollout too aggressively, and provides no automated rollback upon failures. Features \u00b6 Blue-Green (aka red-black) update strategy Canary update strategy Fine-grained, weighted traffic shifting Automated rollbacks and promotions Manual judgement Customizable metric queries and analysis of business KPIs Ingress controller integration: NGINX, ALB Service Mesh integration: Istio, Linkerd, SMI Metric provider integration: Prometheus, Wavefront, Kayenta, Web, Kubernetes Jobs Quick Start \u00b6 kubectl create namespace argo-rollouts kubectl apply -n argo-rollouts -f https://raw.githubusercontent.com/argoproj/argo-rollouts/stable/manifests/install.yaml Follow the full getting started guide to walk through creating and then updating a rollout object. How does it work? \u00b6 Similar to the deployment object, the Argo Rollouts controller will manage the creation, scaling, and deletion of ReplicaSets. These ReplicaSets are defined by the spec.template field, which uses the same pod template as the deployment object. When the spec.template is changed, that signals to the Argo Rollouts controller that a new ReplicaSet will be introduced. The controller will use the strategy set within the spec.strategy field in order to determine how the rollout will progress from the old ReplicaSet to the new ReplicaSet. Once that new ReplicaSet has successfully progressed into the stable version, that Rollout will be marked as the stable ReplicaSet. If another change occurs in the spec.template during a transition from a stable ReplicaSet to a new ReplicaSet. The previously new ReplicaSet will be scaled down, and the controller will try to progress the ReplicasSet that reflects the spec.template field. There is more information on the behaviors of each strategy in the spec section. Use cases of Argo Rollouts \u00b6 A user wants to run last minute functional tests on the new version before it starts to serve production traffic. With the BlueGreen strategy, Argo Rollouts allow users to specify a preview service and an active service. The Rollout will configure the preview service to send traffic to the new version while the active service continues to receive production traffic. Once a user is satisfied, they can promote the preview service to be the new active service. ( example ) Before a new version starts receiving live traffic, a generic set of steps need to be executed beforehand. With the BlueGreen Strategy, the user can bring up the new version without it receiving traffic from the active service. Once those steps finish executing, the rollout can cut over traffic to the new version. A user wants to give a small percentage of the production traffic to a new version of their application for a couple of hours. Afterward, they want to scale down the new version and look at some metrics to determine if the new version is performant compared to the old version. Then they will decide if they want to rollout the new version for all of the production traffic or stick with the current version. With the canary strategy, the rollout can scale up a replica with the new version to receive a specified percentage of traffic, wait for a specified amount of time, set the percentage back to 0, and then wait to rollout out to service all of the traffic once the user is satisfied. ( example ) A user wants to slowly give the new version more production traffic. They start by giving it a small percentage of the live traffic and wait a while before giving the new version more traffic. Eventually, the new version will receive all the production traffic. With the canary strategy, the user specifies the percentages they want the new version to receive and the amount of time to wait between percentages. ( example ) A user wants to use the normal Rolling Update strategy from the deployment. If a user uses the canary strategy with no steps, the rollout will use the max surge and max unavailable values to roll to the new version. ( example )","title":"Overview"},{"location":"#argo-rollouts-kubernetes-progressive-delivery-controller","text":"","title":"Argo Rollouts - Kubernetes Progressive Delivery Controller"},{"location":"#what-is-argo-rollouts","text":"Argo Rollouts is a Kubernetes controller and set of CRDs which provide advanced deployment capabilities such as blue-green, canary, canary analysis, experimentation, and progressive delivery features to Kubernetes. Argo Rollouts (optionally) integrates with ingress controllers and service meshes, leveraging their traffic shaping abilities to gradually shift traffic to the new version during an update. Additionally, Rollouts can query and interpret metrics from various providers to verify key KPIs and drive automated promotion or rollback during an update.","title":"What is Argo Rollouts?"},{"location":"#why-argo-rollouts","text":"Kubernetes Deployments provides the RollingUpdate strategy which provide a basic set of safety guarantees (readiness probes) during an update. However the rolling update strategy faces many limitations: Few controls over the speed of the rollout Inability to control traffic flow to the new version Readiness probes are unsuitable for deeper, stress, or one-time checks No ability to query external metrics to verify an update Can halt the progression, but unable to automatically abort and rollback the update For these reasons, in large scale high-volume production environments, a rolling update is often considered too risky of an update procedure since it provides no control over the blast radius, may rollout too aggressively, and provides no automated rollback upon failures.","title":"Why Argo Rollouts?"},{"location":"#features","text":"Blue-Green (aka red-black) update strategy Canary update strategy Fine-grained, weighted traffic shifting Automated rollbacks and promotions Manual judgement Customizable metric queries and analysis of business KPIs Ingress controller integration: NGINX, ALB Service Mesh integration: Istio, Linkerd, SMI Metric provider integration: Prometheus, Wavefront, Kayenta, Web, Kubernetes Jobs","title":"Features"},{"location":"#quick-start","text":"kubectl create namespace argo-rollouts kubectl apply -n argo-rollouts -f https://raw.githubusercontent.com/argoproj/argo-rollouts/stable/manifests/install.yaml Follow the full getting started guide to walk through creating and then updating a rollout object.","title":"Quick Start"},{"location":"#how-does-it-work","text":"Similar to the deployment object, the Argo Rollouts controller will manage the creation, scaling, and deletion of ReplicaSets. These ReplicaSets are defined by the spec.template field, which uses the same pod template as the deployment object. When the spec.template is changed, that signals to the Argo Rollouts controller that a new ReplicaSet will be introduced. The controller will use the strategy set within the spec.strategy field in order to determine how the rollout will progress from the old ReplicaSet to the new ReplicaSet. Once that new ReplicaSet has successfully progressed into the stable version, that Rollout will be marked as the stable ReplicaSet. If another change occurs in the spec.template during a transition from a stable ReplicaSet to a new ReplicaSet. The previously new ReplicaSet will be scaled down, and the controller will try to progress the ReplicasSet that reflects the spec.template field. There is more information on the behaviors of each strategy in the spec section.","title":"How does it work?"},{"location":"#use-cases-of-argo-rollouts","text":"A user wants to run last minute functional tests on the new version before it starts to serve production traffic. With the BlueGreen strategy, Argo Rollouts allow users to specify a preview service and an active service. The Rollout will configure the preview service to send traffic to the new version while the active service continues to receive production traffic. Once a user is satisfied, they can promote the preview service to be the new active service. ( example ) Before a new version starts receiving live traffic, a generic set of steps need to be executed beforehand. With the BlueGreen Strategy, the user can bring up the new version without it receiving traffic from the active service. Once those steps finish executing, the rollout can cut over traffic to the new version. A user wants to give a small percentage of the production traffic to a new version of their application for a couple of hours. Afterward, they want to scale down the new version and look at some metrics to determine if the new version is performant compared to the old version. Then they will decide if they want to rollout the new version for all of the production traffic or stick with the current version. With the canary strategy, the rollout can scale up a replica with the new version to receive a specified percentage of traffic, wait for a specified amount of time, set the percentage back to 0, and then wait to rollout out to service all of the traffic once the user is satisfied. ( example ) A user wants to slowly give the new version more production traffic. They start by giving it a small percentage of the live traffic and wait a while before giving the new version more traffic. Eventually, the new version will receive all the production traffic. With the canary strategy, the user specifies the percentages they want the new version to receive and the amount of time to wait between percentages. ( example ) A user wants to use the normal Rolling Update strategy from the deployment. If a user uses the canary strategy with no steps, the rollout will use the max surge and max unavailable values to roll to the new version. ( example )","title":"Use cases of Argo Rollouts"},{"location":"CONTRIBUTING/","text":"Contributing \u00b6 Before You Start \u00b6 Argo Rollouts is written in Golang. If you do not have a good grounding in Go, try out the tutorial . Pre-requisites \u00b6 Install: docker golang kubectl kustomize minikube or Docker for Desktop Argo Rollout additionally uses golangci-lint to lint the project. Run the following commands to install them: # macOS brew install golangci-lint # linux go get -u github.com/golangci/golangci-lint/cmd/golangci-lint Brew users can quickly install the lot: brew install go kubectl kustomize Set up environment variables (e.g. is ~/.bashrc ): export GOPATH = ~/go export PATH = $PATH : $GOPATH /bin Checkout the code: go get -u github.com/argoproj/argo-rollouts cd ~/go/src/github.com/argoproj/argo-rollouts Run the following command to download all the dependencies: go mod download Building \u00b6 go.mod is used, so the go build/test commands automatically install the needed dependencies The make controller command will build the controller. make codegen - Runs the code generator that creates the informers, client, lister, and deepcopies from the types.go and modifies the open-api spec. This command fails if the user has not run go mod download to download all the dependencies of the project. Running Unit Tests \u00b6 To run unit tests: make test Running E2E tests \u00b6 The end-to-end tests need to run against a kubernetes cluster with the Argo Rollouts controller running. The rollout controller can be started with the command: make start-e2e Then run the e2e tests: make test-e2e Tips \u00b6 You can run the tests using a different kubeconfig by setting the KUBECONFIG environment variable: KUBECONFIG = ~/.kube/minikube make start-e2e KUBECONFIG = ~/.kube/minikube make test-e2e To run a specific e2e test, set the E2E_TEST_OPTIONS environment variable to specify the test (or test regex): make test-e2e E2E_TEST_OPTIONS = \"-testify.m ^TestRolloutRestart $ \" The e2e tests are designed to run as quickly as possible, eliminating readiness and termination delays. However, it is often desired to artificially slow down the tests for debugging purposes, as well as to understand what the test is doing. To delay startup and termination of pods, set the E2E_POD_DELAY to a integer value in seconds. This environment variable is often coupled with E2E_TEST_OPTIONS to debug and slow down a specific test. make test-e2e E2E_POD_DELAY = 10 The e2e tests leverage a feature of the controller allowing the controller to be sharded with a user-specific \"instance id\" label. This allows the tests to operate only on rollouts with the specified label, and prevents any other controllers (including the system rollouts controller), from also operating on the same set of rollouts. This value can be changed (from the default of argo-rollouts-e2e ), using the E2E_INSTANCE_ID environment variable: make start-e2e E2E_INSTANCE_ID = foo make test-e2e E2E_INSTANCE_ID = foo Running Locally \u00b6 It is much easier to run and debug if you run Argo Rollout in your local machine than in the Kubernetes cluster. cd ~/go/src/github.com/argoproj/argo-rollouts go run ./cmd/rollouts-controller/main.go Running Local Containers \u00b6 You may need to run containers locally, so here's how: Create login to Docker Hub, then login. docker login Add your username as the environment variable, e.g. to your ~/.bash_profile : export IMAGE_NAMESPACE = argoproj Build the images: DOCKER_PUSH = true make image Update the manifests: make manifests Install the manifests: kubectl -n argo-rollouts apply -f manifests/install.yaml Upgrading Kubernetes Libraries \u00b6 Argo Rollouts has a dependency on the kubernetes/kubernetes repo for some of the functionality that has not been pushed into the other kubernetes repositories yet. In order to import the kubernetes/kubernetes repo, all of the associated repos have to pinned to the correct version specified by the kubernetes/kubernetes release. The ./hack/update-k8s-dependencies.sh updates all the dependencies to the those correct versions. Documentation Changes \u00b6 Modify contents in docs/ directory. Preview changes in your browser by visiting http://localhost:8000 after running: make serve-docs To publish changes, run: make release-docs","title":"Contribution Guide"},{"location":"CONTRIBUTING/#contributing","text":"","title":"Contributing"},{"location":"CONTRIBUTING/#before-you-start","text":"Argo Rollouts is written in Golang. If you do not have a good grounding in Go, try out the tutorial .","title":"Before You Start"},{"location":"CONTRIBUTING/#pre-requisites","text":"Install: docker golang kubectl kustomize minikube or Docker for Desktop Argo Rollout additionally uses golangci-lint to lint the project. Run the following commands to install them: # macOS brew install golangci-lint # linux go get -u github.com/golangci/golangci-lint/cmd/golangci-lint Brew users can quickly install the lot: brew install go kubectl kustomize Set up environment variables (e.g. is ~/.bashrc ): export GOPATH = ~/go export PATH = $PATH : $GOPATH /bin Checkout the code: go get -u github.com/argoproj/argo-rollouts cd ~/go/src/github.com/argoproj/argo-rollouts Run the following command to download all the dependencies: go mod download","title":"Pre-requisites"},{"location":"CONTRIBUTING/#building","text":"go.mod is used, so the go build/test commands automatically install the needed dependencies The make controller command will build the controller. make codegen - Runs the code generator that creates the informers, client, lister, and deepcopies from the types.go and modifies the open-api spec. This command fails if the user has not run go mod download to download all the dependencies of the project.","title":"Building"},{"location":"CONTRIBUTING/#running-unit-tests","text":"To run unit tests: make test","title":"Running Unit Tests"},{"location":"CONTRIBUTING/#running-e2e-tests","text":"The end-to-end tests need to run against a kubernetes cluster with the Argo Rollouts controller running. The rollout controller can be started with the command: make start-e2e Then run the e2e tests: make test-e2e","title":"Running E2E tests"},{"location":"CONTRIBUTING/#tips","text":"You can run the tests using a different kubeconfig by setting the KUBECONFIG environment variable: KUBECONFIG = ~/.kube/minikube make start-e2e KUBECONFIG = ~/.kube/minikube make test-e2e To run a specific e2e test, set the E2E_TEST_OPTIONS environment variable to specify the test (or test regex): make test-e2e E2E_TEST_OPTIONS = \"-testify.m ^TestRolloutRestart $ \" The e2e tests are designed to run as quickly as possible, eliminating readiness and termination delays. However, it is often desired to artificially slow down the tests for debugging purposes, as well as to understand what the test is doing. To delay startup and termination of pods, set the E2E_POD_DELAY to a integer value in seconds. This environment variable is often coupled with E2E_TEST_OPTIONS to debug and slow down a specific test. make test-e2e E2E_POD_DELAY = 10 The e2e tests leverage a feature of the controller allowing the controller to be sharded with a user-specific \"instance id\" label. This allows the tests to operate only on rollouts with the specified label, and prevents any other controllers (including the system rollouts controller), from also operating on the same set of rollouts. This value can be changed (from the default of argo-rollouts-e2e ), using the E2E_INSTANCE_ID environment variable: make start-e2e E2E_INSTANCE_ID = foo make test-e2e E2E_INSTANCE_ID = foo","title":"Tips"},{"location":"CONTRIBUTING/#running-locally","text":"It is much easier to run and debug if you run Argo Rollout in your local machine than in the Kubernetes cluster. cd ~/go/src/github.com/argoproj/argo-rollouts go run ./cmd/rollouts-controller/main.go","title":"Running Locally"},{"location":"CONTRIBUTING/#running-local-containers","text":"You may need to run containers locally, so here's how: Create login to Docker Hub, then login. docker login Add your username as the environment variable, e.g. to your ~/.bash_profile : export IMAGE_NAMESPACE = argoproj Build the images: DOCKER_PUSH = true make image Update the manifests: make manifests Install the manifests: kubectl -n argo-rollouts apply -f manifests/install.yaml","title":"Running Local Containers"},{"location":"CONTRIBUTING/#upgrading-kubernetes-libraries","text":"Argo Rollouts has a dependency on the kubernetes/kubernetes repo for some of the functionality that has not been pushed into the other kubernetes repositories yet. In order to import the kubernetes/kubernetes repo, all of the associated repos have to pinned to the correct version specified by the kubernetes/kubernetes release. The ./hack/update-k8s-dependencies.sh updates all the dependencies to the those correct versions.","title":"Upgrading Kubernetes Libraries"},{"location":"CONTRIBUTING/#documentation-changes","text":"Modify contents in docs/ directory. Preview changes in your browser by visiting http://localhost:8000 after running: make serve-docs To publish changes, run: make release-docs","title":"Documentation Changes"},{"location":"FAQ/","text":"FAQ \u00b6 General \u00b6 How does Argo Rollouts integrate with Argo CD? \u00b6 Argo CD understands the health of Argo Rollouts resources via Argo CD\u2019s Lua health check . These Health checks understand when the Argo Rollout objects are Progressing, Suspended, Degraded, or Healthy. Additionally, Argo CD has Lua based Resource Actions that can mutate an Argo Rollouts resource (i.e. unpause a Rollout). As a result, an operator can build automation to react to the states of the Argo Rollouts resources. For example, if a Rollout created by Argo CD is paused, Argo CD detects that and marks the Application as suspended. Once the new version is verified to be good, the operator can use Argo CD\u2019s resume resource action to unpause the Rollout so it can continue to make progress. Can we run the Argo Rollouts kubectl plugin commands via Argo CD? \u00b6 Argo CD supports running Lua scripts to modify resource kinds (i.e. suspending a CronJob by setting the .spec.suspend to true). These Lua Scripts can be configured in the argocd-cm ConfigMap or upstreamed to the Argo CD's resource_customizations directory. These custom actions have two Lua scripts: one to modify the said resource and another to detect if the action can be executed (i.e. A user should not be able to resuming a unpaused Rollout). Argo CD allows users to execute these actions via the UI or CLI. In the CLI, a user (or a CI system) can run argocd app actions run <APP_NAME> <ACTION> This command executes the action listed on the application listed. In the UI, a user can click the hamburger button of a resource and the available actions will appear in a couple of seconds. The user can click and confirm that action to execute it. Currently, the Rollout action has two available custom actions in Argo CD: resume and restart. * Resume unpauses a Rollout with a PauseCondition * Restart: Sets the RestartAt and causes all the pods to be restarted. Does Argo Rollout require a Service Mesh like Istio? \u00b6 Argo Rollouts does not require a service mesh or ingress controller to be used. In the absence of a traffic routing provider, Argo Rollouts manages the replica counts of the canary/stable ReplicaSets to achieve the desired canary weights. Normal Kubernetes Service routing (via kube-proxy) is used to split traffic between the ReplicaSets. Rollouts \u00b6 Which deployment strategies does Argo Rollouts support? \u00b6 Argo Rollouts supports BlueGreen, Canary, and Rolling Update. Additionally, Progressive Delivery features can be enabled on top of the blue-green/canary update, which further provides advanced deployment such as automated analysis and rollback. Does the Rollout object follow the provided strategy when it is first created? \u00b6 As with Deployments, Rollouts does not follow the strategy parameters on the initial deploy. The controller tries to get the Rollout into a steady state as fast as possible. The controller tries to get the Rollout into a steady state as fast as possible by creating a fully scaled up ReplicaSet from the provided .spec.template . Once the Rollout has a stable ReplicaSet to transition from, the controller starts using the provided strategy to transition the previous ReplicaSet to the desired ReplicaSet. How does BlueGreen rollback work? \u00b6 A BlueGreen Rollout keeps the old ReplicaSet up and running for 30 seconds or the value of the scaleDownDelaySeconds. The controller tracks the remaining time before scaling down by adding an annotation called argo-rollouts.argoproj.io/scale-down-deadline to the old ReplicaSet. If the user applies the old Rollout manifest before the old ReplicaSet before it scales down, the controller does something called a fast rollback. The controller immediately switches the active service\u2019s selector back to the old ReplicaSet\u2019s rollout-pod-template-hash and removes the scaled down annotation from that ReplicaSet. The controller does not do any of the normal operations when trying to introduce a new version since it is trying to revert as fast as possible. A non-fast-track rollback occurs when the scale down annotation has past and the old ReplicaSet has been scaled down. In this case, the Rollout treats the ReplicaSet like any other new ReplicaSet and follows the usual procedure for deploying a new ReplicaSet. What is the argo-rollouts.argoproj.io/managed-by-rollouts annotation? \u00b6 Argo Rollouts adds an argo-rollouts.argoproj.io/managed-by-rollouts annotation to Services and Ingresses that the controller modifies. They are used when the Rollout managing these resources is deleted and the controller tries to revert them back into their previous state. Experiments \u00b6 Why doesn't my Experiment end? \u00b6 An Experiment\u2019s duration is controlled by the .spec.duration field and the analyses created for the Experiment. The .spec.duration indicates how long the ReplicaSets created by the Experiment should run. Once the duration passes, the experiment scales down the ReplicaSets it created and marks the AnalysisRuns successful unless the requiredForCompletion field is used in the Experiment. If enabled, the ReplicaSets are still scaled-down, but the Experiment does not finish until the Analysis Run finishes. Additionally, the .spec.duration is an optional field. If it\u2019s left unset, and the Experiment creates no AnalysisRuns, the ReplicaSets run indefinitely. The Experiment creates AnalysisRuns without the requiredForCompletion field, the Experiment fails only when the AnalysisRun created fails or errors out. If the requiredForCompletion field is set, the Experiment only marks itself as Successful and scales down the created ReplicaSets when the AnalysisRun finishes Successfully. Additionally, an Experiment ends if the .spec.terminate field is set to true regardless of the state of the Experiment. Analysis \u00b6 Why doesn't my AnalysisRun end? \u00b6 The AnalysisRun\u2019s duration is controlled by the metrics specified. Each Metric can specify an interval, count, and various limits (ConsecutiveErrorLimit, InconclusiveLimit, FailureLimit). If the interval is omitted, the AnalysisRun takes a single measurement. The count indicates how many measurements should be taken and causes the AnalysisRun to run indefinitely if omitted. The ConsecutiveErrorLimit, InconclusiveLimit, and FailureLimit define the thresholds allowed before putting the rollout into a completed state. Additionally, an AnalysisRun ends if the .spec.terminate field is set to true regardless of the state of the AnalysisRun. What is the difference between failures and errors? \u00b6 Failures are when the failure condition evaluates to true or an AnalysisRun without a failure condition evaluates the success condition to false. Errors are when the controller has any kind of issue with taking a measurement (i.e. invalid Prometheus URL).","title":"FAQ"},{"location":"FAQ/#faq","text":"","title":"FAQ"},{"location":"FAQ/#general","text":"","title":"General"},{"location":"FAQ/#how-does-argo-rollouts-integrate-with-argo-cd","text":"Argo CD understands the health of Argo Rollouts resources via Argo CD\u2019s Lua health check . These Health checks understand when the Argo Rollout objects are Progressing, Suspended, Degraded, or Healthy. Additionally, Argo CD has Lua based Resource Actions that can mutate an Argo Rollouts resource (i.e. unpause a Rollout). As a result, an operator can build automation to react to the states of the Argo Rollouts resources. For example, if a Rollout created by Argo CD is paused, Argo CD detects that and marks the Application as suspended. Once the new version is verified to be good, the operator can use Argo CD\u2019s resume resource action to unpause the Rollout so it can continue to make progress.","title":"How does Argo Rollouts integrate with Argo CD?"},{"location":"FAQ/#can-we-run-the-argo-rollouts-kubectl-plugin-commands-via-argo-cd","text":"Argo CD supports running Lua scripts to modify resource kinds (i.e. suspending a CronJob by setting the .spec.suspend to true). These Lua Scripts can be configured in the argocd-cm ConfigMap or upstreamed to the Argo CD's resource_customizations directory. These custom actions have two Lua scripts: one to modify the said resource and another to detect if the action can be executed (i.e. A user should not be able to resuming a unpaused Rollout). Argo CD allows users to execute these actions via the UI or CLI. In the CLI, a user (or a CI system) can run argocd app actions run <APP_NAME> <ACTION> This command executes the action listed on the application listed. In the UI, a user can click the hamburger button of a resource and the available actions will appear in a couple of seconds. The user can click and confirm that action to execute it. Currently, the Rollout action has two available custom actions in Argo CD: resume and restart. * Resume unpauses a Rollout with a PauseCondition * Restart: Sets the RestartAt and causes all the pods to be restarted.","title":"Can we run the Argo Rollouts kubectl plugin commands via Argo CD?"},{"location":"FAQ/#does-argo-rollout-require-a-service-mesh-like-istio","text":"Argo Rollouts does not require a service mesh or ingress controller to be used. In the absence of a traffic routing provider, Argo Rollouts manages the replica counts of the canary/stable ReplicaSets to achieve the desired canary weights. Normal Kubernetes Service routing (via kube-proxy) is used to split traffic between the ReplicaSets.","title":"Does Argo Rollout require a Service Mesh like Istio?"},{"location":"FAQ/#rollouts","text":"","title":"Rollouts"},{"location":"FAQ/#which-deployment-strategies-does-argo-rollouts-support","text":"Argo Rollouts supports BlueGreen, Canary, and Rolling Update. Additionally, Progressive Delivery features can be enabled on top of the blue-green/canary update, which further provides advanced deployment such as automated analysis and rollback.","title":"Which deployment strategies does Argo Rollouts support?"},{"location":"FAQ/#does-the-rollout-object-follow-the-provided-strategy-when-it-is-first-created","text":"As with Deployments, Rollouts does not follow the strategy parameters on the initial deploy. The controller tries to get the Rollout into a steady state as fast as possible. The controller tries to get the Rollout into a steady state as fast as possible by creating a fully scaled up ReplicaSet from the provided .spec.template . Once the Rollout has a stable ReplicaSet to transition from, the controller starts using the provided strategy to transition the previous ReplicaSet to the desired ReplicaSet.","title":"Does the Rollout object follow the provided strategy when it is first created?"},{"location":"FAQ/#how-does-bluegreen-rollback-work","text":"A BlueGreen Rollout keeps the old ReplicaSet up and running for 30 seconds or the value of the scaleDownDelaySeconds. The controller tracks the remaining time before scaling down by adding an annotation called argo-rollouts.argoproj.io/scale-down-deadline to the old ReplicaSet. If the user applies the old Rollout manifest before the old ReplicaSet before it scales down, the controller does something called a fast rollback. The controller immediately switches the active service\u2019s selector back to the old ReplicaSet\u2019s rollout-pod-template-hash and removes the scaled down annotation from that ReplicaSet. The controller does not do any of the normal operations when trying to introduce a new version since it is trying to revert as fast as possible. A non-fast-track rollback occurs when the scale down annotation has past and the old ReplicaSet has been scaled down. In this case, the Rollout treats the ReplicaSet like any other new ReplicaSet and follows the usual procedure for deploying a new ReplicaSet.","title":"How does BlueGreen rollback work?"},{"location":"FAQ/#what-is-the-argo-rolloutsargoprojiomanaged-by-rollouts-annotation","text":"Argo Rollouts adds an argo-rollouts.argoproj.io/managed-by-rollouts annotation to Services and Ingresses that the controller modifies. They are used when the Rollout managing these resources is deleted and the controller tries to revert them back into their previous state.","title":"What is the argo-rollouts.argoproj.io/managed-by-rollouts annotation?"},{"location":"FAQ/#experiments","text":"","title":"Experiments"},{"location":"FAQ/#why-doesnt-my-experiment-end","text":"An Experiment\u2019s duration is controlled by the .spec.duration field and the analyses created for the Experiment. The .spec.duration indicates how long the ReplicaSets created by the Experiment should run. Once the duration passes, the experiment scales down the ReplicaSets it created and marks the AnalysisRuns successful unless the requiredForCompletion field is used in the Experiment. If enabled, the ReplicaSets are still scaled-down, but the Experiment does not finish until the Analysis Run finishes. Additionally, the .spec.duration is an optional field. If it\u2019s left unset, and the Experiment creates no AnalysisRuns, the ReplicaSets run indefinitely. The Experiment creates AnalysisRuns without the requiredForCompletion field, the Experiment fails only when the AnalysisRun created fails or errors out. If the requiredForCompletion field is set, the Experiment only marks itself as Successful and scales down the created ReplicaSets when the AnalysisRun finishes Successfully. Additionally, an Experiment ends if the .spec.terminate field is set to true regardless of the state of the Experiment.","title":"Why doesn't my Experiment end?"},{"location":"FAQ/#analysis","text":"","title":"Analysis"},{"location":"FAQ/#why-doesnt-my-analysisrun-end","text":"The AnalysisRun\u2019s duration is controlled by the metrics specified. Each Metric can specify an interval, count, and various limits (ConsecutiveErrorLimit, InconclusiveLimit, FailureLimit). If the interval is omitted, the AnalysisRun takes a single measurement. The count indicates how many measurements should be taken and causes the AnalysisRun to run indefinitely if omitted. The ConsecutiveErrorLimit, InconclusiveLimit, and FailureLimit define the thresholds allowed before putting the rollout into a completed state. Additionally, an AnalysisRun ends if the .spec.terminate field is set to true regardless of the state of the AnalysisRun.","title":"Why doesn't my AnalysisRun end?"},{"location":"FAQ/#what-is-the-difference-between-failures-and-errors","text":"Failures are when the failure condition evaluates to true or an AnalysisRun without a failure condition evaluates the success condition to false. Errors are when the controller has any kind of issue with taking a measurement (i.e. invalid Prometheus URL).","title":"What is the difference between failures and errors?"},{"location":"concepts/","text":"Concepts \u00b6 Rollout \u00b6 A Rollout is Kubernetes workload resource which is equivalent to a Kubernetes Deployment object. It is intended to replace a Deployment object in scenarios when more advanced deployment or progressive delivery functionality is needed. A Rollout provides the following features which a Kubernetes Deployment cannot: blue-green deployments canary deployments integration with ingress controllers and service meshes for advanced traffic routing integration with metric providers for blue-green & canary analysis automated promotion or rollback based on successful or failed metrics Progressive Delivery \u00b6 Progressive delivery is the process of releasing updates of a product in a controlled and gradual manner, thereby reducing the risk of the release, typically coupling automation and metric analysis to drive the automated promotion or rollback of the update. Progressive delivery is often described as an evolution of continuous delivery, extending the speed benefits made in CI/CD to the deployment process. This is accomplished by limiting the exposure of the new version to a subset of users, observing and analyzing for correct behavior, then progressively increasing the exposure to a broader and wider audience while continuously verifying correctness. Deployment Strategies \u00b6 While the industry has used a consistent terminology to describe various deployment strategies, the implementations of these strategies tend to differ across tooling. To make it clear how the Argo Rollouts will behave, here are the descriptions of the various deployment strategies implementations offered by the Argo Rollouts. Rolling Update \u00b6 A RollingUpdate slowly replaces the old version with the new version. As the new version comes up, the old version is scaled down in order to maintain the overall count of the application. This is the default strategy of the Deployment object. Recreate \u00b6 A Recreate deployment deletes the old version of the application before bring up the new version. As a result, this ensures that two versions of the application never run at the same time, but there is downtime during the deployment. Blue-Green \u00b6 A Blue-Green deployment (sometimes referred to as a Red-Black) has both the new and old version of the application deployed at the same time. During this time, only the old version of the application will receive production traffic. This allows the developers to run tests against the new version before switching the live traffic to the new version. Canary \u00b6 A Canary deployment exposes a subset of users to the new version of the application while serving the rest of the traffic to the old version. Once the new version is verified to be correct, the new version can gradually replace the old version. Ingress controllers and service meshes such as NGINX and Istio, enable more sophisticated traffic shaping patterns for canarying than what is natively available (e.g. achieving very fine-grained traffic splitting, or splitting based on HTTP headers).","title":"Concepts"},{"location":"concepts/#concepts","text":"","title":"Concepts"},{"location":"concepts/#rollout","text":"A Rollout is Kubernetes workload resource which is equivalent to a Kubernetes Deployment object. It is intended to replace a Deployment object in scenarios when more advanced deployment or progressive delivery functionality is needed. A Rollout provides the following features which a Kubernetes Deployment cannot: blue-green deployments canary deployments integration with ingress controllers and service meshes for advanced traffic routing integration with metric providers for blue-green & canary analysis automated promotion or rollback based on successful or failed metrics","title":"Rollout"},{"location":"concepts/#progressive-delivery","text":"Progressive delivery is the process of releasing updates of a product in a controlled and gradual manner, thereby reducing the risk of the release, typically coupling automation and metric analysis to drive the automated promotion or rollback of the update. Progressive delivery is often described as an evolution of continuous delivery, extending the speed benefits made in CI/CD to the deployment process. This is accomplished by limiting the exposure of the new version to a subset of users, observing and analyzing for correct behavior, then progressively increasing the exposure to a broader and wider audience while continuously verifying correctness.","title":"Progressive Delivery"},{"location":"concepts/#deployment-strategies","text":"While the industry has used a consistent terminology to describe various deployment strategies, the implementations of these strategies tend to differ across tooling. To make it clear how the Argo Rollouts will behave, here are the descriptions of the various deployment strategies implementations offered by the Argo Rollouts.","title":"Deployment Strategies"},{"location":"concepts/#rolling-update","text":"A RollingUpdate slowly replaces the old version with the new version. As the new version comes up, the old version is scaled down in order to maintain the overall count of the application. This is the default strategy of the Deployment object.","title":"Rolling Update"},{"location":"concepts/#recreate","text":"A Recreate deployment deletes the old version of the application before bring up the new version. As a result, this ensures that two versions of the application never run at the same time, but there is downtime during the deployment.","title":"Recreate"},{"location":"concepts/#blue-green","text":"A Blue-Green deployment (sometimes referred to as a Red-Black) has both the new and old version of the application deployed at the same time. During this time, only the old version of the application will receive production traffic. This allows the developers to run tests against the new version before switching the live traffic to the new version.","title":"Blue-Green"},{"location":"concepts/#canary","text":"A Canary deployment exposes a subset of users to the new version of the application while serving the rest of the traffic to the old version. Once the new version is verified to be correct, the new version can gradually replace the old version. Ingress controllers and service meshes such as NGINX and Istio, enable more sophisticated traffic shaping patterns for canarying than what is natively available (e.g. achieving very fine-grained traffic splitting, or splitting based on HTTP headers).","title":"Canary"},{"location":"getting-started/","text":"Getting Started \u00b6 This guide will demonstrate various concepts and features of Argo Rollouts by going through deployment, upgrade, promotion, and abortion of a Rollout. Requirements \u00b6 Kubernetes cluster with argo-rollouts controller installed (see install guide ) kubectl with argo-rollouts plugin installed (see install guide ) 1. Deploying a Rollout \u00b6 First we deploy a Rollout resource and a Kubernetes Service targeting that Rollout. The example Rollout in this guide utilizes a canary update strategy which sends 20% of traffic to the canary, followed by a manual promotion, and finally gradual automated traffic increases for the remainder of the upgrade. This behavior is described in the following portion of the Rollout spec: spec : replicas : 5 strategy : canary : steps : - setWeight : 20 - pause : {} - setWeight : 40 - pause : { duration : 10 } - setWeight : 60 - pause : { duration : 10 } - setWeight : 80 - pause : { duration : 10 } Run the following command to deploy the initial Rollout and Service: kubectl apply -f https://raw.githubusercontent.com/argoproj/argo-rollouts/master/docs/getting-started/basic/rollout.yaml kubectl apply -f https://raw.githubusercontent.com/argoproj/argo-rollouts/master/docs/getting-started/basic/service.yaml Initial creations of any Rollout will immediately scale up the replicas to 100% (skipping any canary upgrade steps, analysis, etc...) since there was no upgrade that occurred. The Argo Rollouts kubectl plugin allows you to visualize the Rollout, its related resources (ReplicaSets, Pods, AnalysisRuns), and presents live state changes as they occur. To watch the rollout as it deploys, run the get rollout --watch command from plugin: kubectl argo rollouts get rollout rollouts-demo --watch 2. Updating a Rollout \u00b6 Next it is time to perform an update. Just as with Deployments, any change to the Pod template field ( spec.template ) results in a new version (i.e. ReplicaSet) to be deployed. Updating a Rollout involves modifying the rollout spec, typically changing the container image field with a new version, and then running kubectl apply against the new manifest. As a convenience, the rollouts plugin provides a set image command, which performs these steps against the live rollout object in-place. Run the following command to update the rollouts-demo Rollout with the \"yellow\" version of the container: kubectl argo rollouts set image rollouts-demo \\ rollouts-demo = argoproj/rollouts-demo:yellow During a rollout update, the controller will progress through the steps defined in the Rollout's update strategy. The example rollout sets a 20% traffic weight to the canary, and pauses the rollout indefinitely until user action is taken to unpause/promote the rollout. After updating the image, watch the rollout again until it reaches the paused state: kubectl argo rollouts get rollout rollouts-demo --watch When the demo rollout reaches the second step, we can see from the plugin that the Rollout is in a paused state, and now has 1 of 5 replicas running the new version of the pod template, and 4 of 5 replicas running the old version. This equates to the 20% canary weight as defined by the setWeight: 20 step. 3. Promoting a Rollout \u00b6 The rollout is now in an paused state. When a Rollout reaches a pause step with no duration, it will remain in a paused state indefinitely until it is resumed/promoted. To manually promote a rollout to the next step, run the promote command of the plugin: kubectl argo rollouts promote rollouts-demo After promotion, Rollout will proceed to execute the remaining steps. The remaining rollout steps in our example are fully automated, so the Rollout will eventually complete steps until it has has fully transitioned to the new version. Watch the rollout again until it has completed all steps: kubectl argo rollouts get rollout rollouts-demo --watch Tip The promote command also supports the ability to skip all remaining steps with the --skip-all-steps flag. Once all steps complete successfully, the new ReplicaSet is marked as the \"stable\" ReplicaSet. Whenever a rollout is aborted during an update, either automatically via a failed canary analysis, or manually by a user, the Rollout will fall back to the \"stable\" version. 4. Aborting a Rollout \u00b6 Next we will learn how to manually abort a rollout during an update. First, deploy a new \"red\" version of the container using the set image command, and wait for the rollout to reach the paused step again: kubectl argo rollouts set image rollouts-demo \\ rollouts-demo = argoproj/rollouts-demo:red This time, instead of promoting the rollout to the next step, we will abort the update, so that it falls back to the \"stable\" version. The plugin provides an abort command as a way to manually abort a rollout at any time during an update: kubectl argo rollouts abort rollouts-demo When a rollout is aborted, it will scale up the \"stable\" version of the ReplicaSet (in this case the yellow image), and scale down any other versions. Although the stable version of the ReplicaSet may be running and is healthy, the overall rollout is still considered Degraded , since the desired version (the red image) is not the version which is actually running. In order to make Rollout considered Healthy again and not Degraded, it is necessary to change the desired state back to the previous, stable version. This typically involves running kubectl apply against the previous Rollout spec. In our case, we can simply re-run the set image command using the previous, \"yellow\" image. kubectl argo rollouts set image rollouts-demo \\ rollouts-demo=argoproj/rollouts-demo:yellow After running this command, you should notice that the Rollout immediately becomes Healthy, and there is no activity with regards to new ReplicaSets becoming created. When a Rollout has not yet reached its desired state (e.g. it was aborted, or in the middle of an update), and the stable manifest were re-applied, the Rollout detects this as a rollback and not a update, and will fast-track the deployment of the stable ReplicaSet by skipping analysis, and the steps. Summary \u00b6 In this guide, we have learned basic capabilities of Argo Rollouts, including: Deploying a rollout Performing a canary update Manual promotion Manual abortion The Rollout in this basic example did not utilize a ingress controller or service mesh provider to route traffic. Instead, it used normal Kubernetes Service networking (i.e. kube-proxy) to achieve an approximate canary weight, based on the closest ratio of new to old replica counts. As a result, this Rollout had a limitation in that it could only achieve a minimum canary weight of 20%, by scaling 1 of 5 pods to run the new version. In order to achieve much finer grained canarys, a ingress controller or service mesh is necessary. Follow the NGINX Guide to see how Argo Rollouts can leverage a networking provider to gain more advanced traffic shaping.","title":"Basic Usage"},{"location":"getting-started/#getting-started","text":"This guide will demonstrate various concepts and features of Argo Rollouts by going through deployment, upgrade, promotion, and abortion of a Rollout.","title":"Getting Started"},{"location":"getting-started/#requirements","text":"Kubernetes cluster with argo-rollouts controller installed (see install guide ) kubectl with argo-rollouts plugin installed (see install guide )","title":"Requirements"},{"location":"getting-started/#1-deploying-a-rollout","text":"First we deploy a Rollout resource and a Kubernetes Service targeting that Rollout. The example Rollout in this guide utilizes a canary update strategy which sends 20% of traffic to the canary, followed by a manual promotion, and finally gradual automated traffic increases for the remainder of the upgrade. This behavior is described in the following portion of the Rollout spec: spec : replicas : 5 strategy : canary : steps : - setWeight : 20 - pause : {} - setWeight : 40 - pause : { duration : 10 } - setWeight : 60 - pause : { duration : 10 } - setWeight : 80 - pause : { duration : 10 } Run the following command to deploy the initial Rollout and Service: kubectl apply -f https://raw.githubusercontent.com/argoproj/argo-rollouts/master/docs/getting-started/basic/rollout.yaml kubectl apply -f https://raw.githubusercontent.com/argoproj/argo-rollouts/master/docs/getting-started/basic/service.yaml Initial creations of any Rollout will immediately scale up the replicas to 100% (skipping any canary upgrade steps, analysis, etc...) since there was no upgrade that occurred. The Argo Rollouts kubectl plugin allows you to visualize the Rollout, its related resources (ReplicaSets, Pods, AnalysisRuns), and presents live state changes as they occur. To watch the rollout as it deploys, run the get rollout --watch command from plugin: kubectl argo rollouts get rollout rollouts-demo --watch","title":"1. Deploying a Rollout"},{"location":"getting-started/#2-updating-a-rollout","text":"Next it is time to perform an update. Just as with Deployments, any change to the Pod template field ( spec.template ) results in a new version (i.e. ReplicaSet) to be deployed. Updating a Rollout involves modifying the rollout spec, typically changing the container image field with a new version, and then running kubectl apply against the new manifest. As a convenience, the rollouts plugin provides a set image command, which performs these steps against the live rollout object in-place. Run the following command to update the rollouts-demo Rollout with the \"yellow\" version of the container: kubectl argo rollouts set image rollouts-demo \\ rollouts-demo = argoproj/rollouts-demo:yellow During a rollout update, the controller will progress through the steps defined in the Rollout's update strategy. The example rollout sets a 20% traffic weight to the canary, and pauses the rollout indefinitely until user action is taken to unpause/promote the rollout. After updating the image, watch the rollout again until it reaches the paused state: kubectl argo rollouts get rollout rollouts-demo --watch When the demo rollout reaches the second step, we can see from the plugin that the Rollout is in a paused state, and now has 1 of 5 replicas running the new version of the pod template, and 4 of 5 replicas running the old version. This equates to the 20% canary weight as defined by the setWeight: 20 step.","title":"2. Updating a Rollout"},{"location":"getting-started/#3-promoting-a-rollout","text":"The rollout is now in an paused state. When a Rollout reaches a pause step with no duration, it will remain in a paused state indefinitely until it is resumed/promoted. To manually promote a rollout to the next step, run the promote command of the plugin: kubectl argo rollouts promote rollouts-demo After promotion, Rollout will proceed to execute the remaining steps. The remaining rollout steps in our example are fully automated, so the Rollout will eventually complete steps until it has has fully transitioned to the new version. Watch the rollout again until it has completed all steps: kubectl argo rollouts get rollout rollouts-demo --watch Tip The promote command also supports the ability to skip all remaining steps with the --skip-all-steps flag. Once all steps complete successfully, the new ReplicaSet is marked as the \"stable\" ReplicaSet. Whenever a rollout is aborted during an update, either automatically via a failed canary analysis, or manually by a user, the Rollout will fall back to the \"stable\" version.","title":"3. Promoting a Rollout"},{"location":"getting-started/#4-aborting-a-rollout","text":"Next we will learn how to manually abort a rollout during an update. First, deploy a new \"red\" version of the container using the set image command, and wait for the rollout to reach the paused step again: kubectl argo rollouts set image rollouts-demo \\ rollouts-demo = argoproj/rollouts-demo:red This time, instead of promoting the rollout to the next step, we will abort the update, so that it falls back to the \"stable\" version. The plugin provides an abort command as a way to manually abort a rollout at any time during an update: kubectl argo rollouts abort rollouts-demo When a rollout is aborted, it will scale up the \"stable\" version of the ReplicaSet (in this case the yellow image), and scale down any other versions. Although the stable version of the ReplicaSet may be running and is healthy, the overall rollout is still considered Degraded , since the desired version (the red image) is not the version which is actually running. In order to make Rollout considered Healthy again and not Degraded, it is necessary to change the desired state back to the previous, stable version. This typically involves running kubectl apply against the previous Rollout spec. In our case, we can simply re-run the set image command using the previous, \"yellow\" image. kubectl argo rollouts set image rollouts-demo \\ rollouts-demo=argoproj/rollouts-demo:yellow After running this command, you should notice that the Rollout immediately becomes Healthy, and there is no activity with regards to new ReplicaSets becoming created. When a Rollout has not yet reached its desired state (e.g. it was aborted, or in the middle of an update), and the stable manifest were re-applied, the Rollout detects this as a rollback and not a update, and will fast-track the deployment of the stable ReplicaSet by skipping analysis, and the steps.","title":"4. Aborting a Rollout"},{"location":"getting-started/#summary","text":"In this guide, we have learned basic capabilities of Argo Rollouts, including: Deploying a rollout Performing a canary update Manual promotion Manual abortion The Rollout in this basic example did not utilize a ingress controller or service mesh provider to route traffic. Instead, it used normal Kubernetes Service networking (i.e. kube-proxy) to achieve an approximate canary weight, based on the closest ratio of new to old replica counts. As a result, this Rollout had a limitation in that it could only achieve a minimum canary weight of 20%, by scaling 1 of 5 pods to run the new version. In order to achieve much finer grained canarys, a ingress controller or service mesh is necessary. Follow the NGINX Guide to see how Argo Rollouts can leverage a networking provider to gain more advanced traffic shaping.","title":"Summary"},{"location":"installation/","text":"Installation \u00b6 Controller Installation \u00b6 kubectl create namespace argo-rollouts kubectl apply -n argo-rollouts -f https://raw.githubusercontent.com/argoproj/argo-rollouts/stable/manifests/install.yaml This will create a new namespace, argo-rollouts , where Argo Rollouts controller will run. Tip When installing Argo Rollouts on Kubernetes v1.14 or lower, the CRD manifests must be kubectl applied with the --validate=false option. This is caused by use of new CRD fields introduced in v1.15, which are rejected by default in lower API servers. Tip On GKE, you will need grant your account the ability to create new cluster roles: kubectl create clusterrolebinding YOURNAME-cluster-admin-binding --clusterrole = cluster-admin --user = YOUREMAIL@gmail.com Kubectl Plugin Installation \u00b6 The kubectl plugin is optional, but is convenient for managing and visualizing rollouts from the command line. Brew \u00b6 brew install argoproj/tap/kubectl-argo-rollouts Manual \u00b6 Install Argo Rollouts Kubectl plugin with curl. curl -LO https://github.com/argoproj/argo-rollouts/releases/latest/download/kubectl-argo-rollouts-darwin-amd64 For Linux dist, replace darwin with linux Make the kubectl-argo-rollouts binary executable. chmod +x ./kubectl-argo-rollouts-darwin-amd64 Move the binary into your PATH. sudo mv ./kubectl-argo-rollouts-darwin-amd64 /usr/local/bin/kubectl-argo-rollouts Test to ensure the version you installed is up-to-date: kubectl argo rollouts version","title":"Installation"},{"location":"installation/#installation","text":"","title":"Installation"},{"location":"installation/#controller-installation","text":"kubectl create namespace argo-rollouts kubectl apply -n argo-rollouts -f https://raw.githubusercontent.com/argoproj/argo-rollouts/stable/manifests/install.yaml This will create a new namespace, argo-rollouts , where Argo Rollouts controller will run. Tip When installing Argo Rollouts on Kubernetes v1.14 or lower, the CRD manifests must be kubectl applied with the --validate=false option. This is caused by use of new CRD fields introduced in v1.15, which are rejected by default in lower API servers. Tip On GKE, you will need grant your account the ability to create new cluster roles: kubectl create clusterrolebinding YOURNAME-cluster-admin-binding --clusterrole = cluster-admin --user = YOUREMAIL@gmail.com","title":"Controller Installation"},{"location":"installation/#kubectl-plugin-installation","text":"The kubectl plugin is optional, but is convenient for managing and visualizing rollouts from the command line.","title":"Kubectl Plugin Installation"},{"location":"installation/#brew","text":"brew install argoproj/tap/kubectl-argo-rollouts","title":"Brew"},{"location":"installation/#manual","text":"Install Argo Rollouts Kubectl plugin with curl. curl -LO https://github.com/argoproj/argo-rollouts/releases/latest/download/kubectl-argo-rollouts-darwin-amd64 For Linux dist, replace darwin with linux Make the kubectl-argo-rollouts binary executable. chmod +x ./kubectl-argo-rollouts-darwin-amd64 Move the binary into your PATH. sudo mv ./kubectl-argo-rollouts-darwin-amd64 /usr/local/bin/kubectl-argo-rollouts Test to ensure the version you installed is up-to-date: kubectl argo rollouts version","title":"Manual"},{"location":"migrating/","text":"Migrating to Rollouts \u00b6 Migrating to Argo Rollouts involves converting an existing Deployment resource, to a Rollout resource. When converting a Deployment to a Rollout, it involves changing three fields: Replacing the apiVersion from apps/v1 to argoproj.io/v1alpha1 Replacing the kind from Deployment to Rollout Replacing the deployment strategy with a blue-green or canary strategy Below is an example of a Rollout resource using the canary strategy. apiVersion : argoproj.io/v1alpha1 # Changed from apps/v1 kind : Rollout # Changed from Deployment metadata : name : rollouts-demo spec : selector : matchLabels : app : rollouts-demo template : metadata : labels : app : rollouts-demo spec : containers : - name : rollouts-demo image : argoproj/rollouts-demo:blue ports : - containerPort : 8080 strategy : canary : # Changed from rollingUpdate or recreate steps : - setWeight : 20 - pause : {} Other Considerations \u00b6 When migrating a Deployment which is already serving live production traffic, a Rollout should run next to the Deployment before deleting the Deployment. Not following this approach might result in downtime . It also allows for the Rollout to be tested before deleting the original Deployment.","title":"Migrating"},{"location":"migrating/#migrating-to-rollouts","text":"Migrating to Argo Rollouts involves converting an existing Deployment resource, to a Rollout resource. When converting a Deployment to a Rollout, it involves changing three fields: Replacing the apiVersion from apps/v1 to argoproj.io/v1alpha1 Replacing the kind from Deployment to Rollout Replacing the deployment strategy with a blue-green or canary strategy Below is an example of a Rollout resource using the canary strategy. apiVersion : argoproj.io/v1alpha1 # Changed from apps/v1 kind : Rollout # Changed from Deployment metadata : name : rollouts-demo spec : selector : matchLabels : app : rollouts-demo template : metadata : labels : app : rollouts-demo spec : containers : - name : rollouts-demo image : argoproj/rollouts-demo:blue ports : - containerPort : 8080 strategy : canary : # Changed from rollingUpdate or recreate steps : - setWeight : 20 - pause : {}","title":"Migrating to Rollouts"},{"location":"migrating/#other-considerations","text":"When migrating a Deployment which is already serving live production traffic, a Rollout should run next to the Deployment before deleting the Deployment. Not following this approach might result in downtime . It also allows for the Rollout to be tested before deleting the original Deployment.","title":"Other Considerations"},{"location":"roadmap/","text":"Roadmap \u00b6 The item listed here are proposed items for Argo Rollouts and are subject to change. To see where items may fall into releases, visit the github milestones and notice if the item appears in the milestone description. Roadmap Validation Webhook Notifications Ephemeral Canary Labels Rollback Window Header Based Routing Shadow Traffic Validation (continued) \u00b6 The v0.9 rollouts release added improved validation of user made errors in the Rollout spec, and now surfaces the reason for errors to the Rollout conditions and ultimately to tools like Argo CD. Additional improvements regarding validation are being considered such as: * a validating webhook to prevent invalid objects from entering the system. * a linting command in the CLI to statically validate rollout objects. Webhook Notifications \u00b6 Issue #369 When a rollout transitions state, such as an aborted rollout due to failed analysis, there is no mechanism to notify an external system about the failure. Instead, users must currently put in place something to monitor the rollout, and notice the condition to take action. Monitoring a rollout is not always an option, since it requires that the external system have access to the Kubernetes API server. A webhook notification feature of Rollouts would allow a push-based model where the Rollout controller itself would push an event to an external system, in the form of a webhook/cloud event. Ephemeral Canary Labels \u00b6 Issue #445 Currently the pods which are associated with a Rollout's canary and stable ReplicaSet, are not labeled with a predictable label. Instead they are labeled with a value under rollouts-pod-template-hash , which is a hashed value of the pod template spec. This value is always changing, and makes it very inconvenient to creating dashboards or formulate static queries against the canary/stable ReplicaSets, for the purposes of analysis. This enhancement would allow user-defined labels to be attached to the canary/stable pods, as well as removed when the pods changes roles. For example, during an upgrade, the canary pods could be labeled with a canary label, which would be removed or relabeled as to stable , once the Rollout was successful. Rollback Window \u00b6 Issue #574 Currently, when an older Rollout manifest is re-applied, the controller treats it the same as a spec change, and will execute the full list of steps, and perform analysis too. There are two exceptions to this rule: 1. the controller detects if it is moving back to a blue-green ReplicaSet which exists and is still scaled up (within its scaleDownDelay) 2. the controller detects it is moving back to the canary's \"stable\" ReplicaSet, and the upgrade had not yet completed. It is often undesirable to re-run analysis and steps for a rollout, when the desired behavior is to rollback as soon as possible. To help with this, a rollback window feature would allow users a window indicate to the controller to Header Based Routing \u00b6 Issue #474 Users who are using Rollout with a service mesh, may want to leverage some of its more advanced features, such as routing traffic via headers instead of purely by percentage. Header based routing provides the ability to route traffic based on a header, instead of a percentage of traffic. This allows more flexibility when canarying, such as providing session stickiness, or only exposing a subset of users with a HTTP cookie or user-agent. Shadow Traffic \u00b6 Issue #474 Some service meshes provide the ability to \"shadow\" live production traffic. A feature in rollouts could provide a canary step to shadow traffic to the canary stack, to see how it responds to the real-world data.","title":"Roadmap"},{"location":"roadmap/#roadmap","text":"The item listed here are proposed items for Argo Rollouts and are subject to change. To see where items may fall into releases, visit the github milestones and notice if the item appears in the milestone description. Roadmap Validation Webhook Notifications Ephemeral Canary Labels Rollback Window Header Based Routing Shadow Traffic","title":"Roadmap"},{"location":"roadmap/#validation-continued","text":"The v0.9 rollouts release added improved validation of user made errors in the Rollout spec, and now surfaces the reason for errors to the Rollout conditions and ultimately to tools like Argo CD. Additional improvements regarding validation are being considered such as: * a validating webhook to prevent invalid objects from entering the system. * a linting command in the CLI to statically validate rollout objects.","title":"Validation (continued)"},{"location":"roadmap/#webhook-notifications","text":"Issue #369 When a rollout transitions state, such as an aborted rollout due to failed analysis, there is no mechanism to notify an external system about the failure. Instead, users must currently put in place something to monitor the rollout, and notice the condition to take action. Monitoring a rollout is not always an option, since it requires that the external system have access to the Kubernetes API server. A webhook notification feature of Rollouts would allow a push-based model where the Rollout controller itself would push an event to an external system, in the form of a webhook/cloud event.","title":"Webhook Notifications"},{"location":"roadmap/#ephemeral-canary-labels","text":"Issue #445 Currently the pods which are associated with a Rollout's canary and stable ReplicaSet, are not labeled with a predictable label. Instead they are labeled with a value under rollouts-pod-template-hash , which is a hashed value of the pod template spec. This value is always changing, and makes it very inconvenient to creating dashboards or formulate static queries against the canary/stable ReplicaSets, for the purposes of analysis. This enhancement would allow user-defined labels to be attached to the canary/stable pods, as well as removed when the pods changes roles. For example, during an upgrade, the canary pods could be labeled with a canary label, which would be removed or relabeled as to stable , once the Rollout was successful.","title":"Ephemeral Canary Labels"},{"location":"roadmap/#rollback-window","text":"Issue #574 Currently, when an older Rollout manifest is re-applied, the controller treats it the same as a spec change, and will execute the full list of steps, and perform analysis too. There are two exceptions to this rule: 1. the controller detects if it is moving back to a blue-green ReplicaSet which exists and is still scaled up (within its scaleDownDelay) 2. the controller detects it is moving back to the canary's \"stable\" ReplicaSet, and the upgrade had not yet completed. It is often undesirable to re-run analysis and steps for a rollout, when the desired behavior is to rollback as soon as possible. To help with this, a rollback window feature would allow users a window indicate to the controller to","title":"Rollback Window"},{"location":"roadmap/#header-based-routing","text":"Issue #474 Users who are using Rollout with a service mesh, may want to leverage some of its more advanced features, such as routing traffic via headers instead of purely by percentage. Header based routing provides the ability to route traffic based on a header, instead of a percentage of traffic. This allows more flexibility when canarying, such as providing session stickiness, or only exposing a subset of users with a HTTP cookie or user-agent.","title":"Header Based Routing"},{"location":"roadmap/#shadow-traffic","text":"Issue #474 Some service meshes provide the ability to \"shadow\" live production traffic. A feature in rollouts could provide a canary step to shadow traffic to the canary stack, to see how it responds to the real-world data.","title":"Shadow Traffic"},{"location":"features/analysis/","text":"Analysis & Progressive Delivery \u00b6 Argo Rollouts provides several ways to perform analysis to drive progressive delivery. This document describes how to achieve various forms of progressive delivery, varying the point in time analysis is performed, it's frequency, and occurrence. Custom Resource Definitions \u00b6 CRD Description Rollout A Rollout acts as a drop-in replacement for a Deployment resource. It provides additional blueGreen and canary update strategies. These strategies can create AnalysisRuns and Experiments during the update, which will progress the update, or abort it. AnalysisTemplate An AnalysisTemplate is a template spec which defines how to perform a canary analysis, such as the metrics which it should perform, its frequency, and the values which are considered successful or failed. AnalysisTemplates may be parameterized with inputs values. ClusterAnalysisTemplate A ClusterAnalysisTemplate is like an AnalysisTemplate , but it is not limited to its namespace. It can be used by any Rollout throughout the cluster. AnalysisRun An AnalysisRun is an instantiation of an AnalysisTemplate . AnalysisRuns are like Jobs in that they eventually complete. Completed runs are considered Successful, Failed, or Inconclusive, and the result of the run affect if the Rollout's update will continue, abort, or pause, respectively. Experiment An Experiment is limited run of one or more ReplicaSets for the purposes of analysis. Experiments typically run for a pre-determined duration, but can also run indefinitely until stopped. Experiments may reference an AnalysisTemplate to run during or after the experiment. The canonical use case for an Experiment is to start a baseline and canary deployment in parallel, and compare the metrics produced by the baseline and canary pods for an equal comparison. Background Analysis \u00b6 Analysis can be run in the background -- while the canary is progressing through its rollout steps. The following example gradually increments the canary weight by 20% every 10 minutes until it reaches 100%. In the background, an AnalysisRun is started based on the AnalysisTemplate named success-rate . The success-rate template queries a prometheus server, measuring the HTTP success rates at 5 minute intervals/samples. It has no end time, and continues until stopped or failed. If the metric is measured to be less than 95%, and there are three such measurements, the analysis is considered Failed. The failed analysis causes the Rollout to abort, setting the canary weight back to zero, and the Rollout would be considered in a Degraded . Otherwise, if the rollout completes all of its canary steps, the rollout is considered successful and the analysis run is stopped by the controller. This example highlights: Background analysis style of progressive delivery Using a Prometheus query to perform a measurement The ability to parameterize the analysis Delay starting the analysis run until step 3 (Set Weight 40%) Rollout apiVersion : argoproj.io/v1alpha1 kind : Rollout metadata : name : guestbook spec : ... strategy : canary : analysis : templates : - templateName : success-rate startingStep : 2 # delay starting analysis run until setWeight: 40% args : - name : service-name value : guestbook-svc.default.svc.cluster.local steps : - setWeight : 20 - pause : { duration : 10m } - setWeight : 40 - pause : { duration : 10m } - setWeight : 60 - pause : { duration : 10m } - setWeight : 80 - pause : { duration : 10m } AnalysisTemplate apiVersion : argoproj.io/v1alpha1 kind : AnalysisTemplate metadata : name : success-rate spec : args : - name : service-name metrics : - name : success-rate interval : 5m # NOTE: prometheus queries return results in the form of a vector. # So it is common to access the index 0 of the returned array to obtain the value successCondition : result[0] >= 0.95 failureLimit : 3 provider : prometheus : address : http://prometheus.example.com:9090 query : | sum(irate( istio_requests_total{reporter=\"source\",destination_service=~\"{{args.service-name}}\",response_code!~\"5.*\"}[5m] )) / sum(irate( istio_requests_total{reporter=\"source\",destination_service=~\"{{args.service-name}}\"}[5m] )) Inline Analysis \u00b6 Analysis can also be performed as a rollout step as an inline \"analysis\" step. When analysis is performed \"inlined,\" an AnalysisRun is started when the step is reached, and blocks the rollout until the run is completed. The success or failure of the analysis run decides if the rollout will proceed to the next step, or abort the rollout completely. This example sets the canary weight to 20%, pauses for 5 minutes, then runs an analysis. If the analysis was successful, continues with rollout, otherwise aborts. This example demonstrates: The ability to invoke an analysis in-line as part of steps apiVersion : argoproj.io/v1alpha1 kind : Rollout metadata : name : guestbook spec : ... strategy : canary : steps : - setWeight : 20 - pause : { duration : 5m } - analysis : templates : - templateName : success-rate args : - name : service-name value : guestbook-svc.default.svc.cluster.local In this example, the AnalysisTemplate is identical to the background analysis example, but since no interval is specified, the analysis will perform a single measurement and complete. apiVersion : argoproj.io/v1alpha1 kind : AnalysisTemplate metadata : name : success-rate spec : args : - name : service-name - name : prometheus-port value : 9090 metrics : - name : success-rate successCondition : result[0] >= 0.95 provider : prometheus : address : \"http://prometheus.example.com:{{args.prometheus-port}}\" query : | sum(irate( istio_requests_total{reporter=\"source\",destination_service=~\"{{args.service-name}}\",response_code!~\"5.*\"}[5m] )) / sum(irate( istio_requests_total{reporter=\"source\",destination_service=~\"{{args.service-name}}\"}[5m] )) Multiple measurements can be performed over a longer duration period, by specifying the count and interval fields: metrics : - name : success-rate successCondition : result[0] >= 0.95 interval : 60s count : 5 provider : prometheus : address : http://prometheus.example.com:9090 query : ... ClusterAnalysisTemplates \u00b6 Important Available since v0.9.0 A Rollout can reference a Cluster scoped AnalysisTemplate called a ClusterAnalysisTemplate . This can be useful when you want to share an AnalysisTemplate across multiple Rollouts; in different namespaces, and avoid duplicating the same template in every namespace. Use the field clusterScope: true to reference a ClusterAnalysisTemplate instead of an AnalysisTemplate. Rollout apiVersion : argoproj.io/v1alpha1 kind : Rollout metadata : name : guestbook spec : ... strategy : canary : steps : - setWeight : 20 - pause : { duration : 5m } - analysis : templates : - templateName : success-rate clusterScope : true args : - name : service-name value : guestbook-svc.default.svc.cluster.local ClusterAnalysisTemplate apiVersion : argoproj.io/v1alpha1 kind : ClusterAnalysisTemplate metadata : name : success-rate spec : args : - name : service-name - name : prometheus-port value : 9090 metrics : - name : success-rate successCondition : result[0] >= 0.95 provider : prometheus : address : \"http://prometheus.example.com:{{args.prometheus-port}}\" query : | sum(irate( istio_requests_total{reporter=\"source\",destination_service=~\"{{args.service-name}}\",response_code!~\"5.*\"}[5m] )) / sum(irate( istio_requests_total{reporter=\"source\",destination_service=~\"{{args.service-name}}\"}[5m] )) Note The resulting AnalysisRun will still run in the namespace of the Rollout Analysis with Multiple Templates \u00b6 A Rollout can reference multiple AnalysisTemplates when constructing an AnalysisRun. This allows users to compose analysis from multiple AnalysisTemplates. If multiple templates are referenced, then the controller will merge the templates together. The controller combines the metrics and args fields of all the templates. Rollout apiVersion : argoproj.io/v1alpha1 kind : Rollout metadata : name : guestbook spec : ... strategy : canary : analysis : templates : - templateName : success-rate - templateName : error-rate args : - name : service-name value : guestbook-svc.default.svc.cluster.local AnalysisTemplate apiVersion : argoproj.io/v1alpha1 kind : AnalysisTemplate metadata : name : success-rate spec : args : - name : service-name metrics : - name : success-rate interval : 5m successCondition : result[0] >= 0.95 failureLimit : 3 provider : prometheus : address : http://prometheus.example.com:9090 query : | sum(irate( istio_requests_total{reporter=\"source\",destination_service=~\"{{args.service-name}}\",response_code!~\"5.*\"}[5m] )) / sum(irate( istio_requests_total{reporter=\"source\",destination_service=~\"{{args.service-name}}\"}[5m] )) --- apiVersion : argoproj.io/v1alpha1 kind : AnalysisTemplate metadata : name : error-rate spec : args : - name : service-name metrics : - name : error-rate interval : 5m successCondition : result[0] <= 0.95 failureLimit : 3 provider : prometheus : address : http://prometheus.example.com:9090 query : | sum(irate( istio_requests_total{reporter=\"source\",destination_service=~\"{{args.service-name}}\",response_code=~\"5.*\"}[5m] )) / sum(irate( istio_requests_total{reporter=\"source\",destination_service=~\"{{args.service-name}}\"}[5m] )) AnalysisRun # NOTE: Generated AnalysisRun from the multiple templates apiVersion : argoproj.io/v1alpha1 kind : AnalysisRun metadata : name : guestbook-CurrentPodHash-multiple-templates spec : args : - name : service-name value : guestbook-svc.default.svc.cluster.local metrics : - name : success-rate interval : 5m successCondition : result[0] >= 0.95 failureLimit : 3 provider : prometheus : address : http://prometheus.example.com:9090 query : | sum(irate( istio_requests_total{reporter=\"source\",destination_service=~\"{{args.service-name}}\",response_code!~\"5.*\"}[5m] )) / sum(irate( istio_requests_total{reporter=\"source\",destination_service=~\"{{args.service-name}}\"}[5m] )) - name : error-rate interval : 5m successCondition : result[0] <= 0.95 failureLimit : 3 provider : prometheus : address : http://prometheus.example.com:9090 query : | sum(irate( istio_requests_total{reporter=\"source\",destination_service=~\"{{args.service-name}}\",response_code=~\"5.*\"}[5m] )) / sum(irate( istio_requests_total{reporter=\"source\",destination_service=~\"{{args.service-name}}\"}[5m] )) Note The controller will error when merging the templates if: Multiple metrics in the templates have the same name Two arguments with the same name both have values Analysis Template Arguments \u00b6 AnalysisTemplates may declare a set of arguments that can be passed by Rollouts. The args can then be used as in metrics configuration and are resolved at the time the AnalysisRun is created. Argument placeholders are defined as {{ args.<name> }} . apiVersion : argoproj.io/v1alpha1 kind : AnalysisTemplate metadata : name : args-example spec : args : # required - name : service-name - name : stable-hash - name : latest-hash # optional - name : api-url value : http://example/measure # from secret - name : api-token valueFrom : secretKeyRef : name : token-secret key : apiToken metrics : - name : webmetric successCondition : result == 'true' provider : web : # placeholders are resolved when an AnalysisRun is created url : \"{{ args.api-url }}?service={{ args.service-name }}\" headers : - key : Authorization value : \"Bearer {{ args.api-token }}\" jsonPath : \"{$.results.ok}\" Analysis arguments defined in a Rollout are merged with the args from the AnalysisTemplate when the AnalysisRun is created. apiVersion : argoproj.io/v1alpha1 kind : Rollout metadata : name : guestbook spec : ... strategy : canary : analysis : templates : - templateName : args-example args : # required value - name : service-name value : guestbook-svc.default.svc.cluster.local # override default value - name : api-url value : http://other-api # pod template hash from the stable ReplicaSet - name : stable-hash valueFrom : podTemplateHashValue : Stable # pod template hash from the latest ReplicaSet - name : latest-hash valueFrom : podTemplateHashValue : Latest BlueGreen Pre Promotion Analysis \u00b6 A Rollout using the BlueGreen strategy can launch an AnalysisRun before it switches traffic to the new version. The AnalysisRun can be used to block the Service selector switch until the AnalysisRun finishes successful. The success or failure of the analysis run decides if the Rollout will switch traffic, or abort the Rollout completely. apiVersion : argoproj.io/v1alpha1 kind : Rollout metadata : name : guestbook spec : ... strategy : blueGreen : activeService : active-svc previewService : preview-svc prePromotionAnalysis : templates : - templateName : smoke-tests args : - name : service-name value : preview-svc.default.svc.cluster.local In this example, the Rollout is creating a AnalysisRun once the new version has all the pods available. The Rollout will not switch traffic to the new version until the analysis run finishes successfully. Note: if the autoPromotionSeconds field is specified and the Rollout has waited auto promotion seconds amount of time, the Rollout marks the AnalysisRun successful and switches the traffic to a new version automatically. If the AnalysisRun completes before then, the Rollout will not create another AnalysisRun and wait out the rest of the autoPromotionSeconds . BlueGreen Post Promotion Analysis \u00b6 A Rollout using a BlueGreen strategy can launch an analysis run after the traffic switch to new version. If the analysis run fails or errors out, the Rollout enters an aborted state and switch traffic back to the previous stable Replicaset. If scaleDownDelaySeconds is specified, the controller will cancel any AnalysisRuns at time of scaleDownDelay to scale down the ReplicaSet. If it is omitted, and post analysis is specified, it will scale down the ReplicaSet only after the AnalysisRun completes (with a minimum of 30 seconds). apiVersion : argoproj.io/v1alpha1 kind : Rollout metadata : name : guestbook spec : ... strategy : blueGreen : activeService : active-svc previewService : preview-svc scaleDownDelaySeconds : 600 # 10 minutes postPromotionAnalysis : templates : - templateName : smoke-tests args : - name : service-name value : preview-svc.default.svc.cluster.local Failure Conditions \u00b6 failureCondition can be used to cause an analysis run to fail. The following example continually polls a prometheus server to get the total number of errors every 5 minutes, causing the analysis run to fail if 10 or more errors were encountered. metrics : - name : total-errors interval : 5m failureCondition : result[0] >= 10 failureLimit : 3 provider : prometheus : address : http://prometheus.example.com:9090 query : | sum(irate( istio_requests_total{reporter=\"source\",destination_service=~\"{{args.service-name}}\",response_code~\"5.*\"}[5m] )) Inconclusive Runs \u00b6 Analysis runs can also be considered Inconclusive , which indicates the run was neither successful, nor failed. Inconclusive runs causes a rollout to become paused at its current step. Manual intervention is then needed to either resume the rollout, or abort. One example of how analysis runs could become Inconclusive , is when a metric defines no success or failure conditions. metrics : - name : my-query provider : prometheus : address : http://prometheus.example.com:9090 query : ... Inconclusive analysis runs might also happen when both success and failure conditions are specified, but the measurement value did not meet either condition. metrics : - name : success-rate successCondition : result[0] >= 0.90 failureCondition : result[0] < 0.50 provider : prometheus : address : http://prometheus.example.com:9090 query : ... A use case for having Inconclusive analysis runs are to enable Argo Rollouts to automate the execution of analysis runs, and collect the measurement, but still allow human judgement to decide whether or not measurement value is acceptable and decide to proceed or abort. Delay Analysis Runs \u00b6 If the analysis run does not need to start immediately (i.e give the metric provider time to collect metrics on the canary version), Analysis Runs can delay the specific metric analysis. Each metric can be configured to have a different delay. In additional to the metric specific delays, the rollouts with background analysis can delay creating an analysis run until a certain step is reached Delaying a specific analysis metric: metrics : - name : success-rate # Do not start this analysis until 5 minutes after the analysis run starts initialDelay : 5m successCondition : result[0] >= 0.90 provider : prometheus : address : http://prometheus.example.com:9090 query : ... Delaying starting background analysis run until step 3 (Set Weight 40%): apiVersion : argoproj.io/v1alpha1 kind : Rollout metadata : name : guestbook spec : strategy : canary : analysis : templates : - templateName : success-rate startingStep : 2 steps : - setWeight : 20 - pause : { duration : 10m } - setWeight : 40 - pause : { duration : 10m } Referencing Secrets \u00b6 AnalysisTemplates and AnalysisRuns can reference secret objects in .spec.args . This allows users to securely pass authentication information to Metric Providers, like login credentials or API tokens. An AnalysisRun can only reference secrets from the same namespace as it's running in. This is only relevant for AnalysisRuns, since AnalysisTemplates do not resolve the secret. In the following example, an AnalysisTemplate references an API token and passes it to a Web metric provider. This example demonstrates: The ability to reference a secret in the AnalysisTemplate .spec.args The ability to pass secret arguments to Metric Providers apiVersion : argoproj.io/v1alpha1 kind : AnalysisTemplate spec : args : - name : api-token valueFrom : secretKeyRef : name : token-secret key : apiToken metrics : - name : webmetric provider : web : headers : - key : Authorization value : \"Bearer {{ args.api-token }}\" Experimentation (e.g. Mann-Whitney Analysis) \u00b6 Analysis can also be done as part of an Experiment. This example starts both a canary and baseline ReplicaSet. The ReplicaSets run for 1 hour, then scale down to zero. Call out to Kayenta to perform Mann-Whintney analysis against the two pods. Demonstrates ability to start a short-lived experiment and an asynchronous analysis. This example demonstrates: The ability to start an Experiment as part of rollout steps, which launches multiple ReplicaSets (e.g. baseline & canary) The ability to reference and supply pod-template-hash to an AnalysisRun Kayenta metrics Rollout apiVersion : argoproj.io/v1alpha1 kind : Rollout metadata : name : guestbook labels : app : guestbook spec : strategy : canary : steps : - experiment : duration : 1h templates : - name : baseline specRef : stable - name : canary specRef : canary analysis : templateName : mann-whitney args : - name : stable-hash valueFrom : podTemplateHashValue : Stable - name : canary-hash valueFrom : podTemplateHashValue : Latest AnalysisTemplate apiVersion : argoproj.io/v1alpha1 kind : AnalysisTemplate metadata : name : mann-whitney spec : args : - name : start-time - name : end-time - name : stable-hash - name : canary-hash metrics : - name : mann-whitney provider : kayenta : address : https://kayenta.example.com application : guestbook canaryConfigName : my-test thresholds : pass : 90 marginal : 75 scopes : - name : default controlScope : scope : app=guestbook and rollouts-pod-template-hash={{args.stable-hash}} step : 60 start : \"{{args.start-time}}\" end : \"{{args.end-time}}\" experimentScope : scope : app=guestbook and rollouts-pod-template-hash={{args.canary-hash}} step : 60 start : \"{{args.start-time}}\" end : \"{{args.end-time}}\" Experiment apiVersion : argoproj.io/v1alpha1 kind : Experiment name : name : guestbook-6c54544bf9-0 spec : duration : 1h templates : - name : baseline replicas : 1 spec : containers : - name : guestbook image : guestbook:v1 - name : canary replicas : 1 spec : containers : - name : guestbook image : guestbook:v2 analysis : templateName : mann-whitney args : - name : start-time value : \"{{experiment.availableAt}}\" - name : end-time value : \"{{experiment.finishedAt}}\" In order to perform multiple kayenta runs over some time duration, the interval and count fields can be supplied. When the start and end fields are omitted from the kayenta scopes, the values will be implicitly decided as: start = if lookback: true start of analysis, otherwise current time - interval end = current time apiVersion : argoproj.io/v1alpha1 kind : AnalysisTemplate metadata : name : mann-whitney spec : args : - name : stable-hash - name : canary-hash metrics : - name : mann-whitney provider : kayenta : address : https://kayenta.intuit.com application : guestbook canaryConfigName : my-test interval : 3600 count : 3 # loopback will cause start time value to be equal to start of analysis # lookback: true thresholds : pass : 90 marginal : 75 scopes : - name : default controlScope : scope : app=guestbook and rollouts-pod-template-hash={{args.stable-hash}} step : 60 experimentScope : scope : app=guestbook and rollouts-pod-template-hash={{args.canary-hash}} step : 60 Run Experiment Indefinitely \u00b6 Experiments can run for an indefinite duration by omitting the duration field. Indefinite experiments would be stopped externally, or through the completion of a referenced analysis. Job Metrics \u00b6 A Kubernetes Job can be used to run analysis. When a Job is used, the metric is considered successful if the Job completes and had an exit code of zero, otherwise it is failed. metrics : - name : test provider : job : spec : template : backoffLimit : 1 spec : containers : - name : test image : my-image:latest command : [ my-test-script , my-service.default.svc.cluster.local ] restartPolicy : Never Wavefront Metrics \u00b6 A Wavefront query can be used to obtain measurements for analysis. apiVersion : argoproj.io/v1alpha1 kind : AnalysisTemplate metadata : name : success-rate spec : args : - name : service-name metrics : - name : success-rate interval : 5m successCondition : result >= 0.95 failureLimit : 3 provider : wavefront : address : example.wavefront.com query : | sum(rate( 5m, ts(\"istio.requestcount.count\", response_code!=500 and destination_service=\"{{args.service-name}}\" ))) / sum(rate( 5m, ts(\"istio.requestcount.count\", reporter=client and destination_service=\"{{args.service-name}}\" ))) Wavefront api tokens can be configured in a kubernetes secret in argo-rollouts namespace. apiVersion : v1 kind : Secret metadata : name : wavefront-api-tokens type : Opaque data : example1.wavefront.com : <token1> example2.wavefront.com : <token2> Web Metrics \u00b6 A webhook can be used to call out to some external service to obtain the measurement. This example makes a HTTP GET request to some URL. The webhook response must return JSON content. The result of the optional jsonPath expression will be assigned to the result variable that can be referenced in the successCondition and failureCondition expressions. If omitted, will use the entire body of the as the result variable. metrics : - name : webmetric successCondition : result == 'true' provider : web : url : \"http://my-server.com/api/v1/measurement?service={{ args.service-name }}\" timeoutSeconds : 20 # defaults to 10 seconds headers : - key : Authorization value : \"Bearer {{ args.api-token }}\" jsonPath : \"{$.results.ok}\" In the following example, given the payload, the measurement will be Successful if the data.ok field was true , and the data.successPercent was greater than 0.90 { \"data\" : { \"ok\" : true , \"successPercent\" : 0.95 } } metrics : - name : webmetric successCondition : \"result.ok && result.successPercent >= 0.90\" provider : web : url : \"http://my-server.com/api/v1/measurement?service={{ args.service-name }}\" headers : - key : Authorization value : \"Bearer {{ args.api-token }}\" jsonPath : \"{$.data}\" NOTE: if the result is a string, two convenience functions asInt and asFloat are provided to convert a result value to a numeric type so that mathematical comparison operators can be used (e.g. >, <, >=, <=). Datadog Metrics \u00b6 A Datadog query can be used to obtain measurements for analysis. apiVersion : argoproj.io/v1alpha1 kind : AnalysisTemplate metadata : name : loq-error-rate spec : args : - name : service-name metrics : - name : error-rate interval : 5m successCondition : result <= 0.01 failureLimit : 3 provider : datadog : interval : 5m query : | sum:requests.error.count{service:{{args.service-name}}} / sum:requests.request.count{service:{{args.service-name}}} Datadog api and app tokens can be configured in a kubernetes secret in argo-rollouts namespace. apiVersion : v1 kind : Secret metadata : name : datadog type : Opaque data : address : https://api.datadoghq.com api-key : <datadog-api-key> app-key : <datadog-app-key>","title":"Analysis"},{"location":"features/analysis/#analysis-progressive-delivery","text":"Argo Rollouts provides several ways to perform analysis to drive progressive delivery. This document describes how to achieve various forms of progressive delivery, varying the point in time analysis is performed, it's frequency, and occurrence.","title":"Analysis &amp; Progressive Delivery"},{"location":"features/analysis/#custom-resource-definitions","text":"CRD Description Rollout A Rollout acts as a drop-in replacement for a Deployment resource. It provides additional blueGreen and canary update strategies. These strategies can create AnalysisRuns and Experiments during the update, which will progress the update, or abort it. AnalysisTemplate An AnalysisTemplate is a template spec which defines how to perform a canary analysis, such as the metrics which it should perform, its frequency, and the values which are considered successful or failed. AnalysisTemplates may be parameterized with inputs values. ClusterAnalysisTemplate A ClusterAnalysisTemplate is like an AnalysisTemplate , but it is not limited to its namespace. It can be used by any Rollout throughout the cluster. AnalysisRun An AnalysisRun is an instantiation of an AnalysisTemplate . AnalysisRuns are like Jobs in that they eventually complete. Completed runs are considered Successful, Failed, or Inconclusive, and the result of the run affect if the Rollout's update will continue, abort, or pause, respectively. Experiment An Experiment is limited run of one or more ReplicaSets for the purposes of analysis. Experiments typically run for a pre-determined duration, but can also run indefinitely until stopped. Experiments may reference an AnalysisTemplate to run during or after the experiment. The canonical use case for an Experiment is to start a baseline and canary deployment in parallel, and compare the metrics produced by the baseline and canary pods for an equal comparison.","title":"Custom Resource Definitions"},{"location":"features/analysis/#background-analysis","text":"Analysis can be run in the background -- while the canary is progressing through its rollout steps. The following example gradually increments the canary weight by 20% every 10 minutes until it reaches 100%. In the background, an AnalysisRun is started based on the AnalysisTemplate named success-rate . The success-rate template queries a prometheus server, measuring the HTTP success rates at 5 minute intervals/samples. It has no end time, and continues until stopped or failed. If the metric is measured to be less than 95%, and there are three such measurements, the analysis is considered Failed. The failed analysis causes the Rollout to abort, setting the canary weight back to zero, and the Rollout would be considered in a Degraded . Otherwise, if the rollout completes all of its canary steps, the rollout is considered successful and the analysis run is stopped by the controller. This example highlights: Background analysis style of progressive delivery Using a Prometheus query to perform a measurement The ability to parameterize the analysis Delay starting the analysis run until step 3 (Set Weight 40%) Rollout apiVersion : argoproj.io/v1alpha1 kind : Rollout metadata : name : guestbook spec : ... strategy : canary : analysis : templates : - templateName : success-rate startingStep : 2 # delay starting analysis run until setWeight: 40% args : - name : service-name value : guestbook-svc.default.svc.cluster.local steps : - setWeight : 20 - pause : { duration : 10m } - setWeight : 40 - pause : { duration : 10m } - setWeight : 60 - pause : { duration : 10m } - setWeight : 80 - pause : { duration : 10m } AnalysisTemplate apiVersion : argoproj.io/v1alpha1 kind : AnalysisTemplate metadata : name : success-rate spec : args : - name : service-name metrics : - name : success-rate interval : 5m # NOTE: prometheus queries return results in the form of a vector. # So it is common to access the index 0 of the returned array to obtain the value successCondition : result[0] >= 0.95 failureLimit : 3 provider : prometheus : address : http://prometheus.example.com:9090 query : | sum(irate( istio_requests_total{reporter=\"source\",destination_service=~\"{{args.service-name}}\",response_code!~\"5.*\"}[5m] )) / sum(irate( istio_requests_total{reporter=\"source\",destination_service=~\"{{args.service-name}}\"}[5m] ))","title":"Background Analysis"},{"location":"features/analysis/#inline-analysis","text":"Analysis can also be performed as a rollout step as an inline \"analysis\" step. When analysis is performed \"inlined,\" an AnalysisRun is started when the step is reached, and blocks the rollout until the run is completed. The success or failure of the analysis run decides if the rollout will proceed to the next step, or abort the rollout completely. This example sets the canary weight to 20%, pauses for 5 minutes, then runs an analysis. If the analysis was successful, continues with rollout, otherwise aborts. This example demonstrates: The ability to invoke an analysis in-line as part of steps apiVersion : argoproj.io/v1alpha1 kind : Rollout metadata : name : guestbook spec : ... strategy : canary : steps : - setWeight : 20 - pause : { duration : 5m } - analysis : templates : - templateName : success-rate args : - name : service-name value : guestbook-svc.default.svc.cluster.local In this example, the AnalysisTemplate is identical to the background analysis example, but since no interval is specified, the analysis will perform a single measurement and complete. apiVersion : argoproj.io/v1alpha1 kind : AnalysisTemplate metadata : name : success-rate spec : args : - name : service-name - name : prometheus-port value : 9090 metrics : - name : success-rate successCondition : result[0] >= 0.95 provider : prometheus : address : \"http://prometheus.example.com:{{args.prometheus-port}}\" query : | sum(irate( istio_requests_total{reporter=\"source\",destination_service=~\"{{args.service-name}}\",response_code!~\"5.*\"}[5m] )) / sum(irate( istio_requests_total{reporter=\"source\",destination_service=~\"{{args.service-name}}\"}[5m] )) Multiple measurements can be performed over a longer duration period, by specifying the count and interval fields: metrics : - name : success-rate successCondition : result[0] >= 0.95 interval : 60s count : 5 provider : prometheus : address : http://prometheus.example.com:9090 query : ...","title":"Inline Analysis"},{"location":"features/analysis/#clusteranalysistemplates","text":"Important Available since v0.9.0 A Rollout can reference a Cluster scoped AnalysisTemplate called a ClusterAnalysisTemplate . This can be useful when you want to share an AnalysisTemplate across multiple Rollouts; in different namespaces, and avoid duplicating the same template in every namespace. Use the field clusterScope: true to reference a ClusterAnalysisTemplate instead of an AnalysisTemplate. Rollout apiVersion : argoproj.io/v1alpha1 kind : Rollout metadata : name : guestbook spec : ... strategy : canary : steps : - setWeight : 20 - pause : { duration : 5m } - analysis : templates : - templateName : success-rate clusterScope : true args : - name : service-name value : guestbook-svc.default.svc.cluster.local ClusterAnalysisTemplate apiVersion : argoproj.io/v1alpha1 kind : ClusterAnalysisTemplate metadata : name : success-rate spec : args : - name : service-name - name : prometheus-port value : 9090 metrics : - name : success-rate successCondition : result[0] >= 0.95 provider : prometheus : address : \"http://prometheus.example.com:{{args.prometheus-port}}\" query : | sum(irate( istio_requests_total{reporter=\"source\",destination_service=~\"{{args.service-name}}\",response_code!~\"5.*\"}[5m] )) / sum(irate( istio_requests_total{reporter=\"source\",destination_service=~\"{{args.service-name}}\"}[5m] )) Note The resulting AnalysisRun will still run in the namespace of the Rollout","title":"ClusterAnalysisTemplates"},{"location":"features/analysis/#analysis-with-multiple-templates","text":"A Rollout can reference multiple AnalysisTemplates when constructing an AnalysisRun. This allows users to compose analysis from multiple AnalysisTemplates. If multiple templates are referenced, then the controller will merge the templates together. The controller combines the metrics and args fields of all the templates. Rollout apiVersion : argoproj.io/v1alpha1 kind : Rollout metadata : name : guestbook spec : ... strategy : canary : analysis : templates : - templateName : success-rate - templateName : error-rate args : - name : service-name value : guestbook-svc.default.svc.cluster.local AnalysisTemplate apiVersion : argoproj.io/v1alpha1 kind : AnalysisTemplate metadata : name : success-rate spec : args : - name : service-name metrics : - name : success-rate interval : 5m successCondition : result[0] >= 0.95 failureLimit : 3 provider : prometheus : address : http://prometheus.example.com:9090 query : | sum(irate( istio_requests_total{reporter=\"source\",destination_service=~\"{{args.service-name}}\",response_code!~\"5.*\"}[5m] )) / sum(irate( istio_requests_total{reporter=\"source\",destination_service=~\"{{args.service-name}}\"}[5m] )) --- apiVersion : argoproj.io/v1alpha1 kind : AnalysisTemplate metadata : name : error-rate spec : args : - name : service-name metrics : - name : error-rate interval : 5m successCondition : result[0] <= 0.95 failureLimit : 3 provider : prometheus : address : http://prometheus.example.com:9090 query : | sum(irate( istio_requests_total{reporter=\"source\",destination_service=~\"{{args.service-name}}\",response_code=~\"5.*\"}[5m] )) / sum(irate( istio_requests_total{reporter=\"source\",destination_service=~\"{{args.service-name}}\"}[5m] )) AnalysisRun # NOTE: Generated AnalysisRun from the multiple templates apiVersion : argoproj.io/v1alpha1 kind : AnalysisRun metadata : name : guestbook-CurrentPodHash-multiple-templates spec : args : - name : service-name value : guestbook-svc.default.svc.cluster.local metrics : - name : success-rate interval : 5m successCondition : result[0] >= 0.95 failureLimit : 3 provider : prometheus : address : http://prometheus.example.com:9090 query : | sum(irate( istio_requests_total{reporter=\"source\",destination_service=~\"{{args.service-name}}\",response_code!~\"5.*\"}[5m] )) / sum(irate( istio_requests_total{reporter=\"source\",destination_service=~\"{{args.service-name}}\"}[5m] )) - name : error-rate interval : 5m successCondition : result[0] <= 0.95 failureLimit : 3 provider : prometheus : address : http://prometheus.example.com:9090 query : | sum(irate( istio_requests_total{reporter=\"source\",destination_service=~\"{{args.service-name}}\",response_code=~\"5.*\"}[5m] )) / sum(irate( istio_requests_total{reporter=\"source\",destination_service=~\"{{args.service-name}}\"}[5m] )) Note The controller will error when merging the templates if: Multiple metrics in the templates have the same name Two arguments with the same name both have values","title":"Analysis with Multiple Templates"},{"location":"features/analysis/#analysis-template-arguments","text":"AnalysisTemplates may declare a set of arguments that can be passed by Rollouts. The args can then be used as in metrics configuration and are resolved at the time the AnalysisRun is created. Argument placeholders are defined as {{ args.<name> }} . apiVersion : argoproj.io/v1alpha1 kind : AnalysisTemplate metadata : name : args-example spec : args : # required - name : service-name - name : stable-hash - name : latest-hash # optional - name : api-url value : http://example/measure # from secret - name : api-token valueFrom : secretKeyRef : name : token-secret key : apiToken metrics : - name : webmetric successCondition : result == 'true' provider : web : # placeholders are resolved when an AnalysisRun is created url : \"{{ args.api-url }}?service={{ args.service-name }}\" headers : - key : Authorization value : \"Bearer {{ args.api-token }}\" jsonPath : \"{$.results.ok}\" Analysis arguments defined in a Rollout are merged with the args from the AnalysisTemplate when the AnalysisRun is created. apiVersion : argoproj.io/v1alpha1 kind : Rollout metadata : name : guestbook spec : ... strategy : canary : analysis : templates : - templateName : args-example args : # required value - name : service-name value : guestbook-svc.default.svc.cluster.local # override default value - name : api-url value : http://other-api # pod template hash from the stable ReplicaSet - name : stable-hash valueFrom : podTemplateHashValue : Stable # pod template hash from the latest ReplicaSet - name : latest-hash valueFrom : podTemplateHashValue : Latest","title":"Analysis Template Arguments"},{"location":"features/analysis/#bluegreen-pre-promotion-analysis","text":"A Rollout using the BlueGreen strategy can launch an AnalysisRun before it switches traffic to the new version. The AnalysisRun can be used to block the Service selector switch until the AnalysisRun finishes successful. The success or failure of the analysis run decides if the Rollout will switch traffic, or abort the Rollout completely. apiVersion : argoproj.io/v1alpha1 kind : Rollout metadata : name : guestbook spec : ... strategy : blueGreen : activeService : active-svc previewService : preview-svc prePromotionAnalysis : templates : - templateName : smoke-tests args : - name : service-name value : preview-svc.default.svc.cluster.local In this example, the Rollout is creating a AnalysisRun once the new version has all the pods available. The Rollout will not switch traffic to the new version until the analysis run finishes successfully. Note: if the autoPromotionSeconds field is specified and the Rollout has waited auto promotion seconds amount of time, the Rollout marks the AnalysisRun successful and switches the traffic to a new version automatically. If the AnalysisRun completes before then, the Rollout will not create another AnalysisRun and wait out the rest of the autoPromotionSeconds .","title":"BlueGreen Pre Promotion Analysis"},{"location":"features/analysis/#bluegreen-post-promotion-analysis","text":"A Rollout using a BlueGreen strategy can launch an analysis run after the traffic switch to new version. If the analysis run fails or errors out, the Rollout enters an aborted state and switch traffic back to the previous stable Replicaset. If scaleDownDelaySeconds is specified, the controller will cancel any AnalysisRuns at time of scaleDownDelay to scale down the ReplicaSet. If it is omitted, and post analysis is specified, it will scale down the ReplicaSet only after the AnalysisRun completes (with a minimum of 30 seconds). apiVersion : argoproj.io/v1alpha1 kind : Rollout metadata : name : guestbook spec : ... strategy : blueGreen : activeService : active-svc previewService : preview-svc scaleDownDelaySeconds : 600 # 10 minutes postPromotionAnalysis : templates : - templateName : smoke-tests args : - name : service-name value : preview-svc.default.svc.cluster.local","title":"BlueGreen Post Promotion Analysis"},{"location":"features/analysis/#failure-conditions","text":"failureCondition can be used to cause an analysis run to fail. The following example continually polls a prometheus server to get the total number of errors every 5 minutes, causing the analysis run to fail if 10 or more errors were encountered. metrics : - name : total-errors interval : 5m failureCondition : result[0] >= 10 failureLimit : 3 provider : prometheus : address : http://prometheus.example.com:9090 query : | sum(irate( istio_requests_total{reporter=\"source\",destination_service=~\"{{args.service-name}}\",response_code~\"5.*\"}[5m] ))","title":"Failure Conditions"},{"location":"features/analysis/#inconclusive-runs","text":"Analysis runs can also be considered Inconclusive , which indicates the run was neither successful, nor failed. Inconclusive runs causes a rollout to become paused at its current step. Manual intervention is then needed to either resume the rollout, or abort. One example of how analysis runs could become Inconclusive , is when a metric defines no success or failure conditions. metrics : - name : my-query provider : prometheus : address : http://prometheus.example.com:9090 query : ... Inconclusive analysis runs might also happen when both success and failure conditions are specified, but the measurement value did not meet either condition. metrics : - name : success-rate successCondition : result[0] >= 0.90 failureCondition : result[0] < 0.50 provider : prometheus : address : http://prometheus.example.com:9090 query : ... A use case for having Inconclusive analysis runs are to enable Argo Rollouts to automate the execution of analysis runs, and collect the measurement, but still allow human judgement to decide whether or not measurement value is acceptable and decide to proceed or abort.","title":"Inconclusive Runs"},{"location":"features/analysis/#delay-analysis-runs","text":"If the analysis run does not need to start immediately (i.e give the metric provider time to collect metrics on the canary version), Analysis Runs can delay the specific metric analysis. Each metric can be configured to have a different delay. In additional to the metric specific delays, the rollouts with background analysis can delay creating an analysis run until a certain step is reached Delaying a specific analysis metric: metrics : - name : success-rate # Do not start this analysis until 5 minutes after the analysis run starts initialDelay : 5m successCondition : result[0] >= 0.90 provider : prometheus : address : http://prometheus.example.com:9090 query : ... Delaying starting background analysis run until step 3 (Set Weight 40%): apiVersion : argoproj.io/v1alpha1 kind : Rollout metadata : name : guestbook spec : strategy : canary : analysis : templates : - templateName : success-rate startingStep : 2 steps : - setWeight : 20 - pause : { duration : 10m } - setWeight : 40 - pause : { duration : 10m }","title":"Delay Analysis Runs"},{"location":"features/analysis/#referencing-secrets","text":"AnalysisTemplates and AnalysisRuns can reference secret objects in .spec.args . This allows users to securely pass authentication information to Metric Providers, like login credentials or API tokens. An AnalysisRun can only reference secrets from the same namespace as it's running in. This is only relevant for AnalysisRuns, since AnalysisTemplates do not resolve the secret. In the following example, an AnalysisTemplate references an API token and passes it to a Web metric provider. This example demonstrates: The ability to reference a secret in the AnalysisTemplate .spec.args The ability to pass secret arguments to Metric Providers apiVersion : argoproj.io/v1alpha1 kind : AnalysisTemplate spec : args : - name : api-token valueFrom : secretKeyRef : name : token-secret key : apiToken metrics : - name : webmetric provider : web : headers : - key : Authorization value : \"Bearer {{ args.api-token }}\"","title":"Referencing Secrets"},{"location":"features/analysis/#experimentation-eg-mann-whitney-analysis","text":"Analysis can also be done as part of an Experiment. This example starts both a canary and baseline ReplicaSet. The ReplicaSets run for 1 hour, then scale down to zero. Call out to Kayenta to perform Mann-Whintney analysis against the two pods. Demonstrates ability to start a short-lived experiment and an asynchronous analysis. This example demonstrates: The ability to start an Experiment as part of rollout steps, which launches multiple ReplicaSets (e.g. baseline & canary) The ability to reference and supply pod-template-hash to an AnalysisRun Kayenta metrics Rollout apiVersion : argoproj.io/v1alpha1 kind : Rollout metadata : name : guestbook labels : app : guestbook spec : strategy : canary : steps : - experiment : duration : 1h templates : - name : baseline specRef : stable - name : canary specRef : canary analysis : templateName : mann-whitney args : - name : stable-hash valueFrom : podTemplateHashValue : Stable - name : canary-hash valueFrom : podTemplateHashValue : Latest AnalysisTemplate apiVersion : argoproj.io/v1alpha1 kind : AnalysisTemplate metadata : name : mann-whitney spec : args : - name : start-time - name : end-time - name : stable-hash - name : canary-hash metrics : - name : mann-whitney provider : kayenta : address : https://kayenta.example.com application : guestbook canaryConfigName : my-test thresholds : pass : 90 marginal : 75 scopes : - name : default controlScope : scope : app=guestbook and rollouts-pod-template-hash={{args.stable-hash}} step : 60 start : \"{{args.start-time}}\" end : \"{{args.end-time}}\" experimentScope : scope : app=guestbook and rollouts-pod-template-hash={{args.canary-hash}} step : 60 start : \"{{args.start-time}}\" end : \"{{args.end-time}}\" Experiment apiVersion : argoproj.io/v1alpha1 kind : Experiment name : name : guestbook-6c54544bf9-0 spec : duration : 1h templates : - name : baseline replicas : 1 spec : containers : - name : guestbook image : guestbook:v1 - name : canary replicas : 1 spec : containers : - name : guestbook image : guestbook:v2 analysis : templateName : mann-whitney args : - name : start-time value : \"{{experiment.availableAt}}\" - name : end-time value : \"{{experiment.finishedAt}}\" In order to perform multiple kayenta runs over some time duration, the interval and count fields can be supplied. When the start and end fields are omitted from the kayenta scopes, the values will be implicitly decided as: start = if lookback: true start of analysis, otherwise current time - interval end = current time apiVersion : argoproj.io/v1alpha1 kind : AnalysisTemplate metadata : name : mann-whitney spec : args : - name : stable-hash - name : canary-hash metrics : - name : mann-whitney provider : kayenta : address : https://kayenta.intuit.com application : guestbook canaryConfigName : my-test interval : 3600 count : 3 # loopback will cause start time value to be equal to start of analysis # lookback: true thresholds : pass : 90 marginal : 75 scopes : - name : default controlScope : scope : app=guestbook and rollouts-pod-template-hash={{args.stable-hash}} step : 60 experimentScope : scope : app=guestbook and rollouts-pod-template-hash={{args.canary-hash}} step : 60","title":"Experimentation (e.g. Mann-Whitney Analysis)"},{"location":"features/analysis/#run-experiment-indefinitely","text":"Experiments can run for an indefinite duration by omitting the duration field. Indefinite experiments would be stopped externally, or through the completion of a referenced analysis.","title":"Run Experiment Indefinitely"},{"location":"features/analysis/#job-metrics","text":"A Kubernetes Job can be used to run analysis. When a Job is used, the metric is considered successful if the Job completes and had an exit code of zero, otherwise it is failed. metrics : - name : test provider : job : spec : template : backoffLimit : 1 spec : containers : - name : test image : my-image:latest command : [ my-test-script , my-service.default.svc.cluster.local ] restartPolicy : Never","title":"Job Metrics"},{"location":"features/analysis/#wavefront-metrics","text":"A Wavefront query can be used to obtain measurements for analysis. apiVersion : argoproj.io/v1alpha1 kind : AnalysisTemplate metadata : name : success-rate spec : args : - name : service-name metrics : - name : success-rate interval : 5m successCondition : result >= 0.95 failureLimit : 3 provider : wavefront : address : example.wavefront.com query : | sum(rate( 5m, ts(\"istio.requestcount.count\", response_code!=500 and destination_service=\"{{args.service-name}}\" ))) / sum(rate( 5m, ts(\"istio.requestcount.count\", reporter=client and destination_service=\"{{args.service-name}}\" ))) Wavefront api tokens can be configured in a kubernetes secret in argo-rollouts namespace. apiVersion : v1 kind : Secret metadata : name : wavefront-api-tokens type : Opaque data : example1.wavefront.com : <token1> example2.wavefront.com : <token2>","title":"Wavefront Metrics"},{"location":"features/analysis/#web-metrics","text":"A webhook can be used to call out to some external service to obtain the measurement. This example makes a HTTP GET request to some URL. The webhook response must return JSON content. The result of the optional jsonPath expression will be assigned to the result variable that can be referenced in the successCondition and failureCondition expressions. If omitted, will use the entire body of the as the result variable. metrics : - name : webmetric successCondition : result == 'true' provider : web : url : \"http://my-server.com/api/v1/measurement?service={{ args.service-name }}\" timeoutSeconds : 20 # defaults to 10 seconds headers : - key : Authorization value : \"Bearer {{ args.api-token }}\" jsonPath : \"{$.results.ok}\" In the following example, given the payload, the measurement will be Successful if the data.ok field was true , and the data.successPercent was greater than 0.90 { \"data\" : { \"ok\" : true , \"successPercent\" : 0.95 } } metrics : - name : webmetric successCondition : \"result.ok && result.successPercent >= 0.90\" provider : web : url : \"http://my-server.com/api/v1/measurement?service={{ args.service-name }}\" headers : - key : Authorization value : \"Bearer {{ args.api-token }}\" jsonPath : \"{$.data}\" NOTE: if the result is a string, two convenience functions asInt and asFloat are provided to convert a result value to a numeric type so that mathematical comparison operators can be used (e.g. >, <, >=, <=).","title":"Web Metrics"},{"location":"features/analysis/#datadog-metrics","text":"A Datadog query can be used to obtain measurements for analysis. apiVersion : argoproj.io/v1alpha1 kind : AnalysisTemplate metadata : name : loq-error-rate spec : args : - name : service-name metrics : - name : error-rate interval : 5m successCondition : result <= 0.01 failureLimit : 3 provider : datadog : interval : 5m query : | sum:requests.error.count{service:{{args.service-name}}} / sum:requests.request.count{service:{{args.service-name}}} Datadog api and app tokens can be configured in a kubernetes secret in argo-rollouts namespace. apiVersion : v1 kind : Secret metadata : name : datadog type : Opaque data : address : https://api.datadoghq.com api-key : <datadog-api-key> app-key : <datadog-app-key>","title":"Datadog Metrics"},{"location":"features/bluegreen/","text":"BlueGreen Deployment Strategy \u00b6 A Blue Green Deployment allows users to reduce the amount of time multiple versions running at the same time. Overview \u00b6 In addition to managing ReplicaSets, the rollout controller will modify a Service resource during the BlueGreenUpdate strategy. The Rollout spec has users specify a reference to active service and optionally a preview service in the same namespace. The active Service is used to send regular application traffic to the old version, while the preview Service is used as funnel traffic to the new version. The rollout controller ensures proper traffic routing by injecting a unique hash of the ReplicaSet to these services' selectors. This allows the rollout to define an active and preview stack and a process to migrate replica sets from the preview to the active. When there is a change to the .spec.template field of a rollout, the controller will create the new ReplicaSet. If the active service is not sending traffic to a ReplicaSet, the controller will immediately start sending traffic to the ReplicaSet. Otherwise, the active service will point at the old ReplicaSet while the ReplicaSet becomes available. Once the new ReplicaSet becomes available, the controller will modify the active service to point at the new ReplicaSet. After waiting some time configured by the .spec.strategy.blueGreen.scaleDownDelaySeconds , the controller will scale down the old ReplicaSet. Important When the rollout changes the selector on a service, there is a propagation delay before all the nodes update their IP tables to send traffic to the new pods instead of the old. During this delay, traffic will be directed to the old pods if the nodes have not been updated yet. In order to prevent the packets from being sent to a node that killed the old pod, the rollout uses the scaleDownDelaySeconds field to give nodes enough time to broadcast the IP table changes. Example \u00b6 apiVersion : argoproj.io/v1alpha1 kind : Rollout metadata : name : rollout-bluegreen spec : replicas : 2 revisionHistoryLimit : 2 selector : matchLabels : app : rollout-bluegreen template : metadata : labels : app : rollout-bluegreen spec : containers : - name : rollouts-demo image : argoproj/rollouts-demo:blue imagePullPolicy : Always ports : - containerPort : 8080 strategy : blueGreen : # activeService specifies the service to update with the new template hash at time of promotion. # This field is mandatory for the blueGreen update strategy. activeService : rollout-bluegreen-active # previewService specifies the service to update with the new template hash before promotion. # This allows the preview stack to be reachable without serving production traffic. # This field is optional. previewService : rollout-bluegreen-preview # autoPromotionEnabled disables automated promotion of the new stack by pausing the rollout # immediately before the promotion. If omitted, the default behavior is to promote the new # stack as soon as the ReplicaSet are completely ready/available. # Rollouts can be resumed using: `kubectl argo rollouts resume ROLLOUT` autoPromotionEnabled : false Configurable Features \u00b6 Here are the optional fields that will change the behavior of BlueGreen deployment: spec : strategy : blueGreen : autoPromotionEnabled : boolean autoPromotionSeconds : *int32 antiAffinity : object previewService : string prePromotionAnalysis : object postPromotionAnalysis : object previewReplicaCount : *int32 scaleDownDelaySeconds : *int32 scaleDownDelayRevisionLimit : *int32 autoPromotionEnabled \u00b6 The AutoPromotionEnabled will make the rollout automatically promote the new ReplicaSet to the active service once the new ReplicaSet is healthy. This field is defaulted to true if it is not specified. Defaults to true autoPromotionSeconds \u00b6 The AutoPromotionSeconds will make the rollout automatically promote the new ReplicaSet to active Service after the AutoPromotionSeconds time has passed since the rollout has entered a paused state. If the AutoPromotionEnabled field is set to true, this field will be ignored Defaults to nil antiAffinity \u00b6 Check out the Anti Affinity document document for more information. Defaults to nil prePromotionAnalysis \u00b6 Configures the Analysis before it switches traffic to the new version. The AnalysisRun can be used to block the Service selector switch until the AnalysisRun finishes successful. The success or failure of the analysis run decides if the Rollout will switch traffic, or abort the Rollout completely. Defaults to nil postPromotionAnalysis \u00b6 Configures the Analysis after the traffic switch to new version. If the analysis run fails or errors out, the Rollout enters an aborted state and switch traffic back to the previous stable Replicaset. If scaleDownDelaySeconds is specified, the controller will cancel any AnalysisRuns at time of scaleDownDelay to scale down the ReplicaSet. If it is omitted, and post analysis is specified, it will scale down the ReplicaSet only after the AnalysisRun completes (with a minimum of 30 seconds). Defaults to nil previewService \u00b6 The PreviewService field references a Service that will be modified to send traffic to the new replicaset before the new one is promoted to receiving traffic from the active service. Once the new replicaset start receives traffic from the active service, the preview service will be modified to send traffic to no ReplicaSets. The Rollout always makes sure that the preview service is sending traffic to the new ReplicaSet. As a result, if a new version is introduced before the old version is promoted to the active service, the controller will immediately switch over to the new version. This feature is used to provide an endpoint that can be used to test a new version of an application. Defaults to an empty string previewReplicaCount \u00b6 The PreviewReplicaCount will indicate the number of replicas that the new version of an application should run. Once the application is ready to promote to the active service, the controller will scale the new ReplicaSet to the value of the spec.replicas . The rollout will not switch over the active service to the new ReplicaSet until it matches the spec.replicas count. This feature is mainly used to save resources during the testing phase. If the application does not need a fully scaled up application for the tests, this feature can help save some resources. Defaults to nil scaleDownDelaySeconds \u00b6 The ScaleDownDelaySeconds is used to delay scaling down the old ReplicaSet after the active Service is switched to the new ReplicaSet. Defaults to 30 scaleDownDelayRevisionLimit \u00b6 The ScaleDownDelayRevisionLimit limits the number of old active ReplicaSets to keep scaled up while they wait for the scaleDownDelay to pass after being removed from the active service. Defaults to nil","title":"BlueGreen"},{"location":"features/bluegreen/#bluegreen-deployment-strategy","text":"A Blue Green Deployment allows users to reduce the amount of time multiple versions running at the same time.","title":"BlueGreen Deployment Strategy"},{"location":"features/bluegreen/#overview","text":"In addition to managing ReplicaSets, the rollout controller will modify a Service resource during the BlueGreenUpdate strategy. The Rollout spec has users specify a reference to active service and optionally a preview service in the same namespace. The active Service is used to send regular application traffic to the old version, while the preview Service is used as funnel traffic to the new version. The rollout controller ensures proper traffic routing by injecting a unique hash of the ReplicaSet to these services' selectors. This allows the rollout to define an active and preview stack and a process to migrate replica sets from the preview to the active. When there is a change to the .spec.template field of a rollout, the controller will create the new ReplicaSet. If the active service is not sending traffic to a ReplicaSet, the controller will immediately start sending traffic to the ReplicaSet. Otherwise, the active service will point at the old ReplicaSet while the ReplicaSet becomes available. Once the new ReplicaSet becomes available, the controller will modify the active service to point at the new ReplicaSet. After waiting some time configured by the .spec.strategy.blueGreen.scaleDownDelaySeconds , the controller will scale down the old ReplicaSet. Important When the rollout changes the selector on a service, there is a propagation delay before all the nodes update their IP tables to send traffic to the new pods instead of the old. During this delay, traffic will be directed to the old pods if the nodes have not been updated yet. In order to prevent the packets from being sent to a node that killed the old pod, the rollout uses the scaleDownDelaySeconds field to give nodes enough time to broadcast the IP table changes.","title":"Overview"},{"location":"features/bluegreen/#example","text":"apiVersion : argoproj.io/v1alpha1 kind : Rollout metadata : name : rollout-bluegreen spec : replicas : 2 revisionHistoryLimit : 2 selector : matchLabels : app : rollout-bluegreen template : metadata : labels : app : rollout-bluegreen spec : containers : - name : rollouts-demo image : argoproj/rollouts-demo:blue imagePullPolicy : Always ports : - containerPort : 8080 strategy : blueGreen : # activeService specifies the service to update with the new template hash at time of promotion. # This field is mandatory for the blueGreen update strategy. activeService : rollout-bluegreen-active # previewService specifies the service to update with the new template hash before promotion. # This allows the preview stack to be reachable without serving production traffic. # This field is optional. previewService : rollout-bluegreen-preview # autoPromotionEnabled disables automated promotion of the new stack by pausing the rollout # immediately before the promotion. If omitted, the default behavior is to promote the new # stack as soon as the ReplicaSet are completely ready/available. # Rollouts can be resumed using: `kubectl argo rollouts resume ROLLOUT` autoPromotionEnabled : false","title":"Example"},{"location":"features/bluegreen/#configurable-features","text":"Here are the optional fields that will change the behavior of BlueGreen deployment: spec : strategy : blueGreen : autoPromotionEnabled : boolean autoPromotionSeconds : *int32 antiAffinity : object previewService : string prePromotionAnalysis : object postPromotionAnalysis : object previewReplicaCount : *int32 scaleDownDelaySeconds : *int32 scaleDownDelayRevisionLimit : *int32","title":"Configurable Features"},{"location":"features/bluegreen/#autopromotionenabled","text":"The AutoPromotionEnabled will make the rollout automatically promote the new ReplicaSet to the active service once the new ReplicaSet is healthy. This field is defaulted to true if it is not specified. Defaults to true","title":"autoPromotionEnabled"},{"location":"features/bluegreen/#autopromotionseconds","text":"The AutoPromotionSeconds will make the rollout automatically promote the new ReplicaSet to active Service after the AutoPromotionSeconds time has passed since the rollout has entered a paused state. If the AutoPromotionEnabled field is set to true, this field will be ignored Defaults to nil","title":"autoPromotionSeconds"},{"location":"features/bluegreen/#antiaffinity","text":"Check out the Anti Affinity document document for more information. Defaults to nil","title":"antiAffinity"},{"location":"features/bluegreen/#prepromotionanalysis","text":"Configures the Analysis before it switches traffic to the new version. The AnalysisRun can be used to block the Service selector switch until the AnalysisRun finishes successful. The success or failure of the analysis run decides if the Rollout will switch traffic, or abort the Rollout completely. Defaults to nil","title":"prePromotionAnalysis"},{"location":"features/bluegreen/#postpromotionanalysis","text":"Configures the Analysis after the traffic switch to new version. If the analysis run fails or errors out, the Rollout enters an aborted state and switch traffic back to the previous stable Replicaset. If scaleDownDelaySeconds is specified, the controller will cancel any AnalysisRuns at time of scaleDownDelay to scale down the ReplicaSet. If it is omitted, and post analysis is specified, it will scale down the ReplicaSet only after the AnalysisRun completes (with a minimum of 30 seconds). Defaults to nil","title":"postPromotionAnalysis"},{"location":"features/bluegreen/#previewservice","text":"The PreviewService field references a Service that will be modified to send traffic to the new replicaset before the new one is promoted to receiving traffic from the active service. Once the new replicaset start receives traffic from the active service, the preview service will be modified to send traffic to no ReplicaSets. The Rollout always makes sure that the preview service is sending traffic to the new ReplicaSet. As a result, if a new version is introduced before the old version is promoted to the active service, the controller will immediately switch over to the new version. This feature is used to provide an endpoint that can be used to test a new version of an application. Defaults to an empty string","title":"previewService"},{"location":"features/bluegreen/#previewreplicacount","text":"The PreviewReplicaCount will indicate the number of replicas that the new version of an application should run. Once the application is ready to promote to the active service, the controller will scale the new ReplicaSet to the value of the spec.replicas . The rollout will not switch over the active service to the new ReplicaSet until it matches the spec.replicas count. This feature is mainly used to save resources during the testing phase. If the application does not need a fully scaled up application for the tests, this feature can help save some resources. Defaults to nil","title":"previewReplicaCount"},{"location":"features/bluegreen/#scaledowndelayseconds","text":"The ScaleDownDelaySeconds is used to delay scaling down the old ReplicaSet after the active Service is switched to the new ReplicaSet. Defaults to 30","title":"scaleDownDelaySeconds"},{"location":"features/bluegreen/#scaledowndelayrevisionlimit","text":"The ScaleDownDelayRevisionLimit limits the number of old active ReplicaSets to keep scaled up while they wait for the scaleDownDelay to pass after being removed from the active service. Defaults to nil","title":"scaleDownDelayRevisionLimit"},{"location":"features/canary/","text":"Canary Deployment Strategy \u00b6 A canary rollout is a deployment strategy where the operator releases a new version of their application to a small percentage of the production traffic. Overview \u00b6 Since there is no agreed upon standard for a canary deployment, the rollouts controller allows users to outline how they want to run their canary deployment. Users can define a list of steps the controller uses to manipulate the ReplicaSets where there is a change to the .spec.template . Each step will be evaluated before the new ReplicaSet is promoted to the stable version, and the old version is completely scaled down. Each step can have one of two fields. The setWeight field dictates the percentage of traffic that should be sent to the canary, and the pause struct instructs the rollout to pause. When the controller reaches a pause step for a rollout, it will set adds a PauseCondition struct to the .status.PauseConditions field. If the duration field within the pause struct is set, the rollout will not progress to the next step until it has waited for the value of the duration field. Otherwise, the rollout will wait indefinitely until that Pause condition is removed. By using the setWeight and the pause fields, a user can declarative describe how they want to progress to the new version. Below is an example of a canary strategy. Important If the canary Rollout does not use traffic management , the Rollout makes a best effort attempt to achieve the percentage listed in the last setWeight step between the new and old version. For example, if a Rollout has 10 Replicas and 10% for the first setWeight step, the controller will scale the new desired ReplicaSet to 1 replicas and the old stable ReplicaSet to 9. In the case where the setWeight is 15%, the Rollout attempts to get there by rounding up the calculation (i.e. the new ReplicaSet has 2 pod since 15% * 10 rounds up to 2 and the old ReplicaSet has 9 pod since 85% * 10 rounds up to 9). If a user wants to have more fine-grained control of the percentages without a large number of Replicas, that user should use the traffic management functionality. Example \u00b6 apiVersion : argoproj.io/v1alpha1 kind : Rollout metadata : name : example-rollout spec : replicas : 10 selector : matchLabels : app : nginx template : metadata : labels : app : nginx spec : containers : - name : nginx image : nginx:1.15.4 ports : - containerPort : 80 minReadySeconds : 30 revisionHistoryLimit : 3 strategy : canary : #Indicates that the rollout should use the Canary strategy maxSurge : \"25%\" maxUnavailable : 0 steps : - setWeight : 10 - pause : duration : 1h # 1 hour - setWeight : 20 - pause : {} # pause indefinitely Pause Duration \u00b6 Pause duration can be specified with an optional time unit suffix. Valid time units are \"s\", \"m\", \"h\". Defaults to \"s\" if not specified. Values less than zero are not allowed. spec : strategy : canary : steps : - pause : { duration : 10 } # 10 seconds - pause : { duration : 10s } # 10 seconds - pause : { duration : 10m } # 10 minutes - pause : { duration : 10h } # 10 hours - pause : { duration : -10 } # invalid spec! - pause : {} # pause indefinitely If no duration specified for a pause step the rollout will be paused indefinitely. To unpause use the argo kubectl plugin promote command. # promote to the next step kubectl argo rollouts promote <rollout> Mimicking Rolling Update \u00b6 If the steps field is omitted, the canary strategy will mimic the rolling update behavior. Similar to the deployment, the canary strategy has the maxSurge and maxUnavailable fields to configure how the Rollout should progress to the new version. Other Configurable Features \u00b6 Here are the optional fields that will modify the behavior of canary strategy: spec : strategy : canary : analysis : object antiAffinity : object canaryService : string stableService : string maxSurge : stringOrInt maxUnavailable : stringOrInt trafficRouting : object analysis \u00b6 Configure the background Analysis to execute during the rollout. If the analysis is unsuccessful the rollout will be aborted. Defaults to nil antiAffinity \u00b6 Check out the Anti Affinity document document for more information. Defaults to nil canaryService \u00b6 canaryService references a Service that will be modified to send traffic to only the canary ReplicaSet. This allows users to only hit the canary ReplicaSet. Defaults to an empty string stableService \u00b6 stableService the name of a Service which selects pods with stable version and don't select any pods with canary version. This allows users to only hit the stable ReplicaSet. Defaults to an empty string maxSurge \u00b6 maxSurge defines the maximum number of replicas the rollout can create to move to the correct ratio set by the last setWeight. Max Surge can either be an integer or percentage as a string (i.e. \"20%\") Defaults to \"25%\". maxUnavailable \u00b6 The maximum number of pods that can be unavailable during the update. Value can be an absolute number (ex: 5) or a percentage of desired pods (ex: 10%). This can not be 0 if MaxSurge is 0. Defaults to 0 trafficRouting \u00b6 The traffic management rules to apply to control the flow of traffic between the active and canary versions. If not set, the default weighted pod replica based routing will be used. Defaults to nil","title":"Canary"},{"location":"features/canary/#canary-deployment-strategy","text":"A canary rollout is a deployment strategy where the operator releases a new version of their application to a small percentage of the production traffic.","title":"Canary Deployment Strategy"},{"location":"features/canary/#overview","text":"Since there is no agreed upon standard for a canary deployment, the rollouts controller allows users to outline how they want to run their canary deployment. Users can define a list of steps the controller uses to manipulate the ReplicaSets where there is a change to the .spec.template . Each step will be evaluated before the new ReplicaSet is promoted to the stable version, and the old version is completely scaled down. Each step can have one of two fields. The setWeight field dictates the percentage of traffic that should be sent to the canary, and the pause struct instructs the rollout to pause. When the controller reaches a pause step for a rollout, it will set adds a PauseCondition struct to the .status.PauseConditions field. If the duration field within the pause struct is set, the rollout will not progress to the next step until it has waited for the value of the duration field. Otherwise, the rollout will wait indefinitely until that Pause condition is removed. By using the setWeight and the pause fields, a user can declarative describe how they want to progress to the new version. Below is an example of a canary strategy. Important If the canary Rollout does not use traffic management , the Rollout makes a best effort attempt to achieve the percentage listed in the last setWeight step between the new and old version. For example, if a Rollout has 10 Replicas and 10% for the first setWeight step, the controller will scale the new desired ReplicaSet to 1 replicas and the old stable ReplicaSet to 9. In the case where the setWeight is 15%, the Rollout attempts to get there by rounding up the calculation (i.e. the new ReplicaSet has 2 pod since 15% * 10 rounds up to 2 and the old ReplicaSet has 9 pod since 85% * 10 rounds up to 9). If a user wants to have more fine-grained control of the percentages without a large number of Replicas, that user should use the traffic management functionality.","title":"Overview"},{"location":"features/canary/#example","text":"apiVersion : argoproj.io/v1alpha1 kind : Rollout metadata : name : example-rollout spec : replicas : 10 selector : matchLabels : app : nginx template : metadata : labels : app : nginx spec : containers : - name : nginx image : nginx:1.15.4 ports : - containerPort : 80 minReadySeconds : 30 revisionHistoryLimit : 3 strategy : canary : #Indicates that the rollout should use the Canary strategy maxSurge : \"25%\" maxUnavailable : 0 steps : - setWeight : 10 - pause : duration : 1h # 1 hour - setWeight : 20 - pause : {} # pause indefinitely","title":"Example"},{"location":"features/canary/#pause-duration","text":"Pause duration can be specified with an optional time unit suffix. Valid time units are \"s\", \"m\", \"h\". Defaults to \"s\" if not specified. Values less than zero are not allowed. spec : strategy : canary : steps : - pause : { duration : 10 } # 10 seconds - pause : { duration : 10s } # 10 seconds - pause : { duration : 10m } # 10 minutes - pause : { duration : 10h } # 10 hours - pause : { duration : -10 } # invalid spec! - pause : {} # pause indefinitely If no duration specified for a pause step the rollout will be paused indefinitely. To unpause use the argo kubectl plugin promote command. # promote to the next step kubectl argo rollouts promote <rollout>","title":"Pause Duration"},{"location":"features/canary/#mimicking-rolling-update","text":"If the steps field is omitted, the canary strategy will mimic the rolling update behavior. Similar to the deployment, the canary strategy has the maxSurge and maxUnavailable fields to configure how the Rollout should progress to the new version.","title":"Mimicking Rolling Update"},{"location":"features/canary/#other-configurable-features","text":"Here are the optional fields that will modify the behavior of canary strategy: spec : strategy : canary : analysis : object antiAffinity : object canaryService : string stableService : string maxSurge : stringOrInt maxUnavailable : stringOrInt trafficRouting : object","title":"Other Configurable Features"},{"location":"features/canary/#analysis","text":"Configure the background Analysis to execute during the rollout. If the analysis is unsuccessful the rollout will be aborted. Defaults to nil","title":"analysis"},{"location":"features/canary/#antiaffinity","text":"Check out the Anti Affinity document document for more information. Defaults to nil","title":"antiAffinity"},{"location":"features/canary/#canaryservice","text":"canaryService references a Service that will be modified to send traffic to only the canary ReplicaSet. This allows users to only hit the canary ReplicaSet. Defaults to an empty string","title":"canaryService"},{"location":"features/canary/#stableservice","text":"stableService the name of a Service which selects pods with stable version and don't select any pods with canary version. This allows users to only hit the stable ReplicaSet. Defaults to an empty string","title":"stableService"},{"location":"features/canary/#maxsurge","text":"maxSurge defines the maximum number of replicas the rollout can create to move to the correct ratio set by the last setWeight. Max Surge can either be an integer or percentage as a string (i.e. \"20%\") Defaults to \"25%\".","title":"maxSurge"},{"location":"features/canary/#maxunavailable","text":"The maximum number of pods that can be unavailable during the update. Value can be an absolute number (ex: 5) or a percentage of desired pods (ex: 10%). This can not be 0 if MaxSurge is 0. Defaults to 0","title":"maxUnavailable"},{"location":"features/canary/#trafficrouting","text":"The traffic management rules to apply to control the flow of traffic between the active and canary versions. If not set, the default weighted pod replica based routing will be used. Defaults to nil","title":"trafficRouting"},{"location":"features/controller-metrics/","text":"Controller Metrics \u00b6 The Argo Rollouts controller publishes the following prometheus metrics about Argo Rollout objects. Name Description rollout_created_time Creation time in unix timestamp for an rollout. rollout_info Information about rollout. rollout_info_replicas_available The number of available replicas per rollout. rollout_info_replicas_unavailable The number of unavailable replicas per rollout. rollout_phase Information on the state of the rollout. rollout_reconcile Rollout reconciliation performance. rollout_reconcile_error Error occurring during the rollout. experiment_created_time Creation time in unix timestamp for an experiment. experiment_info Information about Experiment. experiment_phase Information on the state of the experiment. experiment_reconcile Experiments reconciliation performance. experiment_reconcile_error Error occurring during the experiment. analysis_run_created_time Creation time in unix timestamp for an Analysis Run. analysis_run_info Information about analysis run. analysis_run_metric_phase Information on the duration of a specific metric in the Analysis Run. analysis_run_metric_type Information on the type of a specific metric in the Analysis Runs. analysis_run_phase Information on the state of the Analysis Run. analysis_run_reconcile Analysis Run reconciliation performance. analysis_run_reconcile_error Error occurring during the analysis run. The controller also publishes the following Prometheus metrics to describe the controller health. Name Description controller_clientset_k8s_request_total Number of kubernetes requests executed during application reconciliation. workqueue_adds_total Total number of adds handled by workqueue workqueue_depth Current depth of workqueue workqueue_queue_duration_seconds How long in seconds an item stays in workqueue before being requested. workqueue_work_duration_seconds How long in seconds processing an item from workqueue takes. workqueue_unfinished_work_seconds How many seconds of work has done that is in progress and hasn't been observed by work_duration. Large values indicate stuck threads. One can deduce the number of stuck threads by observing the rate at which this increases. workqueue_longest_running_processor_seconds How many seconds has the longest running processor for workqueue been running workqueue_retries_total Total number of retries handled by workqueue In additional, the Argo Rollouts controllers offers metrics on CPU, memory and file descriptor usage as well as the process start time and current Go processes including memory stats.","title":"Controller Metrics"},{"location":"features/controller-metrics/#controller-metrics","text":"The Argo Rollouts controller publishes the following prometheus metrics about Argo Rollout objects. Name Description rollout_created_time Creation time in unix timestamp for an rollout. rollout_info Information about rollout. rollout_info_replicas_available The number of available replicas per rollout. rollout_info_replicas_unavailable The number of unavailable replicas per rollout. rollout_phase Information on the state of the rollout. rollout_reconcile Rollout reconciliation performance. rollout_reconcile_error Error occurring during the rollout. experiment_created_time Creation time in unix timestamp for an experiment. experiment_info Information about Experiment. experiment_phase Information on the state of the experiment. experiment_reconcile Experiments reconciliation performance. experiment_reconcile_error Error occurring during the experiment. analysis_run_created_time Creation time in unix timestamp for an Analysis Run. analysis_run_info Information about analysis run. analysis_run_metric_phase Information on the duration of a specific metric in the Analysis Run. analysis_run_metric_type Information on the type of a specific metric in the Analysis Runs. analysis_run_phase Information on the state of the Analysis Run. analysis_run_reconcile Analysis Run reconciliation performance. analysis_run_reconcile_error Error occurring during the analysis run. The controller also publishes the following Prometheus metrics to describe the controller health. Name Description controller_clientset_k8s_request_total Number of kubernetes requests executed during application reconciliation. workqueue_adds_total Total number of adds handled by workqueue workqueue_depth Current depth of workqueue workqueue_queue_duration_seconds How long in seconds an item stays in workqueue before being requested. workqueue_work_duration_seconds How long in seconds processing an item from workqueue takes. workqueue_unfinished_work_seconds How many seconds of work has done that is in progress and hasn't been observed by work_duration. Large values indicate stuck threads. One can deduce the number of stuck threads by observing the rate at which this increases. workqueue_longest_running_processor_seconds How many seconds has the longest running processor for workqueue been running workqueue_retries_total Total number of retries handled by workqueue In additional, the Argo Rollouts controllers offers metrics on CPU, memory and file descriptor usage as well as the process start time and current Go processes including memory stats.","title":"Controller Metrics"},{"location":"features/experiment/","text":"Experiment CRD \u00b6 What is the Experiment CRD? \u00b6 The Experiment CRD allows users to have ephemeral runs of one or more ReplicaSets. In addition to running ephemeral ReplicaSets, the Experiment CRD can launch AnalysisRuns alongside the ReplicaSets. Generally, those AnalysisRun is used to confirm that new ReplicaSets are running as expected. Use cases of the Experiment CRD \u00b6 A user wants to run two versions of an application for a specific duration to enable Kayenta-style analysis of their application. The Experiment CRD creates 2 ReplicaSets (a baseline and a canary) based on the spec.templates field of the Experiment and waits until both are healthy. After the duration passes, the Experiment scales down the ReplicaSets, and the user can start the Kayenta analysis run. A user can use experiments to enable A/B/C testing by launching multiple experiments with a different version of their application for a long duration. Each Experiment has one PodSpec template that defines a specific version a user would want to run. The Experiment allows users to launch multiple experiments at once and keep each Experiment self-contained. Launching a new version of an existing application with different labels to avoid receiving traffic from a Kubernetes service. The user can run tests against the new version before continuing the Rollout. Experiment Spec \u00b6 Below is an example of an experiment that creates two ReplicaSets with 1 replica each and runs them for 60 seconds once they both become available. Also, the controller launches two AnalysisRuns after the ReplicaSets become available. apiVersion : argoproj.io/v1alpha1 kind : Experiment metadata : name : example-experiment spec : duration : 1m # How long to run the Experiment once the ReplicaSets created from the templates are healthy progressDeadlineSeconds : 30 templates : - name : purple # (required) Unique name for the template that gets used as a part of the ReplicaSet name. replicas : 1 selector : # Same selector that has been as in Deployments and Rollouts matchLabels : app : canary-demo color : purple template : metadata : labels : app : canary-demo color : purple spec : # Same Pod Spec that has been as in Deployments and Rollouts containers : - name : rollouts-demo image : argoproj/rollouts-demo:purple imagePullPolicy : Always ports : - name : http containerPort : 8080 protocol : TCP - name : orange replicas : 1 minReadySeconds : 10 selector : # Same selector that has been as in Deployments and Rollouts matchLabels : app : canary-demo color : orange template : metadata : labels : app : canary-demo color : orange spec : # Same Pod Spec that has been as in Deployments and Rollouts containers : - name : rollouts-demo image : argoproj/rollouts-demo:orange imagePullPolicy : Always ports : - name : http containerPort : 8080 protocol : TCP analyses : - name : http-benchmarkple templateName : http-benchmark args : - name : host value : purple - name : orange templateName : http-benchmark args : - name : host value : orange How does it work? \u00b6 The Experiment controller has two primary responsibilities for each Experiment: Creating and scaling ReplicaSets Creating and watching AnalysisRuns The controller creates a ReplicaSet for each template in the Experiment's .spec.templates . Each template needs a unique name as the controller generates the ReplicaSet's names from the combination of the Experiment's name and template's name. Once the controller creates the ReplicaSets, it waits until those new ReplicaSets become available. Once all the ReplicaSets are available, the controller marks the Experiment as running. The Experiment stays in this state for the duration listed in the spec.duration field or indefinitely if omitted. Once the Experiment is running, the controller creates AnalysisRuns for each analysis listed in the Experiment's .spec.analysis field. These AnalysisRun execute in parallel with the running ReplicaSets. The controller generates the AnalysisRun's name by combining the experiment name and the analysis name with a dash. If an AnalysisRun exists with that name, the controller appends a number to the generated name before recreating the AnalysisRun. If there is another collision, the controller increments the number and try again until it creates an AnalysisRun. Once the Experiment finished, the controller scales down the ReplicaSets it created and terminates the AnalysisRuns if they have not finished. An Experiment is considered complete when: More than the spec.Duration amount of time has passed since the ReplicaSets became healthy. One of the ReplicaSets does not become available, and the progress deadline seconds pass. An AnalysisRun created by an Experiment enters a failed or error state. An external process (i.e. user or pipeline) sets the .spec.terminate to true Integration With Rollouts \u00b6 A rollout using the Canary strategy can create an experiment using the experiment step. The experiment step serves a blocking step for the Rollout as the Rollout does not continue until the Experiment succeeds. The Rollout creates an Experiment using the configuration in the experiment step of the Rollout. The controller generates the Experiment's name by combining the Rollout's name, the PodHash of the new ReplicaSet, the current revision of the Rollout, and the current step-index. If the Experiment fails or errors out, the Rollout enters an aborted state. While in the aborted state, the Rollout fully scales up the stable version and resets the current step index back to zero. Here is an example of a rollout with an experiment step: apiVersion : argoproj.io/v1alpha1 kind : Rollout metadata : name : guestbook labels : app : guestbook spec : strategy : canary : steps : - experiment : duration : 1h templates : - name : baseline specRef : stable replicas : 3 # optional defaults to 1 - name : canary specRef : canary analysis : templateName : mann-whitney args : - name : stable-hash valueFrom : podTemplateHash : baseline - name : canary-hash valueFrom : podTemplateHash : canary In the example above, the Experiment has two templates. The baseline template uses the PodSpec from the stable ReplicaSet, and the canary template uses the PodSpec from the canary ReplicaSet. The Experiment also has one analysis with the mann-whitney template. The stable-hash arg grabs the PodHash from the stable ReplicasSet, and the canary-hash arg grabs the PodHash from the canary ReplicasSet.","title":"Experiments"},{"location":"features/experiment/#experiment-crd","text":"","title":"Experiment CRD"},{"location":"features/experiment/#what-is-the-experiment-crd","text":"The Experiment CRD allows users to have ephemeral runs of one or more ReplicaSets. In addition to running ephemeral ReplicaSets, the Experiment CRD can launch AnalysisRuns alongside the ReplicaSets. Generally, those AnalysisRun is used to confirm that new ReplicaSets are running as expected.","title":"What is the Experiment CRD?"},{"location":"features/experiment/#use-cases-of-the-experiment-crd","text":"A user wants to run two versions of an application for a specific duration to enable Kayenta-style analysis of their application. The Experiment CRD creates 2 ReplicaSets (a baseline and a canary) based on the spec.templates field of the Experiment and waits until both are healthy. After the duration passes, the Experiment scales down the ReplicaSets, and the user can start the Kayenta analysis run. A user can use experiments to enable A/B/C testing by launching multiple experiments with a different version of their application for a long duration. Each Experiment has one PodSpec template that defines a specific version a user would want to run. The Experiment allows users to launch multiple experiments at once and keep each Experiment self-contained. Launching a new version of an existing application with different labels to avoid receiving traffic from a Kubernetes service. The user can run tests against the new version before continuing the Rollout.","title":"Use cases of the Experiment CRD"},{"location":"features/experiment/#experiment-spec","text":"Below is an example of an experiment that creates two ReplicaSets with 1 replica each and runs them for 60 seconds once they both become available. Also, the controller launches two AnalysisRuns after the ReplicaSets become available. apiVersion : argoproj.io/v1alpha1 kind : Experiment metadata : name : example-experiment spec : duration : 1m # How long to run the Experiment once the ReplicaSets created from the templates are healthy progressDeadlineSeconds : 30 templates : - name : purple # (required) Unique name for the template that gets used as a part of the ReplicaSet name. replicas : 1 selector : # Same selector that has been as in Deployments and Rollouts matchLabels : app : canary-demo color : purple template : metadata : labels : app : canary-demo color : purple spec : # Same Pod Spec that has been as in Deployments and Rollouts containers : - name : rollouts-demo image : argoproj/rollouts-demo:purple imagePullPolicy : Always ports : - name : http containerPort : 8080 protocol : TCP - name : orange replicas : 1 minReadySeconds : 10 selector : # Same selector that has been as in Deployments and Rollouts matchLabels : app : canary-demo color : orange template : metadata : labels : app : canary-demo color : orange spec : # Same Pod Spec that has been as in Deployments and Rollouts containers : - name : rollouts-demo image : argoproj/rollouts-demo:orange imagePullPolicy : Always ports : - name : http containerPort : 8080 protocol : TCP analyses : - name : http-benchmarkple templateName : http-benchmark args : - name : host value : purple - name : orange templateName : http-benchmark args : - name : host value : orange","title":"Experiment Spec"},{"location":"features/experiment/#how-does-it-work","text":"The Experiment controller has two primary responsibilities for each Experiment: Creating and scaling ReplicaSets Creating and watching AnalysisRuns The controller creates a ReplicaSet for each template in the Experiment's .spec.templates . Each template needs a unique name as the controller generates the ReplicaSet's names from the combination of the Experiment's name and template's name. Once the controller creates the ReplicaSets, it waits until those new ReplicaSets become available. Once all the ReplicaSets are available, the controller marks the Experiment as running. The Experiment stays in this state for the duration listed in the spec.duration field or indefinitely if omitted. Once the Experiment is running, the controller creates AnalysisRuns for each analysis listed in the Experiment's .spec.analysis field. These AnalysisRun execute in parallel with the running ReplicaSets. The controller generates the AnalysisRun's name by combining the experiment name and the analysis name with a dash. If an AnalysisRun exists with that name, the controller appends a number to the generated name before recreating the AnalysisRun. If there is another collision, the controller increments the number and try again until it creates an AnalysisRun. Once the Experiment finished, the controller scales down the ReplicaSets it created and terminates the AnalysisRuns if they have not finished. An Experiment is considered complete when: More than the spec.Duration amount of time has passed since the ReplicaSets became healthy. One of the ReplicaSets does not become available, and the progress deadline seconds pass. An AnalysisRun created by an Experiment enters a failed or error state. An external process (i.e. user or pipeline) sets the .spec.terminate to true","title":"How does it work?"},{"location":"features/experiment/#integration-with-rollouts","text":"A rollout using the Canary strategy can create an experiment using the experiment step. The experiment step serves a blocking step for the Rollout as the Rollout does not continue until the Experiment succeeds. The Rollout creates an Experiment using the configuration in the experiment step of the Rollout. The controller generates the Experiment's name by combining the Rollout's name, the PodHash of the new ReplicaSet, the current revision of the Rollout, and the current step-index. If the Experiment fails or errors out, the Rollout enters an aborted state. While in the aborted state, the Rollout fully scales up the stable version and resets the current step index back to zero. Here is an example of a rollout with an experiment step: apiVersion : argoproj.io/v1alpha1 kind : Rollout metadata : name : guestbook labels : app : guestbook spec : strategy : canary : steps : - experiment : duration : 1h templates : - name : baseline specRef : stable replicas : 3 # optional defaults to 1 - name : canary specRef : canary analysis : templateName : mann-whitney args : - name : stable-hash valueFrom : podTemplateHash : baseline - name : canary-hash valueFrom : podTemplateHash : canary In the example above, the Experiment has two templates. The baseline template uses the PodSpec from the stable ReplicaSet, and the canary template uses the PodSpec from the canary ReplicaSet. The Experiment also has one analysis with the mann-whitney template. The stable-hash arg grabs the PodHash from the stable ReplicasSet, and the canary-hash arg grabs the PodHash from the canary ReplicasSet.","title":"Integration With Rollouts"},{"location":"features/hpa-support/","text":"Horizontal Pod Autoscaling \u00b6 Horizontal Pod Autoscaling (HPA) automatically scales the number of pods in owned by a Kubernetes resource based on observed CPU utilization or user-configured metrics. In order to accomplish this behavior, HPA only supports resources with the scale endpoint enabled with a couple of required fields. The scale endpoint allows the HPA to understand the current state of a resource and modify the resource to scale it appropriately. Argo Rollouts added support for the scale endpoint in the 0.3.0 release. After being modified by the HPA, the Argo Rollouts controller is responsible for reconciling that change in replicas. Since the strategies within a Rollout are very different, the Argo Rollouts controller handles the scale endpoint differently for various strategies. Below is the behavior for the different strategies: Blue Green \u00b6 The HPA will scale rollouts using the BlueGreen strategy using the metrics from the ReplicaSet receiving traffic from the active service. When the HPA changes the replicas count, the Argo Rollouts controller will first scale up the ReplicaSet receiving traffic from the active service before ReplicaSet receiving traffic from the preview service. The controller will scale up the ReplicaSet receiving traffic from the preview service to prepare it for when the rollout switches the preview to active. If there are no ReplicaSets receiving from the active service, the controller will use all the pods that match the base selector to determine scaling events. In that case, the controller will scale up the latest ReplicaSet to the new count and scale down the older ReplicaSets. Canary (ReplicaSet based) \u00b6 The HPA will scale rollouts using the Canary Strategy using the metrics of all the ReplicasSets within the rollout. Since the Argo Rollouts controller does not control the service that sends traffic to those ReplicaSets, it assumes that all the ReplicaSets in the rollout are receiving traffic. Example \u00b6 Below is an example of a Horizontal Pod Autoscaler that scales a rollout based on CPU metrics: apiVersion : autoscaling/v1 kind : HorizontalPodAutoscaler metadata : name : hpa-rollout-example spec : maxReplicas : 6 minReplicas : 2 scaleTargetRef : apiVersion : argoproj.io/v1alpha1 kind : Rollout name : example-rollout targetCPUUtilizationPercentage : 80 Requirements \u00b6 In order for the HPA to manipulate the rollout, the Kubernetes cluster hosting the rollout CRD needs the subresources support for CRDs. This feature was introduced as alpha in Kubernetes version 1.10 and transitioned to beta in Kubernetes version 1.11. If a user wants to use HPA on v1.10, the Kubernetes Cluster operator will need to add a custom feature flag to the API server. After 1.10, the flag is turned on by default. Check out the following link for more information on setting the custom feature flag.","title":"HPA Support"},{"location":"features/hpa-support/#horizontal-pod-autoscaling","text":"Horizontal Pod Autoscaling (HPA) automatically scales the number of pods in owned by a Kubernetes resource based on observed CPU utilization or user-configured metrics. In order to accomplish this behavior, HPA only supports resources with the scale endpoint enabled with a couple of required fields. The scale endpoint allows the HPA to understand the current state of a resource and modify the resource to scale it appropriately. Argo Rollouts added support for the scale endpoint in the 0.3.0 release. After being modified by the HPA, the Argo Rollouts controller is responsible for reconciling that change in replicas. Since the strategies within a Rollout are very different, the Argo Rollouts controller handles the scale endpoint differently for various strategies. Below is the behavior for the different strategies:","title":"Horizontal Pod Autoscaling"},{"location":"features/hpa-support/#blue-green","text":"The HPA will scale rollouts using the BlueGreen strategy using the metrics from the ReplicaSet receiving traffic from the active service. When the HPA changes the replicas count, the Argo Rollouts controller will first scale up the ReplicaSet receiving traffic from the active service before ReplicaSet receiving traffic from the preview service. The controller will scale up the ReplicaSet receiving traffic from the preview service to prepare it for when the rollout switches the preview to active. If there are no ReplicaSets receiving from the active service, the controller will use all the pods that match the base selector to determine scaling events. In that case, the controller will scale up the latest ReplicaSet to the new count and scale down the older ReplicaSets.","title":"Blue Green"},{"location":"features/hpa-support/#canary-replicaset-based","text":"The HPA will scale rollouts using the Canary Strategy using the metrics of all the ReplicasSets within the rollout. Since the Argo Rollouts controller does not control the service that sends traffic to those ReplicaSets, it assumes that all the ReplicaSets in the rollout are receiving traffic.","title":"Canary (ReplicaSet based)"},{"location":"features/hpa-support/#example","text":"Below is an example of a Horizontal Pod Autoscaler that scales a rollout based on CPU metrics: apiVersion : autoscaling/v1 kind : HorizontalPodAutoscaler metadata : name : hpa-rollout-example spec : maxReplicas : 6 minReplicas : 2 scaleTargetRef : apiVersion : argoproj.io/v1alpha1 kind : Rollout name : example-rollout targetCPUUtilizationPercentage : 80","title":"Example"},{"location":"features/hpa-support/#requirements","text":"In order for the HPA to manipulate the rollout, the Kubernetes cluster hosting the rollout CRD needs the subresources support for CRDs. This feature was introduced as alpha in Kubernetes version 1.10 and transitioned to beta in Kubernetes version 1.11. If a user wants to use HPA on v1.10, the Kubernetes Cluster operator will need to add a custom feature flag to the API server. After 1.10, the flag is turned on by default. Check out the following link for more information on setting the custom feature flag.","title":"Requirements"},{"location":"features/kubectl-plugin/","text":"Kubectl Plugin \u00b6 Kubectl plugins are a way to extend the kubectl command to provide additional behavior. Generally, they are used to add new functionality to kubectl and automate scriptable workflows against a cluster. The official documentation on them is here . Argo Rollouts offers a Kubectl plugin to enrich the experience with Rollouts, Experiments, and Analysis from the command line. It offers the ability to visualize the Argo Rollouts resources and run routine operations like promote or retry on those resources from the command. Installation \u00b6 See the installation guide for instructions on installing the plugin. Usage \u00b6 The best way to get information on the available Argo Rollouts kubectl plugin commands is by run kubectl argo rollouts . The plugin lists all the available commands that the tool can execute along with a description of each commend. All the plugin's commands interact with the Kubernetes API server and use KubeConfig credentials for authentication. Since the plugin leverages the KubeConfig of the user running the command, the plugin has the permissions of those configs. Similar to kubectl, the plugin uses many of the same flags as the kubectl. For example, the kubectl argo rollouts get rollout canary-demo -w command starts a watch on the canary-demo rollout object similar to how the kubectl get deployment canary-demo -w command starts a watch on a deployment. Visualizing Rollouts and Experiments \u00b6 In addition to encapsulating many routine commands, the Argo Rollouts kubectl plugin supports visualizing rollouts and experiments with the get command. The get command provides a clean representation of either the rollouts or the experiments running in a cluster. It returns a bunch of metadata on a resource and a tree view of the child resources created by the parent. As an example, here is a rollout retrieved with a get command: Here is a table to explain some of the icons on the tree view: Icon Kind \u27f3 Rollout \u03a3 Experiment \u03b1 AnalysisRun # Revision \u29c9 ReplicaSet \u25a1 Pod \u229e Job If the get command includes the watch flag ( -w or --watch ), the terminal updates as the rollouts or experiment progress highlighting the progress.","title":"Overview"},{"location":"features/kubectl-plugin/#kubectl-plugin","text":"Kubectl plugins are a way to extend the kubectl command to provide additional behavior. Generally, they are used to add new functionality to kubectl and automate scriptable workflows against a cluster. The official documentation on them is here . Argo Rollouts offers a Kubectl plugin to enrich the experience with Rollouts, Experiments, and Analysis from the command line. It offers the ability to visualize the Argo Rollouts resources and run routine operations like promote or retry on those resources from the command.","title":"Kubectl Plugin"},{"location":"features/kubectl-plugin/#installation","text":"See the installation guide for instructions on installing the plugin.","title":"Installation"},{"location":"features/kubectl-plugin/#usage","text":"The best way to get information on the available Argo Rollouts kubectl plugin commands is by run kubectl argo rollouts . The plugin lists all the available commands that the tool can execute along with a description of each commend. All the plugin's commands interact with the Kubernetes API server and use KubeConfig credentials for authentication. Since the plugin leverages the KubeConfig of the user running the command, the plugin has the permissions of those configs. Similar to kubectl, the plugin uses many of the same flags as the kubectl. For example, the kubectl argo rollouts get rollout canary-demo -w command starts a watch on the canary-demo rollout object similar to how the kubectl get deployment canary-demo -w command starts a watch on a deployment.","title":"Usage"},{"location":"features/kubectl-plugin/#visualizing-rollouts-and-experiments","text":"In addition to encapsulating many routine commands, the Argo Rollouts kubectl plugin supports visualizing rollouts and experiments with the get command. The get command provides a clean representation of either the rollouts or the experiments running in a cluster. It returns a bunch of metadata on a resource and a tree view of the child resources created by the parent. As an example, here is a rollout retrieved with a get command: Here is a table to explain some of the icons on the tree view: Icon Kind \u27f3 Rollout \u03a3 Experiment \u03b1 AnalysisRun # Revision \u29c9 ReplicaSet \u25a1 Pod \u229e Job If the get command includes the watch flag ( -w or --watch ), the terminal updates as the rollouts or experiment progress highlighting the progress.","title":"Visualizing Rollouts and Experiments"},{"location":"features/kustomize/","text":"Kustomize Integration \u00b6 Kustomize can be extended to understand CRD objects through the use of transformer configs . Using transformer configs, kustomize can be \"taught\" about the structure of a Rollout object and leverage kustomize features such as ConfigMap/Secret generators, variable references, and common labels & annotations. To use Rollouts with kustomize: Download rollout-transform.yaml into your kustomize directory. Include rollout-transform.yaml in your kustomize configurations section: kind : Kustomization apiVersion : kustomize.config.k8s.io/v1beta1 configurations : - rollout-transform.yaml With Kustomize 3.6.1 it is possible to reference the configuration directly from a remote resource: configurations : - https://argoproj.github.io/argo-rollouts/features/kustomize/rollout-transform.yaml A example kustomize app demonstrating the ability to use transformers with Rollouts can be seen here .","title":"Kustomize Support"},{"location":"features/kustomize/#kustomize-integration","text":"Kustomize can be extended to understand CRD objects through the use of transformer configs . Using transformer configs, kustomize can be \"taught\" about the structure of a Rollout object and leverage kustomize features such as ConfigMap/Secret generators, variable references, and common labels & annotations. To use Rollouts with kustomize: Download rollout-transform.yaml into your kustomize directory. Include rollout-transform.yaml in your kustomize configurations section: kind : Kustomization apiVersion : kustomize.config.k8s.io/v1beta1 configurations : - rollout-transform.yaml With Kustomize 3.6.1 it is possible to reference the configuration directly from a remote resource: configurations : - https://argoproj.github.io/argo-rollouts/features/kustomize/rollout-transform.yaml A example kustomize app demonstrating the ability to use transformers with Rollouts can be seen here .","title":"Kustomize Integration"},{"location":"features/restart/","text":"Rollout Pod Restarts \u00b6 For various reasons, applications sometimes need a restart. Since the restart is not changing the version, the application should not have to go through the entire BlueGreen or canary deployment process. The Rollout object supports restarting an application by having the controller do a rolling recreate of all the Pods in a Rollout without going through all the regular BlueGreen or Canary deployments. The controller kills one Pod at a time and relies on the ReplicaSet to scale up new Pods until all the Pods are newer than the restarted time. How it works \u00b6 The Rollout object has a field called .spec.restartAt that takes in a RFC 3339 formatted string (ie. 2020-03-30T21:19:35Z). If the current time is past the restartAt time, the controller knows it needs to restart all the Pods in the Rollout. The controller goes through each ReplicaSet to see if all the Pods have a creation timestamp newer than the restartAt time. To prevent too many Pods from restarting at once, the controller limits itself to deleting one Pod at a time and checks that no other Pods in that ReplicaSet have a deletion timestamp and that ReplicaSet is fully available. The controller checks the ReplicaSets in the following order: 1. stable ReplicaSet, 2. new ReplicaSet, and 3rd. all the other ReplicaSets starting with the oldest. Once the controller has confirmed all the Pods are newer than the restartAt time, the controller sets the status.restartedAt field to indicate that the Rollout has been successfully restarted. If a change occurs to the spec.template during a restart, the restart is canceled (by setting the status.restartedAt to the spec.restartAt ) since the Rollout has to bring up a new stack. Note: Unlike deployments, whose restarts are essentially a normal rolling upgrade which happened to be triggered by a timestamp in the pod spec annotation, Rollouts facilitates restarts by sequentially and individually terminating pods one by one. This design choice was made in order to allow a restart to occur even when a Rollout was in the middle of a long-running blue-green/canary update. However, some consequences of this are: Restarting a Rollout with a single replica will cause downtime since the Rollout would only have a single one Pod which would be brought down during the restart. Restarting a rollout occurs slower than a deployment's rolling update, since the sequential restarting of pods is more conservative than the maxSurge, maxUnavailable fields of a rolling update. Kubectl command \u00b6 The Argo Rollouts kubectl plugin has a command for restarting Rollouts. Check it out here . Rescheduled Restarts \u00b6 Users can reschedule a restart on their Rollout by setting the .spec.restartAt field to a time in the future. The controller only starts the restart after the current time is after the restartAt time.","title":"Restarting Rollouts"},{"location":"features/restart/#rollout-pod-restarts","text":"For various reasons, applications sometimes need a restart. Since the restart is not changing the version, the application should not have to go through the entire BlueGreen or canary deployment process. The Rollout object supports restarting an application by having the controller do a rolling recreate of all the Pods in a Rollout without going through all the regular BlueGreen or Canary deployments. The controller kills one Pod at a time and relies on the ReplicaSet to scale up new Pods until all the Pods are newer than the restarted time.","title":"Rollout Pod Restarts"},{"location":"features/restart/#how-it-works","text":"The Rollout object has a field called .spec.restartAt that takes in a RFC 3339 formatted string (ie. 2020-03-30T21:19:35Z). If the current time is past the restartAt time, the controller knows it needs to restart all the Pods in the Rollout. The controller goes through each ReplicaSet to see if all the Pods have a creation timestamp newer than the restartAt time. To prevent too many Pods from restarting at once, the controller limits itself to deleting one Pod at a time and checks that no other Pods in that ReplicaSet have a deletion timestamp and that ReplicaSet is fully available. The controller checks the ReplicaSets in the following order: 1. stable ReplicaSet, 2. new ReplicaSet, and 3rd. all the other ReplicaSets starting with the oldest. Once the controller has confirmed all the Pods are newer than the restartAt time, the controller sets the status.restartedAt field to indicate that the Rollout has been successfully restarted. If a change occurs to the spec.template during a restart, the restart is canceled (by setting the status.restartedAt to the spec.restartAt ) since the Rollout has to bring up a new stack. Note: Unlike deployments, whose restarts are essentially a normal rolling upgrade which happened to be triggered by a timestamp in the pod spec annotation, Rollouts facilitates restarts by sequentially and individually terminating pods one by one. This design choice was made in order to allow a restart to occur even when a Rollout was in the middle of a long-running blue-green/canary update. However, some consequences of this are: Restarting a Rollout with a single replica will cause downtime since the Rollout would only have a single one Pod which would be brought down during the restart. Restarting a rollout occurs slower than a deployment's rolling update, since the sequential restarting of pods is more conservative than the maxSurge, maxUnavailable fields of a rolling update.","title":"How it works"},{"location":"features/restart/#kubectl-command","text":"The Argo Rollouts kubectl plugin has a command for restarting Rollouts. Check it out here .","title":"Kubectl command"},{"location":"features/restart/#rescheduled-restarts","text":"Users can reschedule a restart on their Rollout by setting the .spec.restartAt field to a time in the future. The controller only starts the restart after the current time is after the restartAt time.","title":"Rescheduled Restarts"},{"location":"features/specification/","text":"Rollout Specification \u00b6 The following describes all the available fields of a rollout: apiVersion : argoproj.io/v1alpha1 kind : Rollout metadata : name : example-rollout-canary spec : # Number of desired pods. This is a pointer to distinguish between explicit zero and not specified. # Defaults to 1. replicas : 5 # Label selector for pods. Existing ReplicaSets whose pods are selected by this will be the ones # affected by this rollout. It must match the pod template's labels. selector : matchLabels : app : guestbook # Template describes the pods that will be created. Same as deployment template : spec : containers : - name : guestbook image : gcr.io/heptio-images/ks-guestbook-demo:0.1 # Minimum number of seconds for which a newly created pod should be ready without any of its # container crashing, for it to be considered available. # Defaults to 0 (pod will be considered available as soon as it is ready) minReadySeconds : 30 # The number of old ReplicaSets to retain. # Defaults to 10 revisionHistoryLimit : 3 # Pause allows a user to manually pause a rollout at any time. A rollout will not advance through # its steps while it is manually paused, but HPA auto-scaling will still occur. # Usually not used in the manifest, but if true at initial creation of Rollout, replicas are not scaled up automatically from zero unless manually promoted. paused : true # The maximum time in seconds in which a rollout must make progress during an update, before it is # considered to be failed. Argo Rollouts will continue to process failed rollouts and a condition # with a ProgressDeadlineExceeded reason will be surfaced in the rollout status. Note that # progress will not be estimated during the time a rollout is paused. # Defaults to 600s progressDeadlineSeconds : 600 # UTC timestamp in which a Rollout should sequentially restart all of its pods. Used by the # `kubectl argo rollouts restart ROLLOUT` command. The controller will ensure all pods have a # creationTimestamp greater than or equal to this value. restartAt : \"2020-03-30T21:19:35Z\" # Deployment strategy to use during updates strategy : blueGreen : # Name of the service that the rollout modifies as the active service. activeService : active-service # Pre-promotion analysis run which performs analysis before the service cutover. +optional prePromotionAnalysis : templates : - templateName : success-rate # template arguments args : - name : service-name value : guestbook-svc.default.svc.cluster.local # Post-promotion analysis run which performs analysis after the service cutover. +optional postPromotionAnalysis : templates : - templateName : success-rate # template arguments args : - name : service-name value : guestbook-svc.default.svc.cluster.local # Name of the service that the rollout modifies as the preview service. +optional previewService : preview-service # The number of replicas to run under the preview service before the switchover. Once the rollout is resumed the new replicaset will be full scaled up before the switch occurs +optional previewReplicaCount : 1 # Indicates if the rollout should automatically promote the new ReplicaSet to the active service or enter a paused state. If not specified, the default value is true. +optional autoPromotionEnabled : false # Automatically promotes the current ReplicaSet to active after the specified pause delay in seconds after the ReplicaSet becomes ready. If omitted, the Rollout enters and remains in a paused state until manually resumed by resetting spec.Paused to false. +optional autoPromotionSeconds : 30 # Adds a delay before scaling down the previous replicaset. If omitted, the Rollout waits 30 seconds before scaling down the previous ReplicaSet. A minimum of 30 seconds is recommended to ensure IP table propagation across the nodes in a cluster. See https://github.com/argoproj/argo-rollouts/issues/19#issuecomment-476329960 for more information scaleDownDelaySeconds : 30 # Limits the number of old RS that can run at once before getting scaled down. Defaults to nil scaleDownDelayRevisionLimit : 2 # Anti Affinity configuration between desired and previous replicaset. Only one must be specified antiAffinity : requiredDuringSchedulingIgnoredDuringExecution : {} preferredDuringSchedulingIgnoredDuringExecution : weight : 1 # Between 1 - 100 canary : # CanaryService holds the name of a service which selects pods with canary version and don't select any pods with stable version. +optional canaryService : canary-service # StableService holds the name of a service which selects pods with stable version and don't select any pods with canary version. +optional stableService : stable-service # The maximum number of pods that can be unavailable during the update. Value can be an absolute number (ex: 5) or a percentage of total pods at the start of update (ex: 10%). Absolute number is calculated from percentage by rounding down. This can not be 0 if MaxSurge is 0. By default, a fixed value of 1 is used. Example: when this is set to 30%, the old RC can be scaled down by 30% immediately when the rolling update starts. Once new pods are ready, old RC can be scaled down further, followed by scaling up the new RC, ensuring that at least 70% of original number of pods are available at all times during the update. +optional maxUnavailable : 1 # The maximum number of pods that can be scheduled above the original number of pods. Value can be an absolute number (ex: 5) or a percentage of total pods at the start of the update (ex: 10%). This can not be 0 if MaxUnavailable is 0. Absolute number is calculated from percentage by rounding up. By default, a value of 1 is used. Example: when this is set to 30%, the new RC can be scaled up by 30% immediately when the rolling update starts. Once old pods have been killed, new RC can be scaled up further, ensuring that total number of pods running at any time during the update is at most 130% of original pods. +optional maxSurge : \"20%\" # Background analysis to run during the rollout analysis : templates : - templateName : success-rate # template arguments args : - name : service-name value : guestbook-svc.default.svc.cluster.local # Define the order of phases to execute the canary deployment +optional steps : # Sets the ratio of new replicasets to 20% - setWeight : 20 # Pauses the rollout for an hour - pause : duration : 1h # One hour - setWeight : 40 # Sets .spec.paused to true and waits until the field is changed back - pause : {} # Anti Affinity configuration between desired and previous replicaset. Only one must be specified antiAffinity : requiredDuringSchedulingIgnoredDuringExecution : {} preferredDuringSchedulingIgnoredDuringExecution : weight : 1 # Between 1 - 100 # Traffic routing specifies ingress controller or service mesh configuration to achieve # advanced traffic splitting. If omitted, will achieve traffic split via a weighted # replica counts between the canary and stable ReplicaSet. trafficRouting : # Istio traffic routing configuration istio : virtualService : name : rollout-vsvc # required routes : - primary # At least one route is required # NGINX Ingress Controller routing configuration nginx : stableIngress : primary-ingress # required annotationPrefix : customingress.nginx.ingress.kubernetes.io # optional additionalIngressAnnotations : # optional canary-by-header : X-Canary canary-by-header-value : iwantsit # ALB Ingress Controller routing configuration alb : ingress : ingress # required servicePort : 443 # required annotationPrefix : custom.alb.ingress.kubernetes.io # optional # Service Mesh Interface routing configuration smi : rootService : root-svc # optional trafficSplitName : rollout-example-traffic-split # optional status : pauseConditions : - reason : StepPause startTime : 2019-10-00T1234 - reason : BlueGreenPause startTime : 2019-10-00T1234 - reason : AnalysisRunInconclusive startTime : 2019-10-00T1234","title":"Rollout Spec"},{"location":"features/specification/#rollout-specification","text":"The following describes all the available fields of a rollout: apiVersion : argoproj.io/v1alpha1 kind : Rollout metadata : name : example-rollout-canary spec : # Number of desired pods. This is a pointer to distinguish between explicit zero and not specified. # Defaults to 1. replicas : 5 # Label selector for pods. Existing ReplicaSets whose pods are selected by this will be the ones # affected by this rollout. It must match the pod template's labels. selector : matchLabels : app : guestbook # Template describes the pods that will be created. Same as deployment template : spec : containers : - name : guestbook image : gcr.io/heptio-images/ks-guestbook-demo:0.1 # Minimum number of seconds for which a newly created pod should be ready without any of its # container crashing, for it to be considered available. # Defaults to 0 (pod will be considered available as soon as it is ready) minReadySeconds : 30 # The number of old ReplicaSets to retain. # Defaults to 10 revisionHistoryLimit : 3 # Pause allows a user to manually pause a rollout at any time. A rollout will not advance through # its steps while it is manually paused, but HPA auto-scaling will still occur. # Usually not used in the manifest, but if true at initial creation of Rollout, replicas are not scaled up automatically from zero unless manually promoted. paused : true # The maximum time in seconds in which a rollout must make progress during an update, before it is # considered to be failed. Argo Rollouts will continue to process failed rollouts and a condition # with a ProgressDeadlineExceeded reason will be surfaced in the rollout status. Note that # progress will not be estimated during the time a rollout is paused. # Defaults to 600s progressDeadlineSeconds : 600 # UTC timestamp in which a Rollout should sequentially restart all of its pods. Used by the # `kubectl argo rollouts restart ROLLOUT` command. The controller will ensure all pods have a # creationTimestamp greater than or equal to this value. restartAt : \"2020-03-30T21:19:35Z\" # Deployment strategy to use during updates strategy : blueGreen : # Name of the service that the rollout modifies as the active service. activeService : active-service # Pre-promotion analysis run which performs analysis before the service cutover. +optional prePromotionAnalysis : templates : - templateName : success-rate # template arguments args : - name : service-name value : guestbook-svc.default.svc.cluster.local # Post-promotion analysis run which performs analysis after the service cutover. +optional postPromotionAnalysis : templates : - templateName : success-rate # template arguments args : - name : service-name value : guestbook-svc.default.svc.cluster.local # Name of the service that the rollout modifies as the preview service. +optional previewService : preview-service # The number of replicas to run under the preview service before the switchover. Once the rollout is resumed the new replicaset will be full scaled up before the switch occurs +optional previewReplicaCount : 1 # Indicates if the rollout should automatically promote the new ReplicaSet to the active service or enter a paused state. If not specified, the default value is true. +optional autoPromotionEnabled : false # Automatically promotes the current ReplicaSet to active after the specified pause delay in seconds after the ReplicaSet becomes ready. If omitted, the Rollout enters and remains in a paused state until manually resumed by resetting spec.Paused to false. +optional autoPromotionSeconds : 30 # Adds a delay before scaling down the previous replicaset. If omitted, the Rollout waits 30 seconds before scaling down the previous ReplicaSet. A minimum of 30 seconds is recommended to ensure IP table propagation across the nodes in a cluster. See https://github.com/argoproj/argo-rollouts/issues/19#issuecomment-476329960 for more information scaleDownDelaySeconds : 30 # Limits the number of old RS that can run at once before getting scaled down. Defaults to nil scaleDownDelayRevisionLimit : 2 # Anti Affinity configuration between desired and previous replicaset. Only one must be specified antiAffinity : requiredDuringSchedulingIgnoredDuringExecution : {} preferredDuringSchedulingIgnoredDuringExecution : weight : 1 # Between 1 - 100 canary : # CanaryService holds the name of a service which selects pods with canary version and don't select any pods with stable version. +optional canaryService : canary-service # StableService holds the name of a service which selects pods with stable version and don't select any pods with canary version. +optional stableService : stable-service # The maximum number of pods that can be unavailable during the update. Value can be an absolute number (ex: 5) or a percentage of total pods at the start of update (ex: 10%). Absolute number is calculated from percentage by rounding down. This can not be 0 if MaxSurge is 0. By default, a fixed value of 1 is used. Example: when this is set to 30%, the old RC can be scaled down by 30% immediately when the rolling update starts. Once new pods are ready, old RC can be scaled down further, followed by scaling up the new RC, ensuring that at least 70% of original number of pods are available at all times during the update. +optional maxUnavailable : 1 # The maximum number of pods that can be scheduled above the original number of pods. Value can be an absolute number (ex: 5) or a percentage of total pods at the start of the update (ex: 10%). This can not be 0 if MaxUnavailable is 0. Absolute number is calculated from percentage by rounding up. By default, a value of 1 is used. Example: when this is set to 30%, the new RC can be scaled up by 30% immediately when the rolling update starts. Once old pods have been killed, new RC can be scaled up further, ensuring that total number of pods running at any time during the update is at most 130% of original pods. +optional maxSurge : \"20%\" # Background analysis to run during the rollout analysis : templates : - templateName : success-rate # template arguments args : - name : service-name value : guestbook-svc.default.svc.cluster.local # Define the order of phases to execute the canary deployment +optional steps : # Sets the ratio of new replicasets to 20% - setWeight : 20 # Pauses the rollout for an hour - pause : duration : 1h # One hour - setWeight : 40 # Sets .spec.paused to true and waits until the field is changed back - pause : {} # Anti Affinity configuration between desired and previous replicaset. Only one must be specified antiAffinity : requiredDuringSchedulingIgnoredDuringExecution : {} preferredDuringSchedulingIgnoredDuringExecution : weight : 1 # Between 1 - 100 # Traffic routing specifies ingress controller or service mesh configuration to achieve # advanced traffic splitting. If omitted, will achieve traffic split via a weighted # replica counts between the canary and stable ReplicaSet. trafficRouting : # Istio traffic routing configuration istio : virtualService : name : rollout-vsvc # required routes : - primary # At least one route is required # NGINX Ingress Controller routing configuration nginx : stableIngress : primary-ingress # required annotationPrefix : customingress.nginx.ingress.kubernetes.io # optional additionalIngressAnnotations : # optional canary-by-header : X-Canary canary-by-header-value : iwantsit # ALB Ingress Controller routing configuration alb : ingress : ingress # required servicePort : 443 # required annotationPrefix : custom.alb.ingress.kubernetes.io # optional # Service Mesh Interface routing configuration smi : rootService : root-svc # optional trafficSplitName : rollout-example-traffic-split # optional status : pauseConditions : - reason : StepPause startTime : 2019-10-00T1234 - reason : BlueGreenPause startTime : 2019-10-00T1234 - reason : AnalysisRunInconclusive startTime : 2019-10-00T1234","title":"Rollout Specification"},{"location":"features/anti-affinity/anti-affinity/","text":"Anti Affinity \u00b6 Background \u00b6 Depending on a cluster's configuration, a Blue Green Rollout (or a Canary rollout that uses traffic management) can cause newly created pods to restart after deploying a new version. This can be problematic, especially for applications that cannot startup quickly or do not gracefully exit. This behavior occurs because cluster auto-scaler wants to scale down the extra capacity which was created to support a Rollout running in double capacity. When a node is scaled down, the pods it owns are deleted and recreated. This usually happens if a Rollout has its own dedicated instance group since a Rollout has a greater effect on cluster auto-scaling. Therefore, clusters with a large pool of shared nodes experience the behavior less often. For example, here is a Rollout is running with 8 pods spread across 2 nodes. Each node can hold 6 pods: When the spec.template of the Rollout changes, the controller creates a new ReplicaSet with the spec update and the total number of pods doubles. In this case, the number of pods increases to 16. Since each node can only hold 6 pods, the cluster autoscaler must increase the node count to 3 to accommodate all 16 pods. The resulting distribution of pods across nodes is shown here: Once the Rollout finishes progressing, the old version is scaled down. This leaves the cluster with more nodes than necessary, thus wasting resources (as shown below). The cluster auto-scaler terminates the extra node and the pods are rescheduled on the remaining 2 nodes. To reduce the chance of this behavior, a rollout can inject anti-affinity into the ReplicaSet. This prevents new pods from running on nodes which have the previous version's pods. You can learn more about anti-affinity here . Repeating the above example with anti-affinity enabled, here is what happens when the .spec.template of the Rollout changes. Due to anti-affinity, the new pods cannot be scheduled on nodes which run the old ReplicaSet's pods. As a result, the cluster auto-scaler must create 2 nodes to host the new ReplicaSet's pods. In this case, pods won't be started since the scaled-down nodes are guaranteed to not have the new pods. Enabling Anti-Affinity in Rollouts \u00b6 Anti-affinity is enabled by adding the anti-affinity struct to the Blue-Green or Canary strategy. When the anti-affinity struct is set, controller injects a PodAntiAffinity struct into the ReplicaSet's Affinity. This feature will not modify any of the ReplicaSet's pre-existing affinity rules. Users have a choice between these scheduling rules: RequiredDuringSchedulingIgnoredDuringExecution and PreferredDuringSchedulingIgnoredDuringExecution . RequiredDuringSchedulingIgnoredDuringExecution requires a new version's pods to be on a separate node than the previous versions. If this is not possible, the the new version's pods will not be scheduled. strategy : bluegreen : antiAffinity : requiredDuringSchedulingIgnoredDuringExecution : {} Unlike the Required strategy, PreferredDuringSchedulingIgnoredDuringExecution does not force a new version's pods to be on a separate node than the previous versions. The scheduler attempts to place the new version's pods on separate node(s). If that's not possible, the new version's pods will still be scheduled. The Weight is used to create a priority order for preferred anti-affinity rules. strategy : canary : antiAffinity : preferredDuringSchedulingIgnoredDuringExecution : weight : 1 # Between 1 - 100 Important The main downside to this approach is that deployments can take longer because new nodes are more likely to be created in order to schedule pods with respect to anti-affinity rules. This delay most frequently occurs when a rollout has its own dedicated instance group, since new nodes are more likely to be created to honor anti-affinity rules.","title":"Anti Affinity"},{"location":"features/anti-affinity/anti-affinity/#anti-affinity","text":"","title":"Anti Affinity"},{"location":"features/anti-affinity/anti-affinity/#background","text":"Depending on a cluster's configuration, a Blue Green Rollout (or a Canary rollout that uses traffic management) can cause newly created pods to restart after deploying a new version. This can be problematic, especially for applications that cannot startup quickly or do not gracefully exit. This behavior occurs because cluster auto-scaler wants to scale down the extra capacity which was created to support a Rollout running in double capacity. When a node is scaled down, the pods it owns are deleted and recreated. This usually happens if a Rollout has its own dedicated instance group since a Rollout has a greater effect on cluster auto-scaling. Therefore, clusters with a large pool of shared nodes experience the behavior less often. For example, here is a Rollout is running with 8 pods spread across 2 nodes. Each node can hold 6 pods: When the spec.template of the Rollout changes, the controller creates a new ReplicaSet with the spec update and the total number of pods doubles. In this case, the number of pods increases to 16. Since each node can only hold 6 pods, the cluster autoscaler must increase the node count to 3 to accommodate all 16 pods. The resulting distribution of pods across nodes is shown here: Once the Rollout finishes progressing, the old version is scaled down. This leaves the cluster with more nodes than necessary, thus wasting resources (as shown below). The cluster auto-scaler terminates the extra node and the pods are rescheduled on the remaining 2 nodes. To reduce the chance of this behavior, a rollout can inject anti-affinity into the ReplicaSet. This prevents new pods from running on nodes which have the previous version's pods. You can learn more about anti-affinity here . Repeating the above example with anti-affinity enabled, here is what happens when the .spec.template of the Rollout changes. Due to anti-affinity, the new pods cannot be scheduled on nodes which run the old ReplicaSet's pods. As a result, the cluster auto-scaler must create 2 nodes to host the new ReplicaSet's pods. In this case, pods won't be started since the scaled-down nodes are guaranteed to not have the new pods.","title":"Background"},{"location":"features/anti-affinity/anti-affinity/#enabling-anti-affinity-in-rollouts","text":"Anti-affinity is enabled by adding the anti-affinity struct to the Blue-Green or Canary strategy. When the anti-affinity struct is set, controller injects a PodAntiAffinity struct into the ReplicaSet's Affinity. This feature will not modify any of the ReplicaSet's pre-existing affinity rules. Users have a choice between these scheduling rules: RequiredDuringSchedulingIgnoredDuringExecution and PreferredDuringSchedulingIgnoredDuringExecution . RequiredDuringSchedulingIgnoredDuringExecution requires a new version's pods to be on a separate node than the previous versions. If this is not possible, the the new version's pods will not be scheduled. strategy : bluegreen : antiAffinity : requiredDuringSchedulingIgnoredDuringExecution : {} Unlike the Required strategy, PreferredDuringSchedulingIgnoredDuringExecution does not force a new version's pods to be on a separate node than the previous versions. The scheduler attempts to place the new version's pods on separate node(s). If that's not possible, the new version's pods will still be scheduled. The Weight is used to create a priority order for preferred anti-affinity rules. strategy : canary : antiAffinity : preferredDuringSchedulingIgnoredDuringExecution : weight : 1 # Between 1 - 100 Important The main downside to this approach is that deployments can take longer because new nodes are more likely to be created in order to schedule pods with respect to anti-affinity rules. This delay most frequently occurs when a rollout has its own dedicated instance group, since new nodes are more likely to be created to honor anti-affinity rules.","title":"Enabling Anti-Affinity in Rollouts"},{"location":"features/traffic-management/","text":"Traffic management \u00b6 Traffic management is controlling the data plane to have intelligent routing rules for an application. These routing rules can manipulate the flow of traffic to different versions of an application enabling Progressive Delivery. These controls limit the blast radius of a new release by ensuring a small percentage of users receive a new version while it is verified. There are various techniques to achieve traffic management: Raw percentages (i.e., 5% of traffic should go to the new version while the rest goes to the stable version) Header-based routing (i.e., send requests with a specific header to the new version) Mirrored traffic where all the traffic is copied and send to the new version in parallel (but the response is ignored) Traffic Management tools in Kubernetes \u00b6 The core Kubernetes objects do not have fine-grained tools needed to fulfill all the requirements of traffic management. At most, Kubernetes offers na\u00efve load balancing capabilities through the Service object by offering an endpoint that routes traffic to a grouping of pods based on that Service's selector. Functionality like traffic mirroring or routing by headers is not possible with the default core Service object, and the only way to control the percentage of traffic to different versions of an application is by manipulating replica counts of those versions. Service Meshes fill this missing functionality in Kubernetes. They introduce new concepts and functionality to control the data plane through the use of CRDs and other core Kubernetes resources. How does Argo Rollouts enable traffic management? \u00b6 Argo Rollouts enables traffic management by manipulating the Service Mesh resources to match the intent of the Rollout. Argo Rollouts currently supports the following service meshes: Istio Nginx Ingress Controller AWS ALB Ingress Controller Service Mesh Interface (SMI) File a ticket here if you would like another implementation (or thumbs up it if that issue already exists) Regardless of the Service Mesh used, the Rollout object has to set a canary Service and a stable Service in its spec. Here is an example with those fields set: apiVersion : argoproj.io/v1alpha1 kind : Rollout spec : ... strategy : canary : canaryService : canary-service stableService : stable-service trafficRouting : ... The controller modifies these Services to route traffic to the appropriate canary and stable ReplicaSets as the Rollout progresses. These Services are used by the Service Mesh to define what group of pods should receive the canary and stable traffic. Additionally, the Argo Rollouts controller needs to treat the Rollout object differently when using traffic management. In particular, the Stable ReplicaSet owned by the Rollout remains fully scaled up as the Rollout progresses through the Canary steps. Since the traffic is controlled independently by the Service Mesh resources, the controller needs to make a best effort to ensure that the Stable and New ReplicaSets are not overwhelmed by the traffic sent to them. By leaving the Stable ReplicaSet scaled up, the controller is ensuring that the Stable ReplicaSet can handle 100% of the traffic at any time 1 . The New ReplicaSet follows the same behavior as without traffic management. The new ReplicaSet's replica count is equal to the latest SetWeight step percentage multiple by the total replica count of the Rollout. This calculation ensures that the canary version does not receive more traffic than it can handle. The Rollout has to assume that the application can handle 100% of traffic if it is fully scaled up. It should outsource to the HPA to detect if the Rollout needs to more replicas if 100% isn't enough. \u21a9","title":"Overview"},{"location":"features/traffic-management/#traffic-management","text":"Traffic management is controlling the data plane to have intelligent routing rules for an application. These routing rules can manipulate the flow of traffic to different versions of an application enabling Progressive Delivery. These controls limit the blast radius of a new release by ensuring a small percentage of users receive a new version while it is verified. There are various techniques to achieve traffic management: Raw percentages (i.e., 5% of traffic should go to the new version while the rest goes to the stable version) Header-based routing (i.e., send requests with a specific header to the new version) Mirrored traffic where all the traffic is copied and send to the new version in parallel (but the response is ignored)","title":"Traffic management"},{"location":"features/traffic-management/#traffic-management-tools-in-kubernetes","text":"The core Kubernetes objects do not have fine-grained tools needed to fulfill all the requirements of traffic management. At most, Kubernetes offers na\u00efve load balancing capabilities through the Service object by offering an endpoint that routes traffic to a grouping of pods based on that Service's selector. Functionality like traffic mirroring or routing by headers is not possible with the default core Service object, and the only way to control the percentage of traffic to different versions of an application is by manipulating replica counts of those versions. Service Meshes fill this missing functionality in Kubernetes. They introduce new concepts and functionality to control the data plane through the use of CRDs and other core Kubernetes resources.","title":"Traffic Management tools in Kubernetes"},{"location":"features/traffic-management/#how-does-argo-rollouts-enable-traffic-management","text":"Argo Rollouts enables traffic management by manipulating the Service Mesh resources to match the intent of the Rollout. Argo Rollouts currently supports the following service meshes: Istio Nginx Ingress Controller AWS ALB Ingress Controller Service Mesh Interface (SMI) File a ticket here if you would like another implementation (or thumbs up it if that issue already exists) Regardless of the Service Mesh used, the Rollout object has to set a canary Service and a stable Service in its spec. Here is an example with those fields set: apiVersion : argoproj.io/v1alpha1 kind : Rollout spec : ... strategy : canary : canaryService : canary-service stableService : stable-service trafficRouting : ... The controller modifies these Services to route traffic to the appropriate canary and stable ReplicaSets as the Rollout progresses. These Services are used by the Service Mesh to define what group of pods should receive the canary and stable traffic. Additionally, the Argo Rollouts controller needs to treat the Rollout object differently when using traffic management. In particular, the Stable ReplicaSet owned by the Rollout remains fully scaled up as the Rollout progresses through the Canary steps. Since the traffic is controlled independently by the Service Mesh resources, the controller needs to make a best effort to ensure that the Stable and New ReplicaSets are not overwhelmed by the traffic sent to them. By leaving the Stable ReplicaSet scaled up, the controller is ensuring that the Stable ReplicaSet can handle 100% of the traffic at any time 1 . The New ReplicaSet follows the same behavior as without traffic management. The new ReplicaSet's replica count is equal to the latest SetWeight step percentage multiple by the total replica count of the Rollout. This calculation ensures that the canary version does not receive more traffic than it can handle. The Rollout has to assume that the application can handle 100% of traffic if it is fully scaled up. It should outsource to the HPA to detect if the Rollout needs to more replicas if 100% isn't enough. \u21a9","title":"How does Argo Rollouts enable traffic management?"},{"location":"features/traffic-management/alb/","text":"AWS Application Load Balancer (ALB) \u00b6 Requirements \u00b6 ALB Ingress Controller v1.1.5 or greater Overview \u00b6 AWS ALB Ingress Controller enables traffic management through an Ingress object which configures an ALB to route traffic to one or more Kubernetes services. ALBs supports the ability to split traffic through the concept of weighted target groups . This feature is supported by the AWS ALB Ingress Controller through annotations made in the Ingress object to configure \"actions\". ALBs are configured via listeners and rules with actions. Listeners define how traffic from client comes in, and rules define how to handle those requests with various actions. One action allows users to forward traffic to multiple TargetGroups (with each being defined as a Kubernetes service) You can read more about ALB concepts here . An ALB Ingress defines a desired ALB with listener and rules through its annotations and spec. To leverage multiple target groups, ALB Ingress controller looks to an annotation on an Ingress called alb.ingress.kubernetes.io/actions.<service-name> . To indicate that the action annotation should be used for an specific ingress rule, the value \"use-annotations\" is used as the port value in lieue of a named or numeric port. Below is an example of an ingress which splits traffic between two Kubernetes services, canary-service and stable-service, with a traffic weight of 80 and 20 respectively: apiVersion : extensions/v1beta1 kind : Ingress metadata : annotations : alb.ingress.kubernetes.io/actions.stable-service : | { \"Type\":\"forward\", \"ForwardConfig\":{ \"TargetGroups\":[ { \"Weight\":10, \"ServiceName\":\"canary-service\", \"ServicePort\":\"80\" }, { \"Weight\":90, \"ServiceName\":\"stable-service\", \"ServicePort\":\"80\" } ] } } kubernetes.io/ingress.class : alb name : ingress spec : rules : - http : paths : - backend : serviceName : stable-service servicePort : use-annotation path : /* This Ingress uses the alb.ingress.kubernetes.io/actions.stable-service annotation to define how to route traffic to the various services for the rule with the stable-service serviceName instead of sending traffic to the canary-service service. You can read more about these annotations on the official documentation . Integration with Argo Rollouts \u00b6 To configure a Rollout to split traffic between the canary and stable services during update via its ALB integration, the following fields should be specified: apiVersion : argoproj.io/v1alpha1 kind : Rollout spec : strategy : canary : canaryService : canary-service # required stableService : stable-service # required trafficRouting : alb : ingress : ingress # required servicePort : 443 # required rootService : # optional annotationPrefix : custom.alb.ingress.kubernetes.io # optional The ingress field is a reference to an Ingress in the same namespace of the Rollout, and the servicePort field refers a port of a service. The Rollout requires the Ingress and servicePort to modify the ALB to route traffic to the stable and canary Services. Within the Ingress, looks for the stableService (or the optional rootService if specified) within the Ingress's rules and adds an action annotation for that the action. As the Rollout progresses through the Canary steps, the controller updates the Ingress's action annotation to reflect the desired state of the Rollout enabling traffic splitting between two different versions. Since the ALB Ingress controller allows users to configure the annotation prefix used by the Ingress controller, Rollouts can specify the optional annotationPrefix field. The Ingress uses that prefix instead of the default alb.ingress.kubernetes.io if the field set. The Rollout adds another annotation called rollouts.argoproj.io/managed-alb-actions to the Ingress to help the controller manage the Ingresses. This annotation indicates which actions are being managed by Rollout objects (since multiple Rollouts can reference one Ingress). If a Rollout is deleted, the Argo Rollouts controller uses this annotation to see that this action is no longer managed, and it is reset to only the stable service with 100 weight. Using Argo Rollouts with multiple ALB ingress controllers \u00b6 As a default, the Argo Rollouts controller only operates on ingresses with the kubernetes.io/ingress.class annotation set to alb . A user can configure the controller to operate on Ingresses with different kubernetes.io/ingress.class values by specifying the --alb-ingress-classes flag. A user can list the --alb-ingress-classes flag multiple times if the Argo Rollouts controller should operate on multiple values. This may be desired when a cluster has multiple Ingress controllers that operate on different kubernetes.io/ingress.class values. If the controller needs to operate on any Ingress without the kubernetes.io/ingress.class annotation, the flag can be specified with an empty string (e.g. --alb-ingress-classes '' ).","title":"AWS ALB"},{"location":"features/traffic-management/alb/#aws-application-load-balancer-alb","text":"","title":"AWS Application Load Balancer (ALB)"},{"location":"features/traffic-management/alb/#requirements","text":"ALB Ingress Controller v1.1.5 or greater","title":"Requirements"},{"location":"features/traffic-management/alb/#overview","text":"AWS ALB Ingress Controller enables traffic management through an Ingress object which configures an ALB to route traffic to one or more Kubernetes services. ALBs supports the ability to split traffic through the concept of weighted target groups . This feature is supported by the AWS ALB Ingress Controller through annotations made in the Ingress object to configure \"actions\". ALBs are configured via listeners and rules with actions. Listeners define how traffic from client comes in, and rules define how to handle those requests with various actions. One action allows users to forward traffic to multiple TargetGroups (with each being defined as a Kubernetes service) You can read more about ALB concepts here . An ALB Ingress defines a desired ALB with listener and rules through its annotations and spec. To leverage multiple target groups, ALB Ingress controller looks to an annotation on an Ingress called alb.ingress.kubernetes.io/actions.<service-name> . To indicate that the action annotation should be used for an specific ingress rule, the value \"use-annotations\" is used as the port value in lieue of a named or numeric port. Below is an example of an ingress which splits traffic between two Kubernetes services, canary-service and stable-service, with a traffic weight of 80 and 20 respectively: apiVersion : extensions/v1beta1 kind : Ingress metadata : annotations : alb.ingress.kubernetes.io/actions.stable-service : | { \"Type\":\"forward\", \"ForwardConfig\":{ \"TargetGroups\":[ { \"Weight\":10, \"ServiceName\":\"canary-service\", \"ServicePort\":\"80\" }, { \"Weight\":90, \"ServiceName\":\"stable-service\", \"ServicePort\":\"80\" } ] } } kubernetes.io/ingress.class : alb name : ingress spec : rules : - http : paths : - backend : serviceName : stable-service servicePort : use-annotation path : /* This Ingress uses the alb.ingress.kubernetes.io/actions.stable-service annotation to define how to route traffic to the various services for the rule with the stable-service serviceName instead of sending traffic to the canary-service service. You can read more about these annotations on the official documentation .","title":"Overview"},{"location":"features/traffic-management/alb/#integration-with-argo-rollouts","text":"To configure a Rollout to split traffic between the canary and stable services during update via its ALB integration, the following fields should be specified: apiVersion : argoproj.io/v1alpha1 kind : Rollout spec : strategy : canary : canaryService : canary-service # required stableService : stable-service # required trafficRouting : alb : ingress : ingress # required servicePort : 443 # required rootService : # optional annotationPrefix : custom.alb.ingress.kubernetes.io # optional The ingress field is a reference to an Ingress in the same namespace of the Rollout, and the servicePort field refers a port of a service. The Rollout requires the Ingress and servicePort to modify the ALB to route traffic to the stable and canary Services. Within the Ingress, looks for the stableService (or the optional rootService if specified) within the Ingress's rules and adds an action annotation for that the action. As the Rollout progresses through the Canary steps, the controller updates the Ingress's action annotation to reflect the desired state of the Rollout enabling traffic splitting between two different versions. Since the ALB Ingress controller allows users to configure the annotation prefix used by the Ingress controller, Rollouts can specify the optional annotationPrefix field. The Ingress uses that prefix instead of the default alb.ingress.kubernetes.io if the field set. The Rollout adds another annotation called rollouts.argoproj.io/managed-alb-actions to the Ingress to help the controller manage the Ingresses. This annotation indicates which actions are being managed by Rollout objects (since multiple Rollouts can reference one Ingress). If a Rollout is deleted, the Argo Rollouts controller uses this annotation to see that this action is no longer managed, and it is reset to only the stable service with 100 weight.","title":"Integration with Argo Rollouts"},{"location":"features/traffic-management/alb/#using-argo-rollouts-with-multiple-alb-ingress-controllers","text":"As a default, the Argo Rollouts controller only operates on ingresses with the kubernetes.io/ingress.class annotation set to alb . A user can configure the controller to operate on Ingresses with different kubernetes.io/ingress.class values by specifying the --alb-ingress-classes flag. A user can list the --alb-ingress-classes flag multiple times if the Argo Rollouts controller should operate on multiple values. This may be desired when a cluster has multiple Ingress controllers that operate on different kubernetes.io/ingress.class values. If the controller needs to operate on any Ingress without the kubernetes.io/ingress.class annotation, the flag can be specified with an empty string (e.g. --alb-ingress-classes '' ).","title":"Using Argo Rollouts with multiple ALB ingress controllers"},{"location":"features/traffic-management/istio/","text":"Istio \u00b6 Istio is one of the most popular service mesh in the community and offers a rich feature-set to control the flow of traffic. Istio offers this functionality through a set of CRDs, and the Argo Rollouts controller modifies these resources to manipulate the traffic routing into the desired state. However, the Argo Rollouts controller modifies the Istio resources minimally to gives the developer flexibility while configuring their resources. Istio and Rollouts \u00b6 The Argo Rollout controller achieves traffic shaping by manipulating the Virtual Service. A Virtual Service provides the flexibility to define how to route traffic when a host address is hit. The Argo Rollouts controller manipulates the Virtual Service by using the following Rollout configuration: Canary Service name Stable Service name Virtual Service Name Which HTTP Routes in the Virtual Service Below is an example of a Rollout with all the required fields configured: apiVersion : argoproj.io/v1alpha1 kind : Rollout metadata : name : rollout-example spec : ... strategy : canary : steps : - setWeight : 5 - pause : duration : 10m canaryService : canary-svc # required stableService : stable-svc # required trafficRouting : istio : virtualService : name : rollout-vsvc # required routes : - primary # At least one route is required The controller looks for both the canary and stable service listed as destination hosts within the HTTP routes of the specified Virtual Service and modifies the weights of the destinations as desired. The above Rollout expects that there is a virtual service named rollout-vsvc with an HTTP route named primary . That route should have exactly two destinations: canary-service and stable-svc Services. The canary-svc and stable-svc are required because they indicate to Istio which Pods are the Stable and Canary pods. Here is a Virtual Service that works with the Rollout specified above: apiVersion : networking.istio.io/v1alpha3 kind : VirtualService metadata : name : rollout-vsvc spec : gateways : - istio-rollout-gateway hosts : - istio-rollout.dev.argoproj.io http : - name : primary route : - destination : host : stable-svc weight : 100 - destination : host : canary-svc weight : 0 When the above Rollout progresses through its steps, the controller changes Virtual Service's stable-svc 's weight to 95 and canary-svc 's to 5, wait 5 minutes, and then scales up the canary ReplicaSet to a full replica count. Once it is entirely healthy, the controller changes stable-svc 's selector to point at the canary ReplicaSet and switch the weight back to 100 to stable-svc and 0 to canary-svc . Note The Rollout does not make any other assumptions about the fields within the Virtual Service or the Istio mesh. The user could specify additional configurations for the virtual service like URI rewrite rules on the primary route or any other route if desired. The user can also create specific destination rules for each of the services. Integrating with GitOps \u00b6 The above strategy introduces a problem for users practicing GitOps. The Rollout requires the user-defined Virtual Service to define an HTTP route with both destinations hosts. However, Istio requires routes with multiple destinations to assign a weight to each destination. Since the Argo Rollout controller modifies these Virtual Service's weights as a Rollout progresses through its steps, the Virtual Service becomes out of sync with the Git version. Additionally, if a GitOps tool does an apply after the Argo Rollouts controller changes the Virtual Service's weight, the apply would revert the weight to the percentage stored in the Git repo. At best, the user can specify the desired weight of 100% to the stable service and 0% to the canary service. In this case, the Virtual Service is synced with the Git repo when the Rollout completed all the steps. Argo CD has an open issue here to address this problem. The proposed solution is to introduce an annotation to the VirtualService which tells Argo CD controller to respect the current weights listed and let the Argo Rollouts controller manage them instead. Alternatives Considered \u00b6 Rollout ownership over the Virtual Service \u00b6 Instead of the controller modifying a reference to a Virtual Service, the Rollout controller would create, manage, and own a Virtual Service. While this approach is GitOps friendly, it introduces other issues: To provide the same flexibility as referencing Virtual Service within a Rollout, the Rollout needs to inline a large portion of the Istio spec. However, networking is outside the responsibility of the Rollout and makes the Rollout spec unnecessary complicated. If Istio introduces a feature, that feature will not be available in Argo Rollouts until implemented within Argo Rollouts. Both of these issues adds more complexity to the users and Argo Rollouts developers compared to referencing a Virtual Service. Istio support through the SMI Adapter for Istio \u00b6 SMI is the Service Mesh Interface, which serves as a standard interface for all common features of a service mesh. This feature is GitOps friendly, but native Istio has extra functionality that SMI does not currently provide.","title":"Istio"},{"location":"features/traffic-management/istio/#istio","text":"Istio is one of the most popular service mesh in the community and offers a rich feature-set to control the flow of traffic. Istio offers this functionality through a set of CRDs, and the Argo Rollouts controller modifies these resources to manipulate the traffic routing into the desired state. However, the Argo Rollouts controller modifies the Istio resources minimally to gives the developer flexibility while configuring their resources.","title":"Istio"},{"location":"features/traffic-management/istio/#istio-and-rollouts","text":"The Argo Rollout controller achieves traffic shaping by manipulating the Virtual Service. A Virtual Service provides the flexibility to define how to route traffic when a host address is hit. The Argo Rollouts controller manipulates the Virtual Service by using the following Rollout configuration: Canary Service name Stable Service name Virtual Service Name Which HTTP Routes in the Virtual Service Below is an example of a Rollout with all the required fields configured: apiVersion : argoproj.io/v1alpha1 kind : Rollout metadata : name : rollout-example spec : ... strategy : canary : steps : - setWeight : 5 - pause : duration : 10m canaryService : canary-svc # required stableService : stable-svc # required trafficRouting : istio : virtualService : name : rollout-vsvc # required routes : - primary # At least one route is required The controller looks for both the canary and stable service listed as destination hosts within the HTTP routes of the specified Virtual Service and modifies the weights of the destinations as desired. The above Rollout expects that there is a virtual service named rollout-vsvc with an HTTP route named primary . That route should have exactly two destinations: canary-service and stable-svc Services. The canary-svc and stable-svc are required because they indicate to Istio which Pods are the Stable and Canary pods. Here is a Virtual Service that works with the Rollout specified above: apiVersion : networking.istio.io/v1alpha3 kind : VirtualService metadata : name : rollout-vsvc spec : gateways : - istio-rollout-gateway hosts : - istio-rollout.dev.argoproj.io http : - name : primary route : - destination : host : stable-svc weight : 100 - destination : host : canary-svc weight : 0 When the above Rollout progresses through its steps, the controller changes Virtual Service's stable-svc 's weight to 95 and canary-svc 's to 5, wait 5 minutes, and then scales up the canary ReplicaSet to a full replica count. Once it is entirely healthy, the controller changes stable-svc 's selector to point at the canary ReplicaSet and switch the weight back to 100 to stable-svc and 0 to canary-svc . Note The Rollout does not make any other assumptions about the fields within the Virtual Service or the Istio mesh. The user could specify additional configurations for the virtual service like URI rewrite rules on the primary route or any other route if desired. The user can also create specific destination rules for each of the services.","title":"Istio and Rollouts"},{"location":"features/traffic-management/istio/#integrating-with-gitops","text":"The above strategy introduces a problem for users practicing GitOps. The Rollout requires the user-defined Virtual Service to define an HTTP route with both destinations hosts. However, Istio requires routes with multiple destinations to assign a weight to each destination. Since the Argo Rollout controller modifies these Virtual Service's weights as a Rollout progresses through its steps, the Virtual Service becomes out of sync with the Git version. Additionally, if a GitOps tool does an apply after the Argo Rollouts controller changes the Virtual Service's weight, the apply would revert the weight to the percentage stored in the Git repo. At best, the user can specify the desired weight of 100% to the stable service and 0% to the canary service. In this case, the Virtual Service is synced with the Git repo when the Rollout completed all the steps. Argo CD has an open issue here to address this problem. The proposed solution is to introduce an annotation to the VirtualService which tells Argo CD controller to respect the current weights listed and let the Argo Rollouts controller manage them instead.","title":"Integrating with GitOps"},{"location":"features/traffic-management/istio/#alternatives-considered","text":"","title":"Alternatives Considered"},{"location":"features/traffic-management/istio/#rollout-ownership-over-the-virtual-service","text":"Instead of the controller modifying a reference to a Virtual Service, the Rollout controller would create, manage, and own a Virtual Service. While this approach is GitOps friendly, it introduces other issues: To provide the same flexibility as referencing Virtual Service within a Rollout, the Rollout needs to inline a large portion of the Istio spec. However, networking is outside the responsibility of the Rollout and makes the Rollout spec unnecessary complicated. If Istio introduces a feature, that feature will not be available in Argo Rollouts until implemented within Argo Rollouts. Both of these issues adds more complexity to the users and Argo Rollouts developers compared to referencing a Virtual Service.","title":"Rollout ownership over the Virtual Service"},{"location":"features/traffic-management/istio/#istio-support-through-the-smi-adapter-for-istio","text":"SMI is the Service Mesh Interface, which serves as a standard interface for all common features of a service mesh. This feature is GitOps friendly, but native Istio has extra functionality that SMI does not currently provide.","title":"Istio support through the SMI Adapter for Istio"},{"location":"features/traffic-management/nginx/","text":"Nginx \u00b6 The Nginx Ingress Controller enables traffic management through one or more Ingress objects to configure an Nginx deployment that routes traffic directly to pods. Each Nginx Ingress contains multiple annotations that modify the behavior of the Nginx Deployment. For traffic management between different versions of an application, the Nginx Ingress controller provides the capability to split traffic by introducing a second Ingress object (referred to as the canary Ingress) with some special annotations. You can read more about these canary annotations on the official canary annotations documentation page . The canary Ingress ignores any other non-canary nginx annotations. Instead, it leverages the annotation settings from the primary Ingress. The Rollout controller will always set the following two annotations on the canary Ingress (using your configured or the default nginx.ingress.kubernetes.io prefix): canary: true to indicate that this is the canary Ingress canary-weight: <num> to indicate what percentage of traffic to send to the canary. If all traffic is routed to the stable Service, this is set to 0 You can provide additional annotations to add to the canary Ingress via the additionalIngressAnnotations field to enable features like routing by header or cookie. Integration with Argo Rollouts \u00b6 There are a couple of required fields in a Rollout to send split traffic between versions using Nginx. Below is an example of a Rollout with those fields: apiVersion : argoproj.io/v1alpha1 kind : Rollout spec : ... strategy : canary : canaryService : canary-service # required stableService : stable-service # required trafficRouting : nginx : stableIngress : primary-ingress # required annotationPrefix : customingress.nginx.ingress.kubernetes.io # optional additionalIngressAnnotations : # optional canary-by-header : X-Canary canary-by-header-value : iwantsit The stable Ingress field is a reference to an Ingress in the same namespace of the Rollout. The Rollout requires the primary Ingress routes traffic to the stable Service. The Rollout checks that condition by confirming the Ingress has a backend that matches the Rollout's stableService. The controller routes traffic to the canary Service by creating a second Ingress with the canary annotations. As the Rollout progresses through the Canary steps, the controller updates the canary Ingress's canary annotations to reflect the desired state of the Rollout enabling traffic splitting between two different versions. Since the Nginx Ingress controller allows users to configure the annotation prefix used by the Ingress controller, Rollouts can specify the optional annotationPrefix field. The canary Ingress uses that prefix instead of the default nginx.ingress.kubernetes.io if the field set. Using Argo Rollouts with multiple NGINX ingress controllers \u00b6 As a default, the Argo Rollouts controller only operates on ingresses with the kubernetes.io/ingress.class annotation set to nginx . A user can configure the controller to operate on Ingresses with different kubernetes.io/ingress.class values by specifying the --nginx-ingress-classes flag. A user can list the --nginx-ingress-classes flag multiple times if the Argo Rollouts controller should operate on multiple values. This solves the case where a cluster has multiple Ingress controllers operating on different kubernetes.io/ingress.class values. If the user would like the controller to operate on any Ingress without the kubernetes.io/ingress.class annotation, a user should add the following --nginx-ingress-classes '' .","title":"NGINX"},{"location":"features/traffic-management/nginx/#nginx","text":"The Nginx Ingress Controller enables traffic management through one or more Ingress objects to configure an Nginx deployment that routes traffic directly to pods. Each Nginx Ingress contains multiple annotations that modify the behavior of the Nginx Deployment. For traffic management between different versions of an application, the Nginx Ingress controller provides the capability to split traffic by introducing a second Ingress object (referred to as the canary Ingress) with some special annotations. You can read more about these canary annotations on the official canary annotations documentation page . The canary Ingress ignores any other non-canary nginx annotations. Instead, it leverages the annotation settings from the primary Ingress. The Rollout controller will always set the following two annotations on the canary Ingress (using your configured or the default nginx.ingress.kubernetes.io prefix): canary: true to indicate that this is the canary Ingress canary-weight: <num> to indicate what percentage of traffic to send to the canary. If all traffic is routed to the stable Service, this is set to 0 You can provide additional annotations to add to the canary Ingress via the additionalIngressAnnotations field to enable features like routing by header or cookie.","title":"Nginx"},{"location":"features/traffic-management/nginx/#integration-with-argo-rollouts","text":"There are a couple of required fields in a Rollout to send split traffic between versions using Nginx. Below is an example of a Rollout with those fields: apiVersion : argoproj.io/v1alpha1 kind : Rollout spec : ... strategy : canary : canaryService : canary-service # required stableService : stable-service # required trafficRouting : nginx : stableIngress : primary-ingress # required annotationPrefix : customingress.nginx.ingress.kubernetes.io # optional additionalIngressAnnotations : # optional canary-by-header : X-Canary canary-by-header-value : iwantsit The stable Ingress field is a reference to an Ingress in the same namespace of the Rollout. The Rollout requires the primary Ingress routes traffic to the stable Service. The Rollout checks that condition by confirming the Ingress has a backend that matches the Rollout's stableService. The controller routes traffic to the canary Service by creating a second Ingress with the canary annotations. As the Rollout progresses through the Canary steps, the controller updates the canary Ingress's canary annotations to reflect the desired state of the Rollout enabling traffic splitting between two different versions. Since the Nginx Ingress controller allows users to configure the annotation prefix used by the Ingress controller, Rollouts can specify the optional annotationPrefix field. The canary Ingress uses that prefix instead of the default nginx.ingress.kubernetes.io if the field set.","title":"Integration with Argo Rollouts"},{"location":"features/traffic-management/nginx/#using-argo-rollouts-with-multiple-nginx-ingress-controllers","text":"As a default, the Argo Rollouts controller only operates on ingresses with the kubernetes.io/ingress.class annotation set to nginx . A user can configure the controller to operate on Ingresses with different kubernetes.io/ingress.class values by specifying the --nginx-ingress-classes flag. A user can list the --nginx-ingress-classes flag multiple times if the Argo Rollouts controller should operate on multiple values. This solves the case where a cluster has multiple Ingress controllers operating on different kubernetes.io/ingress.class values. If the user would like the controller to operate on any Ingress without the kubernetes.io/ingress.class annotation, a user should add the following --nginx-ingress-classes '' .","title":"Using Argo Rollouts with multiple NGINX ingress controllers"},{"location":"features/traffic-management/smi/","text":"Service Mesh Interface (SMI) \u00b6 Important Available since v0.9.0 Service Mesh Interface (SMI) is a standard interface for service meshes on Kubernetes leveraged by many Service Mesh implementations (like Linkerd). SMI offers this functionality through a set of CRDs, and the Argo Rollouts controller creates these resources to manipulate the traffic routing into the desired state. The Argo Rollout controller achieves traffic shaping by creating and manipulating the TrafficSplit CR . A TrafficSplit describes the desired traffic routing for an application and relies on the underlying Service Meshes implement that desired state. Instead of worrying about the details of a specific service mesh, a user needs to specify a root Service that clients use to communicate and a list of backends consisting of a Service and weight. The Service Mesh implementing SMI uses this spec to route traffic to the backends Services based on the weights of the backends. For Rollout users, the Argo Rollout controller create and manipulates the TrafficSplit using the following information: Canary Service: Name of the service that sends traffic only to the canary pods Stable Service: Name of the service that sends traffic only to the stable po ds Root Service: Name of the service that clients use to communicate. If a request comes to this root service not through a proxy, the standard Kubernetes service routing will be used. Below is an example of a Rollout with all the required fields configured: apiVersion : argoproj.io/v1alpha1 kind : Rollout metadata : name : rollout-example spec : ... strategy : canary : steps : - setWeight : 5 - pause : duration : 600 canaryService : canary-svc # required stableService : stable-svc # required trafficRouting : smi : rootService : root-svc # optional trafficSplitName : rollout-example-traffic-split # optional With the above configuration, the controller can automate dynamic traffic splitting. First, the controller manipulates the canary and stable Service listed in the Rollout to make them only receive traffic from the respective canary and stable ReplicaSets. The controller achieves this by adding the ReplicaSet's unique pod template hash to that Service's selector. With the stable and canary Services configured, the controller creates a TrafficSplit using these Services in the backend, and the weights of the backend are dynamically configured from the current desired weight of the Rollout's canary steps. The controller sets the TrafficSplit's root service to the stableService unless the Rollout has the rootService field specified. This configured TrafficSplit along with the Service and Rollout resources enable fine-grained percentages of traffic between two versions of an application. Optionally, the user can specify a name for the traffic split. If there is no name listed in the Rollout, the controller uses the Rollout's name for the TrafficSplit. If a TrafficSplit with that name already exists and isn't owned by that Rollout, the controller marks the Rollout as an error state. Here is the TrafficSplit created from the above Rollout: apiVersion : split.smi-spec.io/v1alpha1 kind : TrafficSplit metadata : name : rollout-example-traffic-split spec : service : root-svc # controller uses the stableService if Rollout does not specify the rootService field backends : - service : stable-svc weight : 95 - service : canary-svc weight : 5 As a Rollout progresses through all its steps, the controller updates the TrafficSplit's backend weights to reflect the current weight of the Rollout. When the Rollout has successfully finished executing all the steps, the controller modifies the stable Service's selector to point at the desired ReplicaSet and TrafficSplit's weight to send 100% of traffic to the stable Service. Note The controller defaults to using the v1alpha1 version of the TrafficSplit. The Argo Rollouts operator can change the api version used by specifying a --traffic-split-api-version flag in the controller args.","title":"SMI"},{"location":"features/traffic-management/smi/#service-mesh-interface-smi","text":"Important Available since v0.9.0 Service Mesh Interface (SMI) is a standard interface for service meshes on Kubernetes leveraged by many Service Mesh implementations (like Linkerd). SMI offers this functionality through a set of CRDs, and the Argo Rollouts controller creates these resources to manipulate the traffic routing into the desired state. The Argo Rollout controller achieves traffic shaping by creating and manipulating the TrafficSplit CR . A TrafficSplit describes the desired traffic routing for an application and relies on the underlying Service Meshes implement that desired state. Instead of worrying about the details of a specific service mesh, a user needs to specify a root Service that clients use to communicate and a list of backends consisting of a Service and weight. The Service Mesh implementing SMI uses this spec to route traffic to the backends Services based on the weights of the backends. For Rollout users, the Argo Rollout controller create and manipulates the TrafficSplit using the following information: Canary Service: Name of the service that sends traffic only to the canary pods Stable Service: Name of the service that sends traffic only to the stable po ds Root Service: Name of the service that clients use to communicate. If a request comes to this root service not through a proxy, the standard Kubernetes service routing will be used. Below is an example of a Rollout with all the required fields configured: apiVersion : argoproj.io/v1alpha1 kind : Rollout metadata : name : rollout-example spec : ... strategy : canary : steps : - setWeight : 5 - pause : duration : 600 canaryService : canary-svc # required stableService : stable-svc # required trafficRouting : smi : rootService : root-svc # optional trafficSplitName : rollout-example-traffic-split # optional With the above configuration, the controller can automate dynamic traffic splitting. First, the controller manipulates the canary and stable Service listed in the Rollout to make them only receive traffic from the respective canary and stable ReplicaSets. The controller achieves this by adding the ReplicaSet's unique pod template hash to that Service's selector. With the stable and canary Services configured, the controller creates a TrafficSplit using these Services in the backend, and the weights of the backend are dynamically configured from the current desired weight of the Rollout's canary steps. The controller sets the TrafficSplit's root service to the stableService unless the Rollout has the rootService field specified. This configured TrafficSplit along with the Service and Rollout resources enable fine-grained percentages of traffic between two versions of an application. Optionally, the user can specify a name for the traffic split. If there is no name listed in the Rollout, the controller uses the Rollout's name for the TrafficSplit. If a TrafficSplit with that name already exists and isn't owned by that Rollout, the controller marks the Rollout as an error state. Here is the TrafficSplit created from the above Rollout: apiVersion : split.smi-spec.io/v1alpha1 kind : TrafficSplit metadata : name : rollout-example-traffic-split spec : service : root-svc # controller uses the stableService if Rollout does not specify the rootService field backends : - service : stable-svc weight : 95 - service : canary-svc weight : 5 As a Rollout progresses through all its steps, the controller updates the TrafficSplit's backend weights to reflect the current weight of the Rollout. When the Rollout has successfully finished executing all the steps, the controller modifies the stable Service's selector to point at the desired ReplicaSet and TrafficSplit's weight to send 100% of traffic to the stable Service. Note The controller defaults to using the v1alpha1 version of the TrafficSplit. The Argo Rollouts operator can change the api version used by specifying a --traffic-split-api-version flag in the controller args.","title":"Service Mesh Interface (SMI)"},{"location":"generated/kubectl-argo-rollouts/kubectl-argo-rollouts/","text":"Rollouts \u00b6 Manage argo rollouts Synopsis \u00b6 This command consists of multiple subcommands which can be used to manage Argo Rollouts. kubectl argo rollouts COMMAND [ flags ] Examples \u00b6 # Get guestbook rollout and watch progress kubectl argo rollouts get rollout guestbook -w # Pause the guestbook rollout kubectl argo rollouts pause guestbook # Promote the guestbook rollout kubectl argo rollouts promote guestbook # Abort the guestbook rollout kubectl argo rollouts abort guestbook # Retry the guestbook rollout kubectl argo rollouts retry guestbook Options \u00b6 --as string Username to impersonate for the operation --as-group stringArray Group to impersonate for the operation, this flag can be repeated to specify multiple groups. --cache-dir string Default HTTP cache directory (default \"/home/runner/.kube/http-cache\") --certificate-authority string Path to a cert file for the certificate authority --client-certificate string Path to a client certificate file for TLS --client-key string Path to a client key file for TLS --cluster string The name of the kubeconfig cluster to use --context string The name of the kubeconfig context to use -h, --help help for kubectl-argo-rollouts --insecure-skip-tls-verify If true, the server's certificate will not be checked for validity. This will make your HTTPS connections insecure -v, --kloglevel int Log level for kubernetes client library --kubeconfig string Path to the kubeconfig file to use for CLI requests. --loglevel string Log level for kubectl argo rollouts (default \"info\") -n, --namespace string If present, the namespace scope for this CLI request --request-timeout string The length of time to wait before giving up on a single server request. Non-zero values should contain a corresponding time unit (e.g. 1s, 2m, 3h). A value of zero means don't timeout requests. (default \"0\") -s, --server string The address and port of the Kubernetes API server --tls-server-name string Server name to use for server certificate validation. If it is not provided, the hostname used to contact the server is used --token string Bearer token for authentication to the API server --user string The name of the kubeconfig user to use Available Commands \u00b6 rollouts abort - Abort a rollout rollouts create - Create a Rollout, Experiment, AnalysisTemplate, ClusterAnalysisTemplate, or AnalysisRun resource rollouts get - Get details about rollouts and experiments rollouts list - List rollouts or experiments rollouts pause - Pause a rollout rollouts promote - Promote a rollout rollouts restart - Restart the pods of a rollout rollouts retry - Retry a rollout or experiment rollouts set - Update various values on resources rollouts terminate - Terminate an AnalysisRun or Experiment rollouts version - Print version","title":"Rollouts"},{"location":"generated/kubectl-argo-rollouts/kubectl-argo-rollouts/#rollouts","text":"Manage argo rollouts","title":"Rollouts"},{"location":"generated/kubectl-argo-rollouts/kubectl-argo-rollouts/#synopsis","text":"This command consists of multiple subcommands which can be used to manage Argo Rollouts. kubectl argo rollouts COMMAND [ flags ]","title":"Synopsis"},{"location":"generated/kubectl-argo-rollouts/kubectl-argo-rollouts/#examples","text":"# Get guestbook rollout and watch progress kubectl argo rollouts get rollout guestbook -w # Pause the guestbook rollout kubectl argo rollouts pause guestbook # Promote the guestbook rollout kubectl argo rollouts promote guestbook # Abort the guestbook rollout kubectl argo rollouts abort guestbook # Retry the guestbook rollout kubectl argo rollouts retry guestbook","title":"Examples"},{"location":"generated/kubectl-argo-rollouts/kubectl-argo-rollouts/#options","text":"--as string Username to impersonate for the operation --as-group stringArray Group to impersonate for the operation, this flag can be repeated to specify multiple groups. --cache-dir string Default HTTP cache directory (default \"/home/runner/.kube/http-cache\") --certificate-authority string Path to a cert file for the certificate authority --client-certificate string Path to a client certificate file for TLS --client-key string Path to a client key file for TLS --cluster string The name of the kubeconfig cluster to use --context string The name of the kubeconfig context to use -h, --help help for kubectl-argo-rollouts --insecure-skip-tls-verify If true, the server's certificate will not be checked for validity. This will make your HTTPS connections insecure -v, --kloglevel int Log level for kubernetes client library --kubeconfig string Path to the kubeconfig file to use for CLI requests. --loglevel string Log level for kubectl argo rollouts (default \"info\") -n, --namespace string If present, the namespace scope for this CLI request --request-timeout string The length of time to wait before giving up on a single server request. Non-zero values should contain a corresponding time unit (e.g. 1s, 2m, 3h). A value of zero means don't timeout requests. (default \"0\") -s, --server string The address and port of the Kubernetes API server --tls-server-name string Server name to use for server certificate validation. If it is not provided, the hostname used to contact the server is used --token string Bearer token for authentication to the API server --user string The name of the kubeconfig user to use","title":"Options"},{"location":"generated/kubectl-argo-rollouts/kubectl-argo-rollouts/#available-commands","text":"rollouts abort - Abort a rollout rollouts create - Create a Rollout, Experiment, AnalysisTemplate, ClusterAnalysisTemplate, or AnalysisRun resource rollouts get - Get details about rollouts and experiments rollouts list - List rollouts or experiments rollouts pause - Pause a rollout rollouts promote - Promote a rollout rollouts restart - Restart the pods of a rollout rollouts retry - Retry a rollout or experiment rollouts set - Update various values on resources rollouts terminate - Terminate an AnalysisRun or Experiment rollouts version - Print version","title":"Available Commands"},{"location":"generated/kubectl-argo-rollouts/kubectl-argo-rollouts_abort/","text":"Rollouts Abort \u00b6 Abort a rollout Synopsis \u00b6 This command stops progressing the current rollout and reverts all steps. The previous ReplicaSet will be active. Note the 'spec.template' still represents the new rollout version. If the Rollout leaves the aborted state, it will try to go to the new version. Updating the 'spec.template' back to the previous version will fully revert the rollout. kubectl argo rollouts abort ROLLOUT_NAME [ flags ] Examples \u00b6 # Abort a rollout kubectl argo rollouts abort guestbook Options \u00b6 -h, --help help for abort Options inherited from parent commands \u00b6 --as string Username to impersonate for the operation --as-group stringArray Group to impersonate for the operation, this flag can be repeated to specify multiple groups. --cache-dir string Default HTTP cache directory (default \"/home/runner/.kube/http-cache\") --certificate-authority string Path to a cert file for the certificate authority --client-certificate string Path to a client certificate file for TLS --client-key string Path to a client key file for TLS --cluster string The name of the kubeconfig cluster to use --context string The name of the kubeconfig context to use --insecure-skip-tls-verify If true, the server's certificate will not be checked for validity. This will make your HTTPS connections insecure -v, --kloglevel int Log level for kubernetes client library --kubeconfig string Path to the kubeconfig file to use for CLI requests. --loglevel string Log level for kubectl argo rollouts (default \"info\") -n, --namespace string If present, the namespace scope for this CLI request --request-timeout string The length of time to wait before giving up on a single server request. Non-zero values should contain a corresponding time unit (e.g. 1s, 2m, 3h). A value of zero means don't timeout requests. (default \"0\") -s, --server string The address and port of the Kubernetes API server --tls-server-name string Server name to use for server certificate validation. If it is not provided, the hostname used to contact the server is used --token string Bearer token for authentication to the API server --user string The name of the kubeconfig user to use See Also \u00b6 rollouts - Manage argo rollouts","title":"Rollouts Abort"},{"location":"generated/kubectl-argo-rollouts/kubectl-argo-rollouts_abort/#rollouts-abort","text":"Abort a rollout","title":"Rollouts Abort"},{"location":"generated/kubectl-argo-rollouts/kubectl-argo-rollouts_abort/#synopsis","text":"This command stops progressing the current rollout and reverts all steps. The previous ReplicaSet will be active. Note the 'spec.template' still represents the new rollout version. If the Rollout leaves the aborted state, it will try to go to the new version. Updating the 'spec.template' back to the previous version will fully revert the rollout. kubectl argo rollouts abort ROLLOUT_NAME [ flags ]","title":"Synopsis"},{"location":"generated/kubectl-argo-rollouts/kubectl-argo-rollouts_abort/#examples","text":"# Abort a rollout kubectl argo rollouts abort guestbook","title":"Examples"},{"location":"generated/kubectl-argo-rollouts/kubectl-argo-rollouts_abort/#options","text":"-h, --help help for abort","title":"Options"},{"location":"generated/kubectl-argo-rollouts/kubectl-argo-rollouts_abort/#options-inherited-from-parent-commands","text":"--as string Username to impersonate for the operation --as-group stringArray Group to impersonate for the operation, this flag can be repeated to specify multiple groups. --cache-dir string Default HTTP cache directory (default \"/home/runner/.kube/http-cache\") --certificate-authority string Path to a cert file for the certificate authority --client-certificate string Path to a client certificate file for TLS --client-key string Path to a client key file for TLS --cluster string The name of the kubeconfig cluster to use --context string The name of the kubeconfig context to use --insecure-skip-tls-verify If true, the server's certificate will not be checked for validity. This will make your HTTPS connections insecure -v, --kloglevel int Log level for kubernetes client library --kubeconfig string Path to the kubeconfig file to use for CLI requests. --loglevel string Log level for kubectl argo rollouts (default \"info\") -n, --namespace string If present, the namespace scope for this CLI request --request-timeout string The length of time to wait before giving up on a single server request. Non-zero values should contain a corresponding time unit (e.g. 1s, 2m, 3h). A value of zero means don't timeout requests. (default \"0\") -s, --server string The address and port of the Kubernetes API server --tls-server-name string Server name to use for server certificate validation. If it is not provided, the hostname used to contact the server is used --token string Bearer token for authentication to the API server --user string The name of the kubeconfig user to use","title":"Options inherited from parent commands"},{"location":"generated/kubectl-argo-rollouts/kubectl-argo-rollouts_abort/#see-also","text":"rollouts - Manage argo rollouts","title":"See Also"},{"location":"generated/kubectl-argo-rollouts/kubectl-argo-rollouts_create/","text":"Rollouts Create \u00b6 Create a Rollout, Experiment, AnalysisTemplate, ClusterAnalysisTemplate, or AnalysisRun resource Synopsis \u00b6 This command creates a new Rollout, Experiment, AnalysisTemplate, ClusterAnalysisTemplate, or AnalysisRun resource from a file. kubectl argo rollouts create [ flags ] Examples \u00b6 # Create an experiment and watch it kubectl argo rollouts create -f my-experiment.yaml -w Options \u00b6 -f, --filename stringArray Files to use to create the resource -h, --help help for create --no-color Do not colorize output -w, --watch Watch live updates to the resource after creating Options inherited from parent commands \u00b6 --as string Username to impersonate for the operation --as-group stringArray Group to impersonate for the operation, this flag can be repeated to specify multiple groups. --cache-dir string Default HTTP cache directory (default \"/home/runner/.kube/http-cache\") --certificate-authority string Path to a cert file for the certificate authority --client-certificate string Path to a client certificate file for TLS --client-key string Path to a client key file for TLS --cluster string The name of the kubeconfig cluster to use --context string The name of the kubeconfig context to use --insecure-skip-tls-verify If true, the server's certificate will not be checked for validity. This will make your HTTPS connections insecure -v, --kloglevel int Log level for kubernetes client library --kubeconfig string Path to the kubeconfig file to use for CLI requests. --loglevel string Log level for kubectl argo rollouts (default \"info\") -n, --namespace string If present, the namespace scope for this CLI request --request-timeout string The length of time to wait before giving up on a single server request. Non-zero values should contain a corresponding time unit (e.g. 1s, 2m, 3h). A value of zero means don't timeout requests. (default \"0\") -s, --server string The address and port of the Kubernetes API server --tls-server-name string Server name to use for server certificate validation. If it is not provided, the hostname used to contact the server is used --token string Bearer token for authentication to the API server --user string The name of the kubeconfig user to use Available Commands \u00b6 rollouts create analysisrun - Create an AnalysisRun from an AnalysisTemplate or a ClusterAnalysisTemplate See Also \u00b6 rollouts - Manage argo rollouts","title":"Rollouts Create"},{"location":"generated/kubectl-argo-rollouts/kubectl-argo-rollouts_create/#rollouts-create","text":"Create a Rollout, Experiment, AnalysisTemplate, ClusterAnalysisTemplate, or AnalysisRun resource","title":"Rollouts Create"},{"location":"generated/kubectl-argo-rollouts/kubectl-argo-rollouts_create/#synopsis","text":"This command creates a new Rollout, Experiment, AnalysisTemplate, ClusterAnalysisTemplate, or AnalysisRun resource from a file. kubectl argo rollouts create [ flags ]","title":"Synopsis"},{"location":"generated/kubectl-argo-rollouts/kubectl-argo-rollouts_create/#examples","text":"# Create an experiment and watch it kubectl argo rollouts create -f my-experiment.yaml -w","title":"Examples"},{"location":"generated/kubectl-argo-rollouts/kubectl-argo-rollouts_create/#options","text":"-f, --filename stringArray Files to use to create the resource -h, --help help for create --no-color Do not colorize output -w, --watch Watch live updates to the resource after creating","title":"Options"},{"location":"generated/kubectl-argo-rollouts/kubectl-argo-rollouts_create/#options-inherited-from-parent-commands","text":"--as string Username to impersonate for the operation --as-group stringArray Group to impersonate for the operation, this flag can be repeated to specify multiple groups. --cache-dir string Default HTTP cache directory (default \"/home/runner/.kube/http-cache\") --certificate-authority string Path to a cert file for the certificate authority --client-certificate string Path to a client certificate file for TLS --client-key string Path to a client key file for TLS --cluster string The name of the kubeconfig cluster to use --context string The name of the kubeconfig context to use --insecure-skip-tls-verify If true, the server's certificate will not be checked for validity. This will make your HTTPS connections insecure -v, --kloglevel int Log level for kubernetes client library --kubeconfig string Path to the kubeconfig file to use for CLI requests. --loglevel string Log level for kubectl argo rollouts (default \"info\") -n, --namespace string If present, the namespace scope for this CLI request --request-timeout string The length of time to wait before giving up on a single server request. Non-zero values should contain a corresponding time unit (e.g. 1s, 2m, 3h). A value of zero means don't timeout requests. (default \"0\") -s, --server string The address and port of the Kubernetes API server --tls-server-name string Server name to use for server certificate validation. If it is not provided, the hostname used to contact the server is used --token string Bearer token for authentication to the API server --user string The name of the kubeconfig user to use","title":"Options inherited from parent commands"},{"location":"generated/kubectl-argo-rollouts/kubectl-argo-rollouts_create/#available-commands","text":"rollouts create analysisrun - Create an AnalysisRun from an AnalysisTemplate or a ClusterAnalysisTemplate","title":"Available Commands"},{"location":"generated/kubectl-argo-rollouts/kubectl-argo-rollouts_create/#see-also","text":"rollouts - Manage argo rollouts","title":"See Also"},{"location":"generated/kubectl-argo-rollouts/kubectl-argo-rollouts_create_analysisrun/","text":"Rollouts Create Analysisrun \u00b6 Create an AnalysisRun from an AnalysisTemplate or a ClusterAnalysisTemplate Synopsis \u00b6 This command creates a new AnalysisRun from an existing AnalysisTemplate resources or from an AnalysisTemplate file. kubectl argo rollouts create analysisrun [ flags ] Examples \u00b6 # Create an AnalysisRun from a local AnalysisTemplate file kubectl argo rollouts create analysisrun --from-file my-analysis-template.yaml # Create an AnalysisRun from a AnalysisTemplate in the cluster kubectl argo rollouts create analysisrun --from my-analysis-template # Create an AnalysisRun from a local ClusterAnalysisTemplate file kubectl argo rollouts create analysisrun --global --from my-analysis-cluster-template.yaml # Create an AnalysisRun from a ClusterAnalysisTemplate in the cluster kubectl argo rollouts create analysisrun --global --from my-analysis-cluster-template Options \u00b6 -a, --argument stringArray Arguments to the parameter template --from string Create an AnalysisRun from an AnalysisTemplate or ClusterAnalysisTemplate in the cluster --from-file string Create an AnalysisRun from an AnalysisTemplate or ClusterAnalysisTemplate in a local file --generate-name string Use the specified generateName for the run --global Use a ClusterAnalysisTemplate instead of a AnalysisTemplate -h, --help help for analysisrun --instance-id string Instance-ID for the AnalysisRun --name string Use the specified name for the run Options inherited from parent commands \u00b6 --as string Username to impersonate for the operation --as-group stringArray Group to impersonate for the operation, this flag can be repeated to specify multiple groups. --cache-dir string Default HTTP cache directory (default \"/home/runner/.kube/http-cache\") --certificate-authority string Path to a cert file for the certificate authority --client-certificate string Path to a client certificate file for TLS --client-key string Path to a client key file for TLS --cluster string The name of the kubeconfig cluster to use --context string The name of the kubeconfig context to use --insecure-skip-tls-verify If true, the server's certificate will not be checked for validity. This will make your HTTPS connections insecure -v, --kloglevel int Log level for kubernetes client library --kubeconfig string Path to the kubeconfig file to use for CLI requests. --loglevel string Log level for kubectl argo rollouts (default \"info\") -n, --namespace string If present, the namespace scope for this CLI request --request-timeout string The length of time to wait before giving up on a single server request. Non-zero values should contain a corresponding time unit (e.g. 1s, 2m, 3h). A value of zero means don't timeout requests. (default \"0\") -s, --server string The address and port of the Kubernetes API server --tls-server-name string Server name to use for server certificate validation. If it is not provided, the hostname used to contact the server is used --token string Bearer token for authentication to the API server --user string The name of the kubeconfig user to use See Also \u00b6 rollouts create - Create a Rollout, Experiment, AnalysisTemplate, ClusterAnalysisTemplate, or AnalysisRun resource","title":"Rollouts Create Analysisrun"},{"location":"generated/kubectl-argo-rollouts/kubectl-argo-rollouts_create_analysisrun/#rollouts-create-analysisrun","text":"Create an AnalysisRun from an AnalysisTemplate or a ClusterAnalysisTemplate","title":"Rollouts Create Analysisrun"},{"location":"generated/kubectl-argo-rollouts/kubectl-argo-rollouts_create_analysisrun/#synopsis","text":"This command creates a new AnalysisRun from an existing AnalysisTemplate resources or from an AnalysisTemplate file. kubectl argo rollouts create analysisrun [ flags ]","title":"Synopsis"},{"location":"generated/kubectl-argo-rollouts/kubectl-argo-rollouts_create_analysisrun/#examples","text":"# Create an AnalysisRun from a local AnalysisTemplate file kubectl argo rollouts create analysisrun --from-file my-analysis-template.yaml # Create an AnalysisRun from a AnalysisTemplate in the cluster kubectl argo rollouts create analysisrun --from my-analysis-template # Create an AnalysisRun from a local ClusterAnalysisTemplate file kubectl argo rollouts create analysisrun --global --from my-analysis-cluster-template.yaml # Create an AnalysisRun from a ClusterAnalysisTemplate in the cluster kubectl argo rollouts create analysisrun --global --from my-analysis-cluster-template","title":"Examples"},{"location":"generated/kubectl-argo-rollouts/kubectl-argo-rollouts_create_analysisrun/#options","text":"-a, --argument stringArray Arguments to the parameter template --from string Create an AnalysisRun from an AnalysisTemplate or ClusterAnalysisTemplate in the cluster --from-file string Create an AnalysisRun from an AnalysisTemplate or ClusterAnalysisTemplate in a local file --generate-name string Use the specified generateName for the run --global Use a ClusterAnalysisTemplate instead of a AnalysisTemplate -h, --help help for analysisrun --instance-id string Instance-ID for the AnalysisRun --name string Use the specified name for the run","title":"Options"},{"location":"generated/kubectl-argo-rollouts/kubectl-argo-rollouts_create_analysisrun/#options-inherited-from-parent-commands","text":"--as string Username to impersonate for the operation --as-group stringArray Group to impersonate for the operation, this flag can be repeated to specify multiple groups. --cache-dir string Default HTTP cache directory (default \"/home/runner/.kube/http-cache\") --certificate-authority string Path to a cert file for the certificate authority --client-certificate string Path to a client certificate file for TLS --client-key string Path to a client key file for TLS --cluster string The name of the kubeconfig cluster to use --context string The name of the kubeconfig context to use --insecure-skip-tls-verify If true, the server's certificate will not be checked for validity. This will make your HTTPS connections insecure -v, --kloglevel int Log level for kubernetes client library --kubeconfig string Path to the kubeconfig file to use for CLI requests. --loglevel string Log level for kubectl argo rollouts (default \"info\") -n, --namespace string If present, the namespace scope for this CLI request --request-timeout string The length of time to wait before giving up on a single server request. Non-zero values should contain a corresponding time unit (e.g. 1s, 2m, 3h). A value of zero means don't timeout requests. (default \"0\") -s, --server string The address and port of the Kubernetes API server --tls-server-name string Server name to use for server certificate validation. If it is not provided, the hostname used to contact the server is used --token string Bearer token for authentication to the API server --user string The name of the kubeconfig user to use","title":"Options inherited from parent commands"},{"location":"generated/kubectl-argo-rollouts/kubectl-argo-rollouts_create_analysisrun/#see-also","text":"rollouts create - Create a Rollout, Experiment, AnalysisTemplate, ClusterAnalysisTemplate, or AnalysisRun resource","title":"See Also"},{"location":"generated/kubectl-argo-rollouts/kubectl-argo-rollouts_get/","text":"Rollouts Get \u00b6 Get details about rollouts and experiments Synopsis \u00b6 This command consists of multiple subcommands which can be used to get extended information about a rollout or experiment. kubectl argo rollouts get <rollout | experiment> RESOURCE_NAME [ flags ] Examples \u00b6 # Get a rollout kubectl argo rollouts get rollout guestbook # Watch a rollouts progress kubectl argo rollouts get rollout guestbook -w # Get an experiment kubectl argo rollouts get experiment my-experiment Options \u00b6 -h, --help help for get Options inherited from parent commands \u00b6 --as string Username to impersonate for the operation --as-group stringArray Group to impersonate for the operation, this flag can be repeated to specify multiple groups. --cache-dir string Default HTTP cache directory (default \"/home/runner/.kube/http-cache\") --certificate-authority string Path to a cert file for the certificate authority --client-certificate string Path to a client certificate file for TLS --client-key string Path to a client key file for TLS --cluster string The name of the kubeconfig cluster to use --context string The name of the kubeconfig context to use --insecure-skip-tls-verify If true, the server's certificate will not be checked for validity. This will make your HTTPS connections insecure -v, --kloglevel int Log level for kubernetes client library --kubeconfig string Path to the kubeconfig file to use for CLI requests. --loglevel string Log level for kubectl argo rollouts (default \"info\") -n, --namespace string If present, the namespace scope for this CLI request --request-timeout string The length of time to wait before giving up on a single server request. Non-zero values should contain a corresponding time unit (e.g. 1s, 2m, 3h). A value of zero means don't timeout requests. (default \"0\") -s, --server string The address and port of the Kubernetes API server --tls-server-name string Server name to use for server certificate validation. If it is not provided, the hostname used to contact the server is used --token string Bearer token for authentication to the API server --user string The name of the kubeconfig user to use Available Commands \u00b6 rollouts get experiment - Get details about an Experiment rollouts get rollout - Get details about a rollout See Also \u00b6 rollouts - Manage argo rollouts","title":"Rollouts Get"},{"location":"generated/kubectl-argo-rollouts/kubectl-argo-rollouts_get/#rollouts-get","text":"Get details about rollouts and experiments","title":"Rollouts Get"},{"location":"generated/kubectl-argo-rollouts/kubectl-argo-rollouts_get/#synopsis","text":"This command consists of multiple subcommands which can be used to get extended information about a rollout or experiment. kubectl argo rollouts get <rollout | experiment> RESOURCE_NAME [ flags ]","title":"Synopsis"},{"location":"generated/kubectl-argo-rollouts/kubectl-argo-rollouts_get/#examples","text":"# Get a rollout kubectl argo rollouts get rollout guestbook # Watch a rollouts progress kubectl argo rollouts get rollout guestbook -w # Get an experiment kubectl argo rollouts get experiment my-experiment","title":"Examples"},{"location":"generated/kubectl-argo-rollouts/kubectl-argo-rollouts_get/#options","text":"-h, --help help for get","title":"Options"},{"location":"generated/kubectl-argo-rollouts/kubectl-argo-rollouts_get/#options-inherited-from-parent-commands","text":"--as string Username to impersonate for the operation --as-group stringArray Group to impersonate for the operation, this flag can be repeated to specify multiple groups. --cache-dir string Default HTTP cache directory (default \"/home/runner/.kube/http-cache\") --certificate-authority string Path to a cert file for the certificate authority --client-certificate string Path to a client certificate file for TLS --client-key string Path to a client key file for TLS --cluster string The name of the kubeconfig cluster to use --context string The name of the kubeconfig context to use --insecure-skip-tls-verify If true, the server's certificate will not be checked for validity. This will make your HTTPS connections insecure -v, --kloglevel int Log level for kubernetes client library --kubeconfig string Path to the kubeconfig file to use for CLI requests. --loglevel string Log level for kubectl argo rollouts (default \"info\") -n, --namespace string If present, the namespace scope for this CLI request --request-timeout string The length of time to wait before giving up on a single server request. Non-zero values should contain a corresponding time unit (e.g. 1s, 2m, 3h). A value of zero means don't timeout requests. (default \"0\") -s, --server string The address and port of the Kubernetes API server --tls-server-name string Server name to use for server certificate validation. If it is not provided, the hostname used to contact the server is used --token string Bearer token for authentication to the API server --user string The name of the kubeconfig user to use","title":"Options inherited from parent commands"},{"location":"generated/kubectl-argo-rollouts/kubectl-argo-rollouts_get/#available-commands","text":"rollouts get experiment - Get details about an Experiment rollouts get rollout - Get details about a rollout","title":"Available Commands"},{"location":"generated/kubectl-argo-rollouts/kubectl-argo-rollouts_get/#see-also","text":"rollouts - Manage argo rollouts","title":"See Also"},{"location":"generated/kubectl-argo-rollouts/kubectl-argo-rollouts_get_experiment/","text":"Rollouts Get Experiment \u00b6 Get details about an Experiment Synopsis \u00b6 Get details about and visual representation of a experiment. It returns a bunch of metadata on a resource and a tree view of the child resources created by the parent. Tree view icons Icon Kind \u27f3 Rollout \u03a3 Experiment \u03b1 AnalysisRun # Revision \u29c9 ReplicaSet \u25a1 Pod \u229e Job kubectl argo rollouts get experiment EXPERIMENT_NAME [ flags ] Examples \u00b6 # Get an experiment kubectl argo rollouts get experiment my-experiment # Watch experiment progress kubectl argo rollouts get experiment my-experiment -w Options \u00b6 -h, --help help for experiment --no-color Do not colorize output -w, --watch Watch live updates to the rollout Options inherited from parent commands \u00b6 --as string Username to impersonate for the operation --as-group stringArray Group to impersonate for the operation, this flag can be repeated to specify multiple groups. --cache-dir string Default HTTP cache directory (default \"/home/runner/.kube/http-cache\") --certificate-authority string Path to a cert file for the certificate authority --client-certificate string Path to a client certificate file for TLS --client-key string Path to a client key file for TLS --cluster string The name of the kubeconfig cluster to use --context string The name of the kubeconfig context to use --insecure-skip-tls-verify If true, the server's certificate will not be checked for validity. This will make your HTTPS connections insecure -v, --kloglevel int Log level for kubernetes client library --kubeconfig string Path to the kubeconfig file to use for CLI requests. --loglevel string Log level for kubectl argo rollouts (default \"info\") -n, --namespace string If present, the namespace scope for this CLI request --request-timeout string The length of time to wait before giving up on a single server request. Non-zero values should contain a corresponding time unit (e.g. 1s, 2m, 3h). A value of zero means don't timeout requests. (default \"0\") -s, --server string The address and port of the Kubernetes API server --tls-server-name string Server name to use for server certificate validation. If it is not provided, the hostname used to contact the server is used --token string Bearer token for authentication to the API server --user string The name of the kubeconfig user to use See Also \u00b6 rollouts get - Get details about rollouts and experiments","title":"Rollouts Get Experiment"},{"location":"generated/kubectl-argo-rollouts/kubectl-argo-rollouts_get_experiment/#rollouts-get-experiment","text":"Get details about an Experiment","title":"Rollouts Get Experiment"},{"location":"generated/kubectl-argo-rollouts/kubectl-argo-rollouts_get_experiment/#synopsis","text":"Get details about and visual representation of a experiment. It returns a bunch of metadata on a resource and a tree view of the child resources created by the parent. Tree view icons Icon Kind \u27f3 Rollout \u03a3 Experiment \u03b1 AnalysisRun # Revision \u29c9 ReplicaSet \u25a1 Pod \u229e Job kubectl argo rollouts get experiment EXPERIMENT_NAME [ flags ]","title":"Synopsis"},{"location":"generated/kubectl-argo-rollouts/kubectl-argo-rollouts_get_experiment/#examples","text":"# Get an experiment kubectl argo rollouts get experiment my-experiment # Watch experiment progress kubectl argo rollouts get experiment my-experiment -w","title":"Examples"},{"location":"generated/kubectl-argo-rollouts/kubectl-argo-rollouts_get_experiment/#options","text":"-h, --help help for experiment --no-color Do not colorize output -w, --watch Watch live updates to the rollout","title":"Options"},{"location":"generated/kubectl-argo-rollouts/kubectl-argo-rollouts_get_experiment/#options-inherited-from-parent-commands","text":"--as string Username to impersonate for the operation --as-group stringArray Group to impersonate for the operation, this flag can be repeated to specify multiple groups. --cache-dir string Default HTTP cache directory (default \"/home/runner/.kube/http-cache\") --certificate-authority string Path to a cert file for the certificate authority --client-certificate string Path to a client certificate file for TLS --client-key string Path to a client key file for TLS --cluster string The name of the kubeconfig cluster to use --context string The name of the kubeconfig context to use --insecure-skip-tls-verify If true, the server's certificate will not be checked for validity. This will make your HTTPS connections insecure -v, --kloglevel int Log level for kubernetes client library --kubeconfig string Path to the kubeconfig file to use for CLI requests. --loglevel string Log level for kubectl argo rollouts (default \"info\") -n, --namespace string If present, the namespace scope for this CLI request --request-timeout string The length of time to wait before giving up on a single server request. Non-zero values should contain a corresponding time unit (e.g. 1s, 2m, 3h). A value of zero means don't timeout requests. (default \"0\") -s, --server string The address and port of the Kubernetes API server --tls-server-name string Server name to use for server certificate validation. If it is not provided, the hostname used to contact the server is used --token string Bearer token for authentication to the API server --user string The name of the kubeconfig user to use","title":"Options inherited from parent commands"},{"location":"generated/kubectl-argo-rollouts/kubectl-argo-rollouts_get_experiment/#see-also","text":"rollouts get - Get details about rollouts and experiments","title":"See Also"},{"location":"generated/kubectl-argo-rollouts/kubectl-argo-rollouts_get_rollout/","text":"Rollouts Get Rollout \u00b6 Get details about a rollout Synopsis \u00b6 Get details about and visual representation of a rollout. It returns a bunch of metadata on a resource and a tree view of the child resources created by the parent. Tree view icons Icon Kind \u27f3 Rollout \u03a3 Experiment \u03b1 AnalysisRun # Revision \u29c9 ReplicaSet \u25a1 Pod \u229e Job kubectl argo rollouts get rollout ROLLOUT_NAME [ flags ] Examples \u00b6 # Get a rollout kubectl argo rollouts get rollout guestbook # Watch progress of a rollout kubectl argo rollouts get rollout guestbook -w Options \u00b6 -h, --help help for rollout --no-color Do not colorize output -w, --watch Watch live updates to the rollout Options inherited from parent commands \u00b6 --as string Username to impersonate for the operation --as-group stringArray Group to impersonate for the operation, this flag can be repeated to specify multiple groups. --cache-dir string Default HTTP cache directory (default \"/home/runner/.kube/http-cache\") --certificate-authority string Path to a cert file for the certificate authority --client-certificate string Path to a client certificate file for TLS --client-key string Path to a client key file for TLS --cluster string The name of the kubeconfig cluster to use --context string The name of the kubeconfig context to use --insecure-skip-tls-verify If true, the server's certificate will not be checked for validity. This will make your HTTPS connections insecure -v, --kloglevel int Log level for kubernetes client library --kubeconfig string Path to the kubeconfig file to use for CLI requests. --loglevel string Log level for kubectl argo rollouts (default \"info\") -n, --namespace string If present, the namespace scope for this CLI request --request-timeout string The length of time to wait before giving up on a single server request. Non-zero values should contain a corresponding time unit (e.g. 1s, 2m, 3h). A value of zero means don't timeout requests. (default \"0\") -s, --server string The address and port of the Kubernetes API server --tls-server-name string Server name to use for server certificate validation. If it is not provided, the hostname used to contact the server is used --token string Bearer token for authentication to the API server --user string The name of the kubeconfig user to use See Also \u00b6 rollouts get - Get details about rollouts and experiments","title":"Rollouts Get Rollout"},{"location":"generated/kubectl-argo-rollouts/kubectl-argo-rollouts_get_rollout/#rollouts-get-rollout","text":"Get details about a rollout","title":"Rollouts Get Rollout"},{"location":"generated/kubectl-argo-rollouts/kubectl-argo-rollouts_get_rollout/#synopsis","text":"Get details about and visual representation of a rollout. It returns a bunch of metadata on a resource and a tree view of the child resources created by the parent. Tree view icons Icon Kind \u27f3 Rollout \u03a3 Experiment \u03b1 AnalysisRun # Revision \u29c9 ReplicaSet \u25a1 Pod \u229e Job kubectl argo rollouts get rollout ROLLOUT_NAME [ flags ]","title":"Synopsis"},{"location":"generated/kubectl-argo-rollouts/kubectl-argo-rollouts_get_rollout/#examples","text":"# Get a rollout kubectl argo rollouts get rollout guestbook # Watch progress of a rollout kubectl argo rollouts get rollout guestbook -w","title":"Examples"},{"location":"generated/kubectl-argo-rollouts/kubectl-argo-rollouts_get_rollout/#options","text":"-h, --help help for rollout --no-color Do not colorize output -w, --watch Watch live updates to the rollout","title":"Options"},{"location":"generated/kubectl-argo-rollouts/kubectl-argo-rollouts_get_rollout/#options-inherited-from-parent-commands","text":"--as string Username to impersonate for the operation --as-group stringArray Group to impersonate for the operation, this flag can be repeated to specify multiple groups. --cache-dir string Default HTTP cache directory (default \"/home/runner/.kube/http-cache\") --certificate-authority string Path to a cert file for the certificate authority --client-certificate string Path to a client certificate file for TLS --client-key string Path to a client key file for TLS --cluster string The name of the kubeconfig cluster to use --context string The name of the kubeconfig context to use --insecure-skip-tls-verify If true, the server's certificate will not be checked for validity. This will make your HTTPS connections insecure -v, --kloglevel int Log level for kubernetes client library --kubeconfig string Path to the kubeconfig file to use for CLI requests. --loglevel string Log level for kubectl argo rollouts (default \"info\") -n, --namespace string If present, the namespace scope for this CLI request --request-timeout string The length of time to wait before giving up on a single server request. Non-zero values should contain a corresponding time unit (e.g. 1s, 2m, 3h). A value of zero means don't timeout requests. (default \"0\") -s, --server string The address and port of the Kubernetes API server --tls-server-name string Server name to use for server certificate validation. If it is not provided, the hostname used to contact the server is used --token string Bearer token for authentication to the API server --user string The name of the kubeconfig user to use","title":"Options inherited from parent commands"},{"location":"generated/kubectl-argo-rollouts/kubectl-argo-rollouts_get_rollout/#see-also","text":"rollouts get - Get details about rollouts and experiments","title":"See Also"},{"location":"generated/kubectl-argo-rollouts/kubectl-argo-rollouts_list/","text":"Rollouts List \u00b6 List rollouts or experiments Synopsis \u00b6 This command consists of multiple subcommands which can be used to lists all of the rollouts or experiments for a specified namespace (uses current namespace context if namespace not specified). kubectl argo rollouts list <rollout | experiment> [ flags ] Examples \u00b6 # List rollouts kubectl argo rollouts list rollouts # List experiments kubectl argo rollouts list experiments Options \u00b6 -h, --help help for list Options inherited from parent commands \u00b6 --as string Username to impersonate for the operation --as-group stringArray Group to impersonate for the operation, this flag can be repeated to specify multiple groups. --cache-dir string Default HTTP cache directory (default \"/home/runner/.kube/http-cache\") --certificate-authority string Path to a cert file for the certificate authority --client-certificate string Path to a client certificate file for TLS --client-key string Path to a client key file for TLS --cluster string The name of the kubeconfig cluster to use --context string The name of the kubeconfig context to use --insecure-skip-tls-verify If true, the server's certificate will not be checked for validity. This will make your HTTPS connections insecure -v, --kloglevel int Log level for kubernetes client library --kubeconfig string Path to the kubeconfig file to use for CLI requests. --loglevel string Log level for kubectl argo rollouts (default \"info\") -n, --namespace string If present, the namespace scope for this CLI request --request-timeout string The length of time to wait before giving up on a single server request. Non-zero values should contain a corresponding time unit (e.g. 1s, 2m, 3h). A value of zero means don't timeout requests. (default \"0\") -s, --server string The address and port of the Kubernetes API server --tls-server-name string Server name to use for server certificate validation. If it is not provided, the hostname used to contact the server is used --token string Bearer token for authentication to the API server --user string The name of the kubeconfig user to use Available Commands \u00b6 rollouts list experiments - List experiments rollouts list rollouts - List rollouts See Also \u00b6 rollouts - Manage argo rollouts","title":"Rollouts List"},{"location":"generated/kubectl-argo-rollouts/kubectl-argo-rollouts_list/#rollouts-list","text":"List rollouts or experiments","title":"Rollouts List"},{"location":"generated/kubectl-argo-rollouts/kubectl-argo-rollouts_list/#synopsis","text":"This command consists of multiple subcommands which can be used to lists all of the rollouts or experiments for a specified namespace (uses current namespace context if namespace not specified). kubectl argo rollouts list <rollout | experiment> [ flags ]","title":"Synopsis"},{"location":"generated/kubectl-argo-rollouts/kubectl-argo-rollouts_list/#examples","text":"# List rollouts kubectl argo rollouts list rollouts # List experiments kubectl argo rollouts list experiments","title":"Examples"},{"location":"generated/kubectl-argo-rollouts/kubectl-argo-rollouts_list/#options","text":"-h, --help help for list","title":"Options"},{"location":"generated/kubectl-argo-rollouts/kubectl-argo-rollouts_list/#options-inherited-from-parent-commands","text":"--as string Username to impersonate for the operation --as-group stringArray Group to impersonate for the operation, this flag can be repeated to specify multiple groups. --cache-dir string Default HTTP cache directory (default \"/home/runner/.kube/http-cache\") --certificate-authority string Path to a cert file for the certificate authority --client-certificate string Path to a client certificate file for TLS --client-key string Path to a client key file for TLS --cluster string The name of the kubeconfig cluster to use --context string The name of the kubeconfig context to use --insecure-skip-tls-verify If true, the server's certificate will not be checked for validity. This will make your HTTPS connections insecure -v, --kloglevel int Log level for kubernetes client library --kubeconfig string Path to the kubeconfig file to use for CLI requests. --loglevel string Log level for kubectl argo rollouts (default \"info\") -n, --namespace string If present, the namespace scope for this CLI request --request-timeout string The length of time to wait before giving up on a single server request. Non-zero values should contain a corresponding time unit (e.g. 1s, 2m, 3h). A value of zero means don't timeout requests. (default \"0\") -s, --server string The address and port of the Kubernetes API server --tls-server-name string Server name to use for server certificate validation. If it is not provided, the hostname used to contact the server is used --token string Bearer token for authentication to the API server --user string The name of the kubeconfig user to use","title":"Options inherited from parent commands"},{"location":"generated/kubectl-argo-rollouts/kubectl-argo-rollouts_list/#available-commands","text":"rollouts list experiments - List experiments rollouts list rollouts - List rollouts","title":"Available Commands"},{"location":"generated/kubectl-argo-rollouts/kubectl-argo-rollouts_list/#see-also","text":"rollouts - Manage argo rollouts","title":"See Also"},{"location":"generated/kubectl-argo-rollouts/kubectl-argo-rollouts_list_experiments/","text":"Rollouts List Experiments \u00b6 List experiments Synopsis \u00b6 This command lists all of the experiments for a specified namespace (uses current namespace context if namespace not specified). kubectl argo rollouts list experiments [ flags ] Examples \u00b6 # List rollouts kubectl argo rollouts list experiments # List rollouts from all namespaces kubectl argo rollouts list experiments --all-namespaces # List rollouts and watch for changes kubectl argo rollouts list experiments --watch Options \u00b6 --all-namespaces Include all namespaces -h, --help help for experiments Options inherited from parent commands \u00b6 --as string Username to impersonate for the operation --as-group stringArray Group to impersonate for the operation, this flag can be repeated to specify multiple groups. --cache-dir string Default HTTP cache directory (default \"/home/runner/.kube/http-cache\") --certificate-authority string Path to a cert file for the certificate authority --client-certificate string Path to a client certificate file for TLS --client-key string Path to a client key file for TLS --cluster string The name of the kubeconfig cluster to use --context string The name of the kubeconfig context to use --insecure-skip-tls-verify If true, the server's certificate will not be checked for validity. This will make your HTTPS connections insecure -v, --kloglevel int Log level for kubernetes client library --kubeconfig string Path to the kubeconfig file to use for CLI requests. --loglevel string Log level for kubectl argo rollouts (default \"info\") -n, --namespace string If present, the namespace scope for this CLI request --request-timeout string The length of time to wait before giving up on a single server request. Non-zero values should contain a corresponding time unit (e.g. 1s, 2m, 3h). A value of zero means don't timeout requests. (default \"0\") -s, --server string The address and port of the Kubernetes API server --tls-server-name string Server name to use for server certificate validation. If it is not provided, the hostname used to contact the server is used --token string Bearer token for authentication to the API server --user string The name of the kubeconfig user to use See Also \u00b6 rollouts list - List rollouts or experiments","title":"Rollouts List Experiments"},{"location":"generated/kubectl-argo-rollouts/kubectl-argo-rollouts_list_experiments/#rollouts-list-experiments","text":"List experiments","title":"Rollouts List Experiments"},{"location":"generated/kubectl-argo-rollouts/kubectl-argo-rollouts_list_experiments/#synopsis","text":"This command lists all of the experiments for a specified namespace (uses current namespace context if namespace not specified). kubectl argo rollouts list experiments [ flags ]","title":"Synopsis"},{"location":"generated/kubectl-argo-rollouts/kubectl-argo-rollouts_list_experiments/#examples","text":"# List rollouts kubectl argo rollouts list experiments # List rollouts from all namespaces kubectl argo rollouts list experiments --all-namespaces # List rollouts and watch for changes kubectl argo rollouts list experiments --watch","title":"Examples"},{"location":"generated/kubectl-argo-rollouts/kubectl-argo-rollouts_list_experiments/#options","text":"--all-namespaces Include all namespaces -h, --help help for experiments","title":"Options"},{"location":"generated/kubectl-argo-rollouts/kubectl-argo-rollouts_list_experiments/#options-inherited-from-parent-commands","text":"--as string Username to impersonate for the operation --as-group stringArray Group to impersonate for the operation, this flag can be repeated to specify multiple groups. --cache-dir string Default HTTP cache directory (default \"/home/runner/.kube/http-cache\") --certificate-authority string Path to a cert file for the certificate authority --client-certificate string Path to a client certificate file for TLS --client-key string Path to a client key file for TLS --cluster string The name of the kubeconfig cluster to use --context string The name of the kubeconfig context to use --insecure-skip-tls-verify If true, the server's certificate will not be checked for validity. This will make your HTTPS connections insecure -v, --kloglevel int Log level for kubernetes client library --kubeconfig string Path to the kubeconfig file to use for CLI requests. --loglevel string Log level for kubectl argo rollouts (default \"info\") -n, --namespace string If present, the namespace scope for this CLI request --request-timeout string The length of time to wait before giving up on a single server request. Non-zero values should contain a corresponding time unit (e.g. 1s, 2m, 3h). A value of zero means don't timeout requests. (default \"0\") -s, --server string The address and port of the Kubernetes API server --tls-server-name string Server name to use for server certificate validation. If it is not provided, the hostname used to contact the server is used --token string Bearer token for authentication to the API server --user string The name of the kubeconfig user to use","title":"Options inherited from parent commands"},{"location":"generated/kubectl-argo-rollouts/kubectl-argo-rollouts_list_experiments/#see-also","text":"rollouts list - List rollouts or experiments","title":"See Also"},{"location":"generated/kubectl-argo-rollouts/kubectl-argo-rollouts_list_rollouts/","text":"Rollouts List Rollouts \u00b6 List rollouts Synopsis \u00b6 This command lists all of the rollouts for a specified namespace (uses current namespace context if namespace not specified). kubectl argo rollouts list rollouts [ flags ] Examples \u00b6 # List rollouts kubectl argo rollouts list rollouts # List rollouts from all namespaces kubectl argo rollouts list rollouts --all-namespaces # List rollouts and watch for changes kubectl argo rollouts list rollouts --watch Options \u00b6 -A, --all-namespaces Include all namespaces -h, --help help for rollouts --name string Only show rollout with specified name --timestamps Print timestamps on updates -w, --watch Watch for changes Options inherited from parent commands \u00b6 --as string Username to impersonate for the operation --as-group stringArray Group to impersonate for the operation, this flag can be repeated to specify multiple groups. --cache-dir string Default HTTP cache directory (default \"/home/runner/.kube/http-cache\") --certificate-authority string Path to a cert file for the certificate authority --client-certificate string Path to a client certificate file for TLS --client-key string Path to a client key file for TLS --cluster string The name of the kubeconfig cluster to use --context string The name of the kubeconfig context to use --insecure-skip-tls-verify If true, the server's certificate will not be checked for validity. This will make your HTTPS connections insecure -v, --kloglevel int Log level for kubernetes client library --kubeconfig string Path to the kubeconfig file to use for CLI requests. --loglevel string Log level for kubectl argo rollouts (default \"info\") -n, --namespace string If present, the namespace scope for this CLI request --request-timeout string The length of time to wait before giving up on a single server request. Non-zero values should contain a corresponding time unit (e.g. 1s, 2m, 3h). A value of zero means don't timeout requests. (default \"0\") -s, --server string The address and port of the Kubernetes API server --tls-server-name string Server name to use for server certificate validation. If it is not provided, the hostname used to contact the server is used --token string Bearer token for authentication to the API server --user string The name of the kubeconfig user to use See Also \u00b6 rollouts list - List rollouts or experiments","title":"Rollouts List Rollouts"},{"location":"generated/kubectl-argo-rollouts/kubectl-argo-rollouts_list_rollouts/#rollouts-list-rollouts","text":"List rollouts","title":"Rollouts List Rollouts"},{"location":"generated/kubectl-argo-rollouts/kubectl-argo-rollouts_list_rollouts/#synopsis","text":"This command lists all of the rollouts for a specified namespace (uses current namespace context if namespace not specified). kubectl argo rollouts list rollouts [ flags ]","title":"Synopsis"},{"location":"generated/kubectl-argo-rollouts/kubectl-argo-rollouts_list_rollouts/#examples","text":"# List rollouts kubectl argo rollouts list rollouts # List rollouts from all namespaces kubectl argo rollouts list rollouts --all-namespaces # List rollouts and watch for changes kubectl argo rollouts list rollouts --watch","title":"Examples"},{"location":"generated/kubectl-argo-rollouts/kubectl-argo-rollouts_list_rollouts/#options","text":"-A, --all-namespaces Include all namespaces -h, --help help for rollouts --name string Only show rollout with specified name --timestamps Print timestamps on updates -w, --watch Watch for changes","title":"Options"},{"location":"generated/kubectl-argo-rollouts/kubectl-argo-rollouts_list_rollouts/#options-inherited-from-parent-commands","text":"--as string Username to impersonate for the operation --as-group stringArray Group to impersonate for the operation, this flag can be repeated to specify multiple groups. --cache-dir string Default HTTP cache directory (default \"/home/runner/.kube/http-cache\") --certificate-authority string Path to a cert file for the certificate authority --client-certificate string Path to a client certificate file for TLS --client-key string Path to a client key file for TLS --cluster string The name of the kubeconfig cluster to use --context string The name of the kubeconfig context to use --insecure-skip-tls-verify If true, the server's certificate will not be checked for validity. This will make your HTTPS connections insecure -v, --kloglevel int Log level for kubernetes client library --kubeconfig string Path to the kubeconfig file to use for CLI requests. --loglevel string Log level for kubectl argo rollouts (default \"info\") -n, --namespace string If present, the namespace scope for this CLI request --request-timeout string The length of time to wait before giving up on a single server request. Non-zero values should contain a corresponding time unit (e.g. 1s, 2m, 3h). A value of zero means don't timeout requests. (default \"0\") -s, --server string The address and port of the Kubernetes API server --tls-server-name string Server name to use for server certificate validation. If it is not provided, the hostname used to contact the server is used --token string Bearer token for authentication to the API server --user string The name of the kubeconfig user to use","title":"Options inherited from parent commands"},{"location":"generated/kubectl-argo-rollouts/kubectl-argo-rollouts_list_rollouts/#see-also","text":"rollouts list - List rollouts or experiments","title":"See Also"},{"location":"generated/kubectl-argo-rollouts/kubectl-argo-rollouts_pause/","text":"Rollouts Pause \u00b6 Pause a rollout Synopsis \u00b6 Set the rollout paused state to 'true' kubectl argo rollouts pause ROLLOUT_NAME [ flags ] Examples \u00b6 # Pause a rollout kubectl argo rollouts pause guestbook Options \u00b6 -h, --help help for pause Options inherited from parent commands \u00b6 --as string Username to impersonate for the operation --as-group stringArray Group to impersonate for the operation, this flag can be repeated to specify multiple groups. --cache-dir string Default HTTP cache directory (default \"/home/runner/.kube/http-cache\") --certificate-authority string Path to a cert file for the certificate authority --client-certificate string Path to a client certificate file for TLS --client-key string Path to a client key file for TLS --cluster string The name of the kubeconfig cluster to use --context string The name of the kubeconfig context to use --insecure-skip-tls-verify If true, the server's certificate will not be checked for validity. This will make your HTTPS connections insecure -v, --kloglevel int Log level for kubernetes client library --kubeconfig string Path to the kubeconfig file to use for CLI requests. --loglevel string Log level for kubectl argo rollouts (default \"info\") -n, --namespace string If present, the namespace scope for this CLI request --request-timeout string The length of time to wait before giving up on a single server request. Non-zero values should contain a corresponding time unit (e.g. 1s, 2m, 3h). A value of zero means don't timeout requests. (default \"0\") -s, --server string The address and port of the Kubernetes API server --tls-server-name string Server name to use for server certificate validation. If it is not provided, the hostname used to contact the server is used --token string Bearer token for authentication to the API server --user string The name of the kubeconfig user to use See Also \u00b6 rollouts - Manage argo rollouts","title":"Rollouts Pause"},{"location":"generated/kubectl-argo-rollouts/kubectl-argo-rollouts_pause/#rollouts-pause","text":"Pause a rollout","title":"Rollouts Pause"},{"location":"generated/kubectl-argo-rollouts/kubectl-argo-rollouts_pause/#synopsis","text":"Set the rollout paused state to 'true' kubectl argo rollouts pause ROLLOUT_NAME [ flags ]","title":"Synopsis"},{"location":"generated/kubectl-argo-rollouts/kubectl-argo-rollouts_pause/#examples","text":"# Pause a rollout kubectl argo rollouts pause guestbook","title":"Examples"},{"location":"generated/kubectl-argo-rollouts/kubectl-argo-rollouts_pause/#options","text":"-h, --help help for pause","title":"Options"},{"location":"generated/kubectl-argo-rollouts/kubectl-argo-rollouts_pause/#options-inherited-from-parent-commands","text":"--as string Username to impersonate for the operation --as-group stringArray Group to impersonate for the operation, this flag can be repeated to specify multiple groups. --cache-dir string Default HTTP cache directory (default \"/home/runner/.kube/http-cache\") --certificate-authority string Path to a cert file for the certificate authority --client-certificate string Path to a client certificate file for TLS --client-key string Path to a client key file for TLS --cluster string The name of the kubeconfig cluster to use --context string The name of the kubeconfig context to use --insecure-skip-tls-verify If true, the server's certificate will not be checked for validity. This will make your HTTPS connections insecure -v, --kloglevel int Log level for kubernetes client library --kubeconfig string Path to the kubeconfig file to use for CLI requests. --loglevel string Log level for kubectl argo rollouts (default \"info\") -n, --namespace string If present, the namespace scope for this CLI request --request-timeout string The length of time to wait before giving up on a single server request. Non-zero values should contain a corresponding time unit (e.g. 1s, 2m, 3h). A value of zero means don't timeout requests. (default \"0\") -s, --server string The address and port of the Kubernetes API server --tls-server-name string Server name to use for server certificate validation. If it is not provided, the hostname used to contact the server is used --token string Bearer token for authentication to the API server --user string The name of the kubeconfig user to use","title":"Options inherited from parent commands"},{"location":"generated/kubectl-argo-rollouts/kubectl-argo-rollouts_pause/#see-also","text":"rollouts - Manage argo rollouts","title":"See Also"},{"location":"generated/kubectl-argo-rollouts/kubectl-argo-rollouts_promote/","text":"Rollouts Promote \u00b6 Promote a rollout Synopsis \u00b6 Unpause a Canary or BlueGreen rollout or skip Canary rollout steps. If a Canary rollout has more steps the rollout will proceed to the next step in the rollout. Use '--skip-all-steps' to skip and remaining steps. If not on a pause step use '--skip-current-step' to progress to the next step in the rollout. kubectl argo rollouts promote ROLLOUT_NAME [ flags ] Examples \u00b6 # Promote a paused rollout kubectl argo rollouts promote guestbook # Promote a canary rollout and skip all remaining steps kubectl argo rollouts promote guestbook --skip-all-steps Options \u00b6 -h, --help help for promote -a, --skip-all-steps Skip remaining steps -c, --skip-current-step Skip current step Options inherited from parent commands \u00b6 --as string Username to impersonate for the operation --as-group stringArray Group to impersonate for the operation, this flag can be repeated to specify multiple groups. --cache-dir string Default HTTP cache directory (default \"/home/runner/.kube/http-cache\") --certificate-authority string Path to a cert file for the certificate authority --client-certificate string Path to a client certificate file for TLS --client-key string Path to a client key file for TLS --cluster string The name of the kubeconfig cluster to use --context string The name of the kubeconfig context to use --insecure-skip-tls-verify If true, the server's certificate will not be checked for validity. This will make your HTTPS connections insecure -v, --kloglevel int Log level for kubernetes client library --kubeconfig string Path to the kubeconfig file to use for CLI requests. --loglevel string Log level for kubectl argo rollouts (default \"info\") -n, --namespace string If present, the namespace scope for this CLI request --request-timeout string The length of time to wait before giving up on a single server request. Non-zero values should contain a corresponding time unit (e.g. 1s, 2m, 3h). A value of zero means don't timeout requests. (default \"0\") -s, --server string The address and port of the Kubernetes API server --tls-server-name string Server name to use for server certificate validation. If it is not provided, the hostname used to contact the server is used --token string Bearer token for authentication to the API server --user string The name of the kubeconfig user to use See Also \u00b6 rollouts - Manage argo rollouts","title":"Rollouts Promote"},{"location":"generated/kubectl-argo-rollouts/kubectl-argo-rollouts_promote/#rollouts-promote","text":"Promote a rollout","title":"Rollouts Promote"},{"location":"generated/kubectl-argo-rollouts/kubectl-argo-rollouts_promote/#synopsis","text":"Unpause a Canary or BlueGreen rollout or skip Canary rollout steps. If a Canary rollout has more steps the rollout will proceed to the next step in the rollout. Use '--skip-all-steps' to skip and remaining steps. If not on a pause step use '--skip-current-step' to progress to the next step in the rollout. kubectl argo rollouts promote ROLLOUT_NAME [ flags ]","title":"Synopsis"},{"location":"generated/kubectl-argo-rollouts/kubectl-argo-rollouts_promote/#examples","text":"# Promote a paused rollout kubectl argo rollouts promote guestbook # Promote a canary rollout and skip all remaining steps kubectl argo rollouts promote guestbook --skip-all-steps","title":"Examples"},{"location":"generated/kubectl-argo-rollouts/kubectl-argo-rollouts_promote/#options","text":"-h, --help help for promote -a, --skip-all-steps Skip remaining steps -c, --skip-current-step Skip current step","title":"Options"},{"location":"generated/kubectl-argo-rollouts/kubectl-argo-rollouts_promote/#options-inherited-from-parent-commands","text":"--as string Username to impersonate for the operation --as-group stringArray Group to impersonate for the operation, this flag can be repeated to specify multiple groups. --cache-dir string Default HTTP cache directory (default \"/home/runner/.kube/http-cache\") --certificate-authority string Path to a cert file for the certificate authority --client-certificate string Path to a client certificate file for TLS --client-key string Path to a client key file for TLS --cluster string The name of the kubeconfig cluster to use --context string The name of the kubeconfig context to use --insecure-skip-tls-verify If true, the server's certificate will not be checked for validity. This will make your HTTPS connections insecure -v, --kloglevel int Log level for kubernetes client library --kubeconfig string Path to the kubeconfig file to use for CLI requests. --loglevel string Log level for kubectl argo rollouts (default \"info\") -n, --namespace string If present, the namespace scope for this CLI request --request-timeout string The length of time to wait before giving up on a single server request. Non-zero values should contain a corresponding time unit (e.g. 1s, 2m, 3h). A value of zero means don't timeout requests. (default \"0\") -s, --server string The address and port of the Kubernetes API server --tls-server-name string Server name to use for server certificate validation. If it is not provided, the hostname used to contact the server is used --token string Bearer token for authentication to the API server --user string The name of the kubeconfig user to use","title":"Options inherited from parent commands"},{"location":"generated/kubectl-argo-rollouts/kubectl-argo-rollouts_promote/#see-also","text":"rollouts - Manage argo rollouts","title":"See Also"},{"location":"generated/kubectl-argo-rollouts/kubectl-argo-rollouts_restart/","text":"Rollouts Restart \u00b6 Restart the pods of a rollout Synopsis \u00b6 Restart the pods of a rollout kubectl argo rollouts restart ROLLOUT [ flags ] Examples \u00b6 # Restart the pods of a rollout in now kubectl argo rollouts restart ROLLOUT_NAME # Restart the pods of a rollout in ten seconds kubectl argo rollouts restart ROLLOUT_NAME --in 10s Options \u00b6 -h, --help help for restart -i, --in string Amount of time before a restart. (e.g. 30s, 5m, 1h) Options inherited from parent commands \u00b6 --as string Username to impersonate for the operation --as-group stringArray Group to impersonate for the operation, this flag can be repeated to specify multiple groups. --cache-dir string Default HTTP cache directory (default \"/home/runner/.kube/http-cache\") --certificate-authority string Path to a cert file for the certificate authority --client-certificate string Path to a client certificate file for TLS --client-key string Path to a client key file for TLS --cluster string The name of the kubeconfig cluster to use --context string The name of the kubeconfig context to use --insecure-skip-tls-verify If true, the server's certificate will not be checked for validity. This will make your HTTPS connections insecure -v, --kloglevel int Log level for kubernetes client library --kubeconfig string Path to the kubeconfig file to use for CLI requests. --loglevel string Log level for kubectl argo rollouts (default \"info\") -n, --namespace string If present, the namespace scope for this CLI request --request-timeout string The length of time to wait before giving up on a single server request. Non-zero values should contain a corresponding time unit (e.g. 1s, 2m, 3h). A value of zero means don't timeout requests. (default \"0\") -s, --server string The address and port of the Kubernetes API server --tls-server-name string Server name to use for server certificate validation. If it is not provided, the hostname used to contact the server is used --token string Bearer token for authentication to the API server --user string The name of the kubeconfig user to use See Also \u00b6 rollouts - Manage argo rollouts","title":"Rollouts Restart"},{"location":"generated/kubectl-argo-rollouts/kubectl-argo-rollouts_restart/#rollouts-restart","text":"Restart the pods of a rollout","title":"Rollouts Restart"},{"location":"generated/kubectl-argo-rollouts/kubectl-argo-rollouts_restart/#synopsis","text":"Restart the pods of a rollout kubectl argo rollouts restart ROLLOUT [ flags ]","title":"Synopsis"},{"location":"generated/kubectl-argo-rollouts/kubectl-argo-rollouts_restart/#examples","text":"# Restart the pods of a rollout in now kubectl argo rollouts restart ROLLOUT_NAME # Restart the pods of a rollout in ten seconds kubectl argo rollouts restart ROLLOUT_NAME --in 10s","title":"Examples"},{"location":"generated/kubectl-argo-rollouts/kubectl-argo-rollouts_restart/#options","text":"-h, --help help for restart -i, --in string Amount of time before a restart. (e.g. 30s, 5m, 1h)","title":"Options"},{"location":"generated/kubectl-argo-rollouts/kubectl-argo-rollouts_restart/#options-inherited-from-parent-commands","text":"--as string Username to impersonate for the operation --as-group stringArray Group to impersonate for the operation, this flag can be repeated to specify multiple groups. --cache-dir string Default HTTP cache directory (default \"/home/runner/.kube/http-cache\") --certificate-authority string Path to a cert file for the certificate authority --client-certificate string Path to a client certificate file for TLS --client-key string Path to a client key file for TLS --cluster string The name of the kubeconfig cluster to use --context string The name of the kubeconfig context to use --insecure-skip-tls-verify If true, the server's certificate will not be checked for validity. This will make your HTTPS connections insecure -v, --kloglevel int Log level for kubernetes client library --kubeconfig string Path to the kubeconfig file to use for CLI requests. --loglevel string Log level for kubectl argo rollouts (default \"info\") -n, --namespace string If present, the namespace scope for this CLI request --request-timeout string The length of time to wait before giving up on a single server request. Non-zero values should contain a corresponding time unit (e.g. 1s, 2m, 3h). A value of zero means don't timeout requests. (default \"0\") -s, --server string The address and port of the Kubernetes API server --tls-server-name string Server name to use for server certificate validation. If it is not provided, the hostname used to contact the server is used --token string Bearer token for authentication to the API server --user string The name of the kubeconfig user to use","title":"Options inherited from parent commands"},{"location":"generated/kubectl-argo-rollouts/kubectl-argo-rollouts_restart/#see-also","text":"rollouts - Manage argo rollouts","title":"See Also"},{"location":"generated/kubectl-argo-rollouts/kubectl-argo-rollouts_retry/","text":"Rollouts Retry \u00b6 Retry a rollout or experiment Synopsis \u00b6 This command consists of multiple subcommands which can be used to restart an aborted rollout or a failed experiment. kubectl argo rollouts retry <rollout | experiment> RESOURCE_NAME [ flags ] Examples \u00b6 # Retry an aborted rollout kubectl argo rollouts retry rollout guestbook # Retry a failed experiment kubectl argo rollouts retry experiment my-experiment Options \u00b6 -h, --help help for retry Options inherited from parent commands \u00b6 --as string Username to impersonate for the operation --as-group stringArray Group to impersonate for the operation, this flag can be repeated to specify multiple groups. --cache-dir string Default HTTP cache directory (default \"/home/runner/.kube/http-cache\") --certificate-authority string Path to a cert file for the certificate authority --client-certificate string Path to a client certificate file for TLS --client-key string Path to a client key file for TLS --cluster string The name of the kubeconfig cluster to use --context string The name of the kubeconfig context to use --insecure-skip-tls-verify If true, the server's certificate will not be checked for validity. This will make your HTTPS connections insecure -v, --kloglevel int Log level for kubernetes client library --kubeconfig string Path to the kubeconfig file to use for CLI requests. --loglevel string Log level for kubectl argo rollouts (default \"info\") -n, --namespace string If present, the namespace scope for this CLI request --request-timeout string The length of time to wait before giving up on a single server request. Non-zero values should contain a corresponding time unit (e.g. 1s, 2m, 3h). A value of zero means don't timeout requests. (default \"0\") -s, --server string The address and port of the Kubernetes API server --tls-server-name string Server name to use for server certificate validation. If it is not provided, the hostname used to contact the server is used --token string Bearer token for authentication to the API server --user string The name of the kubeconfig user to use Available Commands \u00b6 rollouts retry experiment - Retry an experiment rollouts retry rollout - Retry an aborted rollout See Also \u00b6 rollouts - Manage argo rollouts","title":"Rollouts Retry"},{"location":"generated/kubectl-argo-rollouts/kubectl-argo-rollouts_retry/#rollouts-retry","text":"Retry a rollout or experiment","title":"Rollouts Retry"},{"location":"generated/kubectl-argo-rollouts/kubectl-argo-rollouts_retry/#synopsis","text":"This command consists of multiple subcommands which can be used to restart an aborted rollout or a failed experiment. kubectl argo rollouts retry <rollout | experiment> RESOURCE_NAME [ flags ]","title":"Synopsis"},{"location":"generated/kubectl-argo-rollouts/kubectl-argo-rollouts_retry/#examples","text":"# Retry an aborted rollout kubectl argo rollouts retry rollout guestbook # Retry a failed experiment kubectl argo rollouts retry experiment my-experiment","title":"Examples"},{"location":"generated/kubectl-argo-rollouts/kubectl-argo-rollouts_retry/#options","text":"-h, --help help for retry","title":"Options"},{"location":"generated/kubectl-argo-rollouts/kubectl-argo-rollouts_retry/#options-inherited-from-parent-commands","text":"--as string Username to impersonate for the operation --as-group stringArray Group to impersonate for the operation, this flag can be repeated to specify multiple groups. --cache-dir string Default HTTP cache directory (default \"/home/runner/.kube/http-cache\") --certificate-authority string Path to a cert file for the certificate authority --client-certificate string Path to a client certificate file for TLS --client-key string Path to a client key file for TLS --cluster string The name of the kubeconfig cluster to use --context string The name of the kubeconfig context to use --insecure-skip-tls-verify If true, the server's certificate will not be checked for validity. This will make your HTTPS connections insecure -v, --kloglevel int Log level for kubernetes client library --kubeconfig string Path to the kubeconfig file to use for CLI requests. --loglevel string Log level for kubectl argo rollouts (default \"info\") -n, --namespace string If present, the namespace scope for this CLI request --request-timeout string The length of time to wait before giving up on a single server request. Non-zero values should contain a corresponding time unit (e.g. 1s, 2m, 3h). A value of zero means don't timeout requests. (default \"0\") -s, --server string The address and port of the Kubernetes API server --tls-server-name string Server name to use for server certificate validation. If it is not provided, the hostname used to contact the server is used --token string Bearer token for authentication to the API server --user string The name of the kubeconfig user to use","title":"Options inherited from parent commands"},{"location":"generated/kubectl-argo-rollouts/kubectl-argo-rollouts_retry/#available-commands","text":"rollouts retry experiment - Retry an experiment rollouts retry rollout - Retry an aborted rollout","title":"Available Commands"},{"location":"generated/kubectl-argo-rollouts/kubectl-argo-rollouts_retry/#see-also","text":"rollouts - Manage argo rollouts","title":"See Also"},{"location":"generated/kubectl-argo-rollouts/kubectl-argo-rollouts_retry_experiment/","text":"Rollouts Retry Experiment \u00b6 Retry an experiment Synopsis \u00b6 Retry a failed experiment. kubectl argo rollouts retry experiment EXPERIMENT_NAME [ flags ] Examples \u00b6 # Retry an experiment kubectl argo rollouts retry experiment my-experiment Options \u00b6 -h, --help help for experiment Options inherited from parent commands \u00b6 --as string Username to impersonate for the operation --as-group stringArray Group to impersonate for the operation, this flag can be repeated to specify multiple groups. --cache-dir string Default HTTP cache directory (default \"/home/runner/.kube/http-cache\") --certificate-authority string Path to a cert file for the certificate authority --client-certificate string Path to a client certificate file for TLS --client-key string Path to a client key file for TLS --cluster string The name of the kubeconfig cluster to use --context string The name of the kubeconfig context to use --insecure-skip-tls-verify If true, the server's certificate will not be checked for validity. This will make your HTTPS connections insecure -v, --kloglevel int Log level for kubernetes client library --kubeconfig string Path to the kubeconfig file to use for CLI requests. --loglevel string Log level for kubectl argo rollouts (default \"info\") -n, --namespace string If present, the namespace scope for this CLI request --request-timeout string The length of time to wait before giving up on a single server request. Non-zero values should contain a corresponding time unit (e.g. 1s, 2m, 3h). A value of zero means don't timeout requests. (default \"0\") -s, --server string The address and port of the Kubernetes API server --tls-server-name string Server name to use for server certificate validation. If it is not provided, the hostname used to contact the server is used --token string Bearer token for authentication to the API server --user string The name of the kubeconfig user to use See Also \u00b6 rollouts retry - Retry a rollout or experiment","title":"Rollouts Retry Experiment"},{"location":"generated/kubectl-argo-rollouts/kubectl-argo-rollouts_retry_experiment/#rollouts-retry-experiment","text":"Retry an experiment","title":"Rollouts Retry Experiment"},{"location":"generated/kubectl-argo-rollouts/kubectl-argo-rollouts_retry_experiment/#synopsis","text":"Retry a failed experiment. kubectl argo rollouts retry experiment EXPERIMENT_NAME [ flags ]","title":"Synopsis"},{"location":"generated/kubectl-argo-rollouts/kubectl-argo-rollouts_retry_experiment/#examples","text":"# Retry an experiment kubectl argo rollouts retry experiment my-experiment","title":"Examples"},{"location":"generated/kubectl-argo-rollouts/kubectl-argo-rollouts_retry_experiment/#options","text":"-h, --help help for experiment","title":"Options"},{"location":"generated/kubectl-argo-rollouts/kubectl-argo-rollouts_retry_experiment/#options-inherited-from-parent-commands","text":"--as string Username to impersonate for the operation --as-group stringArray Group to impersonate for the operation, this flag can be repeated to specify multiple groups. --cache-dir string Default HTTP cache directory (default \"/home/runner/.kube/http-cache\") --certificate-authority string Path to a cert file for the certificate authority --client-certificate string Path to a client certificate file for TLS --client-key string Path to a client key file for TLS --cluster string The name of the kubeconfig cluster to use --context string The name of the kubeconfig context to use --insecure-skip-tls-verify If true, the server's certificate will not be checked for validity. This will make your HTTPS connections insecure -v, --kloglevel int Log level for kubernetes client library --kubeconfig string Path to the kubeconfig file to use for CLI requests. --loglevel string Log level for kubectl argo rollouts (default \"info\") -n, --namespace string If present, the namespace scope for this CLI request --request-timeout string The length of time to wait before giving up on a single server request. Non-zero values should contain a corresponding time unit (e.g. 1s, 2m, 3h). A value of zero means don't timeout requests. (default \"0\") -s, --server string The address and port of the Kubernetes API server --tls-server-name string Server name to use for server certificate validation. If it is not provided, the hostname used to contact the server is used --token string Bearer token for authentication to the API server --user string The name of the kubeconfig user to use","title":"Options inherited from parent commands"},{"location":"generated/kubectl-argo-rollouts/kubectl-argo-rollouts_retry_experiment/#see-also","text":"rollouts retry - Retry a rollout or experiment","title":"See Also"},{"location":"generated/kubectl-argo-rollouts/kubectl-argo-rollouts_retry_rollout/","text":"Rollouts Retry Rollout \u00b6 Retry an aborted rollout Synopsis \u00b6 Retry an aborted rollout kubectl argo rollouts retry rollout ROLLOUT_NAME [ flags ] Examples \u00b6 # Retry an aborted rollout kubectl argo rollouts retry rollout guestbook Options \u00b6 -h, --help help for rollout Options inherited from parent commands \u00b6 --as string Username to impersonate for the operation --as-group stringArray Group to impersonate for the operation, this flag can be repeated to specify multiple groups. --cache-dir string Default HTTP cache directory (default \"/home/runner/.kube/http-cache\") --certificate-authority string Path to a cert file for the certificate authority --client-certificate string Path to a client certificate file for TLS --client-key string Path to a client key file for TLS --cluster string The name of the kubeconfig cluster to use --context string The name of the kubeconfig context to use --insecure-skip-tls-verify If true, the server's certificate will not be checked for validity. This will make your HTTPS connections insecure -v, --kloglevel int Log level for kubernetes client library --kubeconfig string Path to the kubeconfig file to use for CLI requests. --loglevel string Log level for kubectl argo rollouts (default \"info\") -n, --namespace string If present, the namespace scope for this CLI request --request-timeout string The length of time to wait before giving up on a single server request. Non-zero values should contain a corresponding time unit (e.g. 1s, 2m, 3h). A value of zero means don't timeout requests. (default \"0\") -s, --server string The address and port of the Kubernetes API server --tls-server-name string Server name to use for server certificate validation. If it is not provided, the hostname used to contact the server is used --token string Bearer token for authentication to the API server --user string The name of the kubeconfig user to use See Also \u00b6 rollouts retry - Retry a rollout or experiment","title":"Rollouts Retry Rollout"},{"location":"generated/kubectl-argo-rollouts/kubectl-argo-rollouts_retry_rollout/#rollouts-retry-rollout","text":"Retry an aborted rollout","title":"Rollouts Retry Rollout"},{"location":"generated/kubectl-argo-rollouts/kubectl-argo-rollouts_retry_rollout/#synopsis","text":"Retry an aborted rollout kubectl argo rollouts retry rollout ROLLOUT_NAME [ flags ]","title":"Synopsis"},{"location":"generated/kubectl-argo-rollouts/kubectl-argo-rollouts_retry_rollout/#examples","text":"# Retry an aborted rollout kubectl argo rollouts retry rollout guestbook","title":"Examples"},{"location":"generated/kubectl-argo-rollouts/kubectl-argo-rollouts_retry_rollout/#options","text":"-h, --help help for rollout","title":"Options"},{"location":"generated/kubectl-argo-rollouts/kubectl-argo-rollouts_retry_rollout/#options-inherited-from-parent-commands","text":"--as string Username to impersonate for the operation --as-group stringArray Group to impersonate for the operation, this flag can be repeated to specify multiple groups. --cache-dir string Default HTTP cache directory (default \"/home/runner/.kube/http-cache\") --certificate-authority string Path to a cert file for the certificate authority --client-certificate string Path to a client certificate file for TLS --client-key string Path to a client key file for TLS --cluster string The name of the kubeconfig cluster to use --context string The name of the kubeconfig context to use --insecure-skip-tls-verify If true, the server's certificate will not be checked for validity. This will make your HTTPS connections insecure -v, --kloglevel int Log level for kubernetes client library --kubeconfig string Path to the kubeconfig file to use for CLI requests. --loglevel string Log level for kubectl argo rollouts (default \"info\") -n, --namespace string If present, the namespace scope for this CLI request --request-timeout string The length of time to wait before giving up on a single server request. Non-zero values should contain a corresponding time unit (e.g. 1s, 2m, 3h). A value of zero means don't timeout requests. (default \"0\") -s, --server string The address and port of the Kubernetes API server --tls-server-name string Server name to use for server certificate validation. If it is not provided, the hostname used to contact the server is used --token string Bearer token for authentication to the API server --user string The name of the kubeconfig user to use","title":"Options inherited from parent commands"},{"location":"generated/kubectl-argo-rollouts/kubectl-argo-rollouts_retry_rollout/#see-also","text":"rollouts retry - Retry a rollout or experiment","title":"See Also"},{"location":"generated/kubectl-argo-rollouts/kubectl-argo-rollouts_set/","text":"Rollouts Set \u00b6 Update various values on resources Synopsis \u00b6 This command consists of multiple subcommands which can be used to update rollout resources. kubectl argo rollouts set COMMAND [ flags ] Examples \u00b6 # Set rollout image kubectl argo rollouts set image my-rollout argoproj/rollouts-demo:yellow Options \u00b6 -h, --help help for set Options inherited from parent commands \u00b6 --as string Username to impersonate for the operation --as-group stringArray Group to impersonate for the operation, this flag can be repeated to specify multiple groups. --cache-dir string Default HTTP cache directory (default \"/home/runner/.kube/http-cache\") --certificate-authority string Path to a cert file for the certificate authority --client-certificate string Path to a client certificate file for TLS --client-key string Path to a client key file for TLS --cluster string The name of the kubeconfig cluster to use --context string The name of the kubeconfig context to use --insecure-skip-tls-verify If true, the server's certificate will not be checked for validity. This will make your HTTPS connections insecure -v, --kloglevel int Log level for kubernetes client library --kubeconfig string Path to the kubeconfig file to use for CLI requests. --loglevel string Log level for kubectl argo rollouts (default \"info\") -n, --namespace string If present, the namespace scope for this CLI request --request-timeout string The length of time to wait before giving up on a single server request. Non-zero values should contain a corresponding time unit (e.g. 1s, 2m, 3h). A value of zero means don't timeout requests. (default \"0\") -s, --server string The address and port of the Kubernetes API server --tls-server-name string Server name to use for server certificate validation. If it is not provided, the hostname used to contact the server is used --token string Bearer token for authentication to the API server --user string The name of the kubeconfig user to use Available Commands \u00b6 rollouts set image - Update the image of a rollout See Also \u00b6 rollouts - Manage argo rollouts","title":"Rollouts Set"},{"location":"generated/kubectl-argo-rollouts/kubectl-argo-rollouts_set/#rollouts-set","text":"Update various values on resources","title":"Rollouts Set"},{"location":"generated/kubectl-argo-rollouts/kubectl-argo-rollouts_set/#synopsis","text":"This command consists of multiple subcommands which can be used to update rollout resources. kubectl argo rollouts set COMMAND [ flags ]","title":"Synopsis"},{"location":"generated/kubectl-argo-rollouts/kubectl-argo-rollouts_set/#examples","text":"# Set rollout image kubectl argo rollouts set image my-rollout argoproj/rollouts-demo:yellow","title":"Examples"},{"location":"generated/kubectl-argo-rollouts/kubectl-argo-rollouts_set/#options","text":"-h, --help help for set","title":"Options"},{"location":"generated/kubectl-argo-rollouts/kubectl-argo-rollouts_set/#options-inherited-from-parent-commands","text":"--as string Username to impersonate for the operation --as-group stringArray Group to impersonate for the operation, this flag can be repeated to specify multiple groups. --cache-dir string Default HTTP cache directory (default \"/home/runner/.kube/http-cache\") --certificate-authority string Path to a cert file for the certificate authority --client-certificate string Path to a client certificate file for TLS --client-key string Path to a client key file for TLS --cluster string The name of the kubeconfig cluster to use --context string The name of the kubeconfig context to use --insecure-skip-tls-verify If true, the server's certificate will not be checked for validity. This will make your HTTPS connections insecure -v, --kloglevel int Log level for kubernetes client library --kubeconfig string Path to the kubeconfig file to use for CLI requests. --loglevel string Log level for kubectl argo rollouts (default \"info\") -n, --namespace string If present, the namespace scope for this CLI request --request-timeout string The length of time to wait before giving up on a single server request. Non-zero values should contain a corresponding time unit (e.g. 1s, 2m, 3h). A value of zero means don't timeout requests. (default \"0\") -s, --server string The address and port of the Kubernetes API server --tls-server-name string Server name to use for server certificate validation. If it is not provided, the hostname used to contact the server is used --token string Bearer token for authentication to the API server --user string The name of the kubeconfig user to use","title":"Options inherited from parent commands"},{"location":"generated/kubectl-argo-rollouts/kubectl-argo-rollouts_set/#available-commands","text":"rollouts set image - Update the image of a rollout","title":"Available Commands"},{"location":"generated/kubectl-argo-rollouts/kubectl-argo-rollouts_set/#see-also","text":"rollouts - Manage argo rollouts","title":"See Also"},{"location":"generated/kubectl-argo-rollouts/kubectl-argo-rollouts_set_image/","text":"Rollouts Set Image \u00b6 Update the image of a rollout Synopsis \u00b6 Update the image of a rollout kubectl argo rollouts set image ROLLOUT_NAME CONTAINER = IMAGE [ flags ] Examples \u00b6 # Set rollout image kubectl argo rollouts set image my-rollout www = image:v2 Options \u00b6 -h, --help help for image Options inherited from parent commands \u00b6 --as string Username to impersonate for the operation --as-group stringArray Group to impersonate for the operation, this flag can be repeated to specify multiple groups. --cache-dir string Default HTTP cache directory (default \"/home/runner/.kube/http-cache\") --certificate-authority string Path to a cert file for the certificate authority --client-certificate string Path to a client certificate file for TLS --client-key string Path to a client key file for TLS --cluster string The name of the kubeconfig cluster to use --context string The name of the kubeconfig context to use --insecure-skip-tls-verify If true, the server's certificate will not be checked for validity. This will make your HTTPS connections insecure -v, --kloglevel int Log level for kubernetes client library --kubeconfig string Path to the kubeconfig file to use for CLI requests. --loglevel string Log level for kubectl argo rollouts (default \"info\") -n, --namespace string If present, the namespace scope for this CLI request --request-timeout string The length of time to wait before giving up on a single server request. Non-zero values should contain a corresponding time unit (e.g. 1s, 2m, 3h). A value of zero means don't timeout requests. (default \"0\") -s, --server string The address and port of the Kubernetes API server --tls-server-name string Server name to use for server certificate validation. If it is not provided, the hostname used to contact the server is used --token string Bearer token for authentication to the API server --user string The name of the kubeconfig user to use See Also \u00b6 rollouts set - Update various values on resources","title":"Rollouts Set Image"},{"location":"generated/kubectl-argo-rollouts/kubectl-argo-rollouts_set_image/#rollouts-set-image","text":"Update the image of a rollout","title":"Rollouts Set Image"},{"location":"generated/kubectl-argo-rollouts/kubectl-argo-rollouts_set_image/#synopsis","text":"Update the image of a rollout kubectl argo rollouts set image ROLLOUT_NAME CONTAINER = IMAGE [ flags ]","title":"Synopsis"},{"location":"generated/kubectl-argo-rollouts/kubectl-argo-rollouts_set_image/#examples","text":"# Set rollout image kubectl argo rollouts set image my-rollout www = image:v2","title":"Examples"},{"location":"generated/kubectl-argo-rollouts/kubectl-argo-rollouts_set_image/#options","text":"-h, --help help for image","title":"Options"},{"location":"generated/kubectl-argo-rollouts/kubectl-argo-rollouts_set_image/#options-inherited-from-parent-commands","text":"--as string Username to impersonate for the operation --as-group stringArray Group to impersonate for the operation, this flag can be repeated to specify multiple groups. --cache-dir string Default HTTP cache directory (default \"/home/runner/.kube/http-cache\") --certificate-authority string Path to a cert file for the certificate authority --client-certificate string Path to a client certificate file for TLS --client-key string Path to a client key file for TLS --cluster string The name of the kubeconfig cluster to use --context string The name of the kubeconfig context to use --insecure-skip-tls-verify If true, the server's certificate will not be checked for validity. This will make your HTTPS connections insecure -v, --kloglevel int Log level for kubernetes client library --kubeconfig string Path to the kubeconfig file to use for CLI requests. --loglevel string Log level for kubectl argo rollouts (default \"info\") -n, --namespace string If present, the namespace scope for this CLI request --request-timeout string The length of time to wait before giving up on a single server request. Non-zero values should contain a corresponding time unit (e.g. 1s, 2m, 3h). A value of zero means don't timeout requests. (default \"0\") -s, --server string The address and port of the Kubernetes API server --tls-server-name string Server name to use for server certificate validation. If it is not provided, the hostname used to contact the server is used --token string Bearer token for authentication to the API server --user string The name of the kubeconfig user to use","title":"Options inherited from parent commands"},{"location":"generated/kubectl-argo-rollouts/kubectl-argo-rollouts_set_image/#see-also","text":"rollouts set - Update various values on resources","title":"See Also"},{"location":"generated/kubectl-argo-rollouts/kubectl-argo-rollouts_terminate/","text":"Rollouts Terminate \u00b6 Terminate an AnalysisRun or Experiment Synopsis \u00b6 This command consists of multiple subcommands which can be used to terminate an AnalysisRun or Experiment that is in progress. kubectl argo rollouts terminate <analysisrun | experiment> RESOURCE_NAME [ flags ] Examples \u00b6 # Terminate an analysisRun kubectl argo rollouts terminate analysisrun guestbook-877894d5b-4-success-rate.1 # Terminate a failed experiment kubectl argo rollouts terminate experiment my-experiment Options \u00b6 -h, --help help for terminate Options inherited from parent commands \u00b6 --as string Username to impersonate for the operation --as-group stringArray Group to impersonate for the operation, this flag can be repeated to specify multiple groups. --cache-dir string Default HTTP cache directory (default \"/home/runner/.kube/http-cache\") --certificate-authority string Path to a cert file for the certificate authority --client-certificate string Path to a client certificate file for TLS --client-key string Path to a client key file for TLS --cluster string The name of the kubeconfig cluster to use --context string The name of the kubeconfig context to use --insecure-skip-tls-verify If true, the server's certificate will not be checked for validity. This will make your HTTPS connections insecure -v, --kloglevel int Log level for kubernetes client library --kubeconfig string Path to the kubeconfig file to use for CLI requests. --loglevel string Log level for kubectl argo rollouts (default \"info\") -n, --namespace string If present, the namespace scope for this CLI request --request-timeout string The length of time to wait before giving up on a single server request. Non-zero values should contain a corresponding time unit (e.g. 1s, 2m, 3h). A value of zero means don't timeout requests. (default \"0\") -s, --server string The address and port of the Kubernetes API server --tls-server-name string Server name to use for server certificate validation. If it is not provided, the hostname used to contact the server is used --token string Bearer token for authentication to the API server --user string The name of the kubeconfig user to use Available Commands \u00b6 rollouts terminate analysisrun - Terminate an AnalysisRun rollouts terminate experiment - Terminate an experiment See Also \u00b6 rollouts - Manage argo rollouts","title":"Rollouts Terminate"},{"location":"generated/kubectl-argo-rollouts/kubectl-argo-rollouts_terminate/#rollouts-terminate","text":"Terminate an AnalysisRun or Experiment","title":"Rollouts Terminate"},{"location":"generated/kubectl-argo-rollouts/kubectl-argo-rollouts_terminate/#synopsis","text":"This command consists of multiple subcommands which can be used to terminate an AnalysisRun or Experiment that is in progress. kubectl argo rollouts terminate <analysisrun | experiment> RESOURCE_NAME [ flags ]","title":"Synopsis"},{"location":"generated/kubectl-argo-rollouts/kubectl-argo-rollouts_terminate/#examples","text":"# Terminate an analysisRun kubectl argo rollouts terminate analysisrun guestbook-877894d5b-4-success-rate.1 # Terminate a failed experiment kubectl argo rollouts terminate experiment my-experiment","title":"Examples"},{"location":"generated/kubectl-argo-rollouts/kubectl-argo-rollouts_terminate/#options","text":"-h, --help help for terminate","title":"Options"},{"location":"generated/kubectl-argo-rollouts/kubectl-argo-rollouts_terminate/#options-inherited-from-parent-commands","text":"--as string Username to impersonate for the operation --as-group stringArray Group to impersonate for the operation, this flag can be repeated to specify multiple groups. --cache-dir string Default HTTP cache directory (default \"/home/runner/.kube/http-cache\") --certificate-authority string Path to a cert file for the certificate authority --client-certificate string Path to a client certificate file for TLS --client-key string Path to a client key file for TLS --cluster string The name of the kubeconfig cluster to use --context string The name of the kubeconfig context to use --insecure-skip-tls-verify If true, the server's certificate will not be checked for validity. This will make your HTTPS connections insecure -v, --kloglevel int Log level for kubernetes client library --kubeconfig string Path to the kubeconfig file to use for CLI requests. --loglevel string Log level for kubectl argo rollouts (default \"info\") -n, --namespace string If present, the namespace scope for this CLI request --request-timeout string The length of time to wait before giving up on a single server request. Non-zero values should contain a corresponding time unit (e.g. 1s, 2m, 3h). A value of zero means don't timeout requests. (default \"0\") -s, --server string The address and port of the Kubernetes API server --tls-server-name string Server name to use for server certificate validation. If it is not provided, the hostname used to contact the server is used --token string Bearer token for authentication to the API server --user string The name of the kubeconfig user to use","title":"Options inherited from parent commands"},{"location":"generated/kubectl-argo-rollouts/kubectl-argo-rollouts_terminate/#available-commands","text":"rollouts terminate analysisrun - Terminate an AnalysisRun rollouts terminate experiment - Terminate an experiment","title":"Available Commands"},{"location":"generated/kubectl-argo-rollouts/kubectl-argo-rollouts_terminate/#see-also","text":"rollouts - Manage argo rollouts","title":"See Also"},{"location":"generated/kubectl-argo-rollouts/kubectl-argo-rollouts_terminate_analysisrun/","text":"Rollouts Terminate Analysisrun \u00b6 Terminate an AnalysisRun Synopsis \u00b6 This command terminates an AnalysisRun. kubectl argo rollouts terminate analysisrun ANALYSISRUN_NAME [ flags ] Examples \u00b6 # Terminate an AnalysisRun kubectl argo rollouts terminate analysis guestbook-877894d5b-4-success-rate.1 Options \u00b6 -h, --help help for analysisrun Options inherited from parent commands \u00b6 --as string Username to impersonate for the operation --as-group stringArray Group to impersonate for the operation, this flag can be repeated to specify multiple groups. --cache-dir string Default HTTP cache directory (default \"/home/runner/.kube/http-cache\") --certificate-authority string Path to a cert file for the certificate authority --client-certificate string Path to a client certificate file for TLS --client-key string Path to a client key file for TLS --cluster string The name of the kubeconfig cluster to use --context string The name of the kubeconfig context to use --insecure-skip-tls-verify If true, the server's certificate will not be checked for validity. This will make your HTTPS connections insecure -v, --kloglevel int Log level for kubernetes client library --kubeconfig string Path to the kubeconfig file to use for CLI requests. --loglevel string Log level for kubectl argo rollouts (default \"info\") -n, --namespace string If present, the namespace scope for this CLI request --request-timeout string The length of time to wait before giving up on a single server request. Non-zero values should contain a corresponding time unit (e.g. 1s, 2m, 3h). A value of zero means don't timeout requests. (default \"0\") -s, --server string The address and port of the Kubernetes API server --tls-server-name string Server name to use for server certificate validation. If it is not provided, the hostname used to contact the server is used --token string Bearer token for authentication to the API server --user string The name of the kubeconfig user to use See Also \u00b6 rollouts terminate - Terminate an AnalysisRun or Experiment","title":"Rollouts Terminate Analysisrun"},{"location":"generated/kubectl-argo-rollouts/kubectl-argo-rollouts_terminate_analysisrun/#rollouts-terminate-analysisrun","text":"Terminate an AnalysisRun","title":"Rollouts Terminate Analysisrun"},{"location":"generated/kubectl-argo-rollouts/kubectl-argo-rollouts_terminate_analysisrun/#synopsis","text":"This command terminates an AnalysisRun. kubectl argo rollouts terminate analysisrun ANALYSISRUN_NAME [ flags ]","title":"Synopsis"},{"location":"generated/kubectl-argo-rollouts/kubectl-argo-rollouts_terminate_analysisrun/#examples","text":"# Terminate an AnalysisRun kubectl argo rollouts terminate analysis guestbook-877894d5b-4-success-rate.1","title":"Examples"},{"location":"generated/kubectl-argo-rollouts/kubectl-argo-rollouts_terminate_analysisrun/#options","text":"-h, --help help for analysisrun","title":"Options"},{"location":"generated/kubectl-argo-rollouts/kubectl-argo-rollouts_terminate_analysisrun/#options-inherited-from-parent-commands","text":"--as string Username to impersonate for the operation --as-group stringArray Group to impersonate for the operation, this flag can be repeated to specify multiple groups. --cache-dir string Default HTTP cache directory (default \"/home/runner/.kube/http-cache\") --certificate-authority string Path to a cert file for the certificate authority --client-certificate string Path to a client certificate file for TLS --client-key string Path to a client key file for TLS --cluster string The name of the kubeconfig cluster to use --context string The name of the kubeconfig context to use --insecure-skip-tls-verify If true, the server's certificate will not be checked for validity. This will make your HTTPS connections insecure -v, --kloglevel int Log level for kubernetes client library --kubeconfig string Path to the kubeconfig file to use for CLI requests. --loglevel string Log level for kubectl argo rollouts (default \"info\") -n, --namespace string If present, the namespace scope for this CLI request --request-timeout string The length of time to wait before giving up on a single server request. Non-zero values should contain a corresponding time unit (e.g. 1s, 2m, 3h). A value of zero means don't timeout requests. (default \"0\") -s, --server string The address and port of the Kubernetes API server --tls-server-name string Server name to use for server certificate validation. If it is not provided, the hostname used to contact the server is used --token string Bearer token for authentication to the API server --user string The name of the kubeconfig user to use","title":"Options inherited from parent commands"},{"location":"generated/kubectl-argo-rollouts/kubectl-argo-rollouts_terminate_analysisrun/#see-also","text":"rollouts terminate - Terminate an AnalysisRun or Experiment","title":"See Also"},{"location":"generated/kubectl-argo-rollouts/kubectl-argo-rollouts_terminate_experiment/","text":"Rollouts Terminate Experiment \u00b6 Terminate an experiment Synopsis \u00b6 This command terminates an Experiment. kubectl argo rollouts terminate experiment EXPERIMENT_NAME [ flags ] Examples \u00b6 # Terminate an experiment kubectl argo rollouts terminate experiment my-experiment Options \u00b6 -h, --help help for experiment Options inherited from parent commands \u00b6 --as string Username to impersonate for the operation --as-group stringArray Group to impersonate for the operation, this flag can be repeated to specify multiple groups. --cache-dir string Default HTTP cache directory (default \"/home/runner/.kube/http-cache\") --certificate-authority string Path to a cert file for the certificate authority --client-certificate string Path to a client certificate file for TLS --client-key string Path to a client key file for TLS --cluster string The name of the kubeconfig cluster to use --context string The name of the kubeconfig context to use --insecure-skip-tls-verify If true, the server's certificate will not be checked for validity. This will make your HTTPS connections insecure -v, --kloglevel int Log level for kubernetes client library --kubeconfig string Path to the kubeconfig file to use for CLI requests. --loglevel string Log level for kubectl argo rollouts (default \"info\") -n, --namespace string If present, the namespace scope for this CLI request --request-timeout string The length of time to wait before giving up on a single server request. Non-zero values should contain a corresponding time unit (e.g. 1s, 2m, 3h). A value of zero means don't timeout requests. (default \"0\") -s, --server string The address and port of the Kubernetes API server --tls-server-name string Server name to use for server certificate validation. If it is not provided, the hostname used to contact the server is used --token string Bearer token for authentication to the API server --user string The name of the kubeconfig user to use See Also \u00b6 rollouts terminate - Terminate an AnalysisRun or Experiment","title":"Rollouts Terminate Experiment"},{"location":"generated/kubectl-argo-rollouts/kubectl-argo-rollouts_terminate_experiment/#rollouts-terminate-experiment","text":"Terminate an experiment","title":"Rollouts Terminate Experiment"},{"location":"generated/kubectl-argo-rollouts/kubectl-argo-rollouts_terminate_experiment/#synopsis","text":"This command terminates an Experiment. kubectl argo rollouts terminate experiment EXPERIMENT_NAME [ flags ]","title":"Synopsis"},{"location":"generated/kubectl-argo-rollouts/kubectl-argo-rollouts_terminate_experiment/#examples","text":"# Terminate an experiment kubectl argo rollouts terminate experiment my-experiment","title":"Examples"},{"location":"generated/kubectl-argo-rollouts/kubectl-argo-rollouts_terminate_experiment/#options","text":"-h, --help help for experiment","title":"Options"},{"location":"generated/kubectl-argo-rollouts/kubectl-argo-rollouts_terminate_experiment/#options-inherited-from-parent-commands","text":"--as string Username to impersonate for the operation --as-group stringArray Group to impersonate for the operation, this flag can be repeated to specify multiple groups. --cache-dir string Default HTTP cache directory (default \"/home/runner/.kube/http-cache\") --certificate-authority string Path to a cert file for the certificate authority --client-certificate string Path to a client certificate file for TLS --client-key string Path to a client key file for TLS --cluster string The name of the kubeconfig cluster to use --context string The name of the kubeconfig context to use --insecure-skip-tls-verify If true, the server's certificate will not be checked for validity. This will make your HTTPS connections insecure -v, --kloglevel int Log level for kubernetes client library --kubeconfig string Path to the kubeconfig file to use for CLI requests. --loglevel string Log level for kubectl argo rollouts (default \"info\") -n, --namespace string If present, the namespace scope for this CLI request --request-timeout string The length of time to wait before giving up on a single server request. Non-zero values should contain a corresponding time unit (e.g. 1s, 2m, 3h). A value of zero means don't timeout requests. (default \"0\") -s, --server string The address and port of the Kubernetes API server --tls-server-name string Server name to use for server certificate validation. If it is not provided, the hostname used to contact the server is used --token string Bearer token for authentication to the API server --user string The name of the kubeconfig user to use","title":"Options inherited from parent commands"},{"location":"generated/kubectl-argo-rollouts/kubectl-argo-rollouts_terminate_experiment/#see-also","text":"rollouts terminate - Terminate an AnalysisRun or Experiment","title":"See Also"},{"location":"generated/kubectl-argo-rollouts/kubectl-argo-rollouts_version/","text":"Rollouts Version \u00b6 Print version Synopsis \u00b6 Show the version and build information of the Argo Rollouts plugin. kubectl argo rollouts version [ flags ] Examples \u00b6 # Get full version info kubectl argo rollouts version # Get just plugin version number kubectl argo rollouts version --short Options \u00b6 -h, --help help for version --short print just the version number Options inherited from parent commands \u00b6 --as string Username to impersonate for the operation --as-group stringArray Group to impersonate for the operation, this flag can be repeated to specify multiple groups. --cache-dir string Default HTTP cache directory (default \"/home/runner/.kube/http-cache\") --certificate-authority string Path to a cert file for the certificate authority --client-certificate string Path to a client certificate file for TLS --client-key string Path to a client key file for TLS --cluster string The name of the kubeconfig cluster to use --context string The name of the kubeconfig context to use --insecure-skip-tls-verify If true, the server's certificate will not be checked for validity. This will make your HTTPS connections insecure -v, --kloglevel int Log level for kubernetes client library --kubeconfig string Path to the kubeconfig file to use for CLI requests. --loglevel string Log level for kubectl argo rollouts (default \"info\") -n, --namespace string If present, the namespace scope for this CLI request --request-timeout string The length of time to wait before giving up on a single server request. Non-zero values should contain a corresponding time unit (e.g. 1s, 2m, 3h). A value of zero means don't timeout requests. (default \"0\") -s, --server string The address and port of the Kubernetes API server --tls-server-name string Server name to use for server certificate validation. If it is not provided, the hostname used to contact the server is used --token string Bearer token for authentication to the API server --user string The name of the kubeconfig user to use See Also \u00b6 rollouts - Manage argo rollouts","title":"Rollouts Version"},{"location":"generated/kubectl-argo-rollouts/kubectl-argo-rollouts_version/#rollouts-version","text":"Print version","title":"Rollouts Version"},{"location":"generated/kubectl-argo-rollouts/kubectl-argo-rollouts_version/#synopsis","text":"Show the version and build information of the Argo Rollouts plugin. kubectl argo rollouts version [ flags ]","title":"Synopsis"},{"location":"generated/kubectl-argo-rollouts/kubectl-argo-rollouts_version/#examples","text":"# Get full version info kubectl argo rollouts version # Get just plugin version number kubectl argo rollouts version --short","title":"Examples"},{"location":"generated/kubectl-argo-rollouts/kubectl-argo-rollouts_version/#options","text":"-h, --help help for version --short print just the version number","title":"Options"},{"location":"generated/kubectl-argo-rollouts/kubectl-argo-rollouts_version/#options-inherited-from-parent-commands","text":"--as string Username to impersonate for the operation --as-group stringArray Group to impersonate for the operation, this flag can be repeated to specify multiple groups. --cache-dir string Default HTTP cache directory (default \"/home/runner/.kube/http-cache\") --certificate-authority string Path to a cert file for the certificate authority --client-certificate string Path to a client certificate file for TLS --client-key string Path to a client key file for TLS --cluster string The name of the kubeconfig cluster to use --context string The name of the kubeconfig context to use --insecure-skip-tls-verify If true, the server's certificate will not be checked for validity. This will make your HTTPS connections insecure -v, --kloglevel int Log level for kubernetes client library --kubeconfig string Path to the kubeconfig file to use for CLI requests. --loglevel string Log level for kubectl argo rollouts (default \"info\") -n, --namespace string If present, the namespace scope for this CLI request --request-timeout string The length of time to wait before giving up on a single server request. Non-zero values should contain a corresponding time unit (e.g. 1s, 2m, 3h). A value of zero means don't timeout requests. (default \"0\") -s, --server string The address and port of the Kubernetes API server --tls-server-name string Server name to use for server certificate validation. If it is not provided, the hostname used to contact the server is used --token string Bearer token for authentication to the API server --user string The name of the kubeconfig user to use","title":"Options inherited from parent commands"},{"location":"generated/kubectl-argo-rollouts/kubectl-argo-rollouts_version/#see-also","text":"rollouts - Manage argo rollouts","title":"See Also"},{"location":"getting-started/alb/","text":"Getting Started - AWS ALB Ingress Controller \u00b6 This guide covers how Argo Rollouts integrates with the AWS Application Load Balancer (ALB) for traffic shaping. This guide builds upon the concepts of the basic getting started guide . Requirements \u00b6 Kubernetes cluster with AWS ALB Ingress Controller installed Tip See the Setup ALB ingress controller on how to setup a Kubernetes cluster with AWS ALB Ingress Controller 1. Deploy the Rollout, Services, and Ingress \u00b6 When AWS ALB is used as the traffic router, the Rollout canary strategy must define the following mandatory fields: apiVersion : argoproj.io/v1alpha1 kind : Rollout metadata : name : rollouts-demo spec : strategy : canary : # Reference to a Service which the controller updates to point to the canary ReplicaSet canaryService : rollouts-demo-canary # Reference to a Service which the controller updates to point to the stable ReplicaSet stableService : rollouts-demo-stable trafficRouting : alb : # Reference to an Ingress in the same namespace of the Rollout ingress : rollouts-demo-ingress # Reference to a port of the Service servicePort : 80 ... The Ingress in trafficRouting.alb.ingress is required to have a custom action which splits between the stable and canary Services, referenced in the rollout. In this guide, those Services are named: rollouts-demo-stable and rollouts-demo-canary respectively. The weight values for these services used should be initially set to 100% stable, and 0% on the canary. During an update, these values will be modified by the controller. apiVersion : networking.k8s.io/v1beta1 kind : Ingress metadata : name : rollouts-demo-ingress annotations : kubernetes.io/ingress.class : alb alb.ingress.kubernetes.io/scheme : internet-facing alb.ingress.kubernetes.io/actions.rollouts-demo-stable : | { \"Type\":\"forward\", \"ForwardConfig\":{ \"TargetGroups\":[ { \"Weight\":0, \"ServiceName\":\"rollouts-demo-canary\", \"ServicePort\":\"80\" }, { \"Weight\":100, \"ServiceName\":\"rollouts-demo-stable\", \"ServicePort\":\"80\" } ] } } spec : rules : - http : paths : - path : /* backend : serviceName : rollouts-demo-stable servicePort : use-annotation Run the following commands to deploy: A Rollout Two Services (stable and canary) An Ingress kubectl apply -f https://raw.githubusercontent.com/argoproj/argo-rollouts/master/docs/getting-started/alb/rollout.yaml kubectl apply -f https://raw.githubusercontent.com/argoproj/argo-rollouts/master/docs/getting-started/alb/services.yaml kubectl apply -f https://raw.githubusercontent.com/argoproj/argo-rollouts/master/docs/getting-started/alb/ingress.yaml After applying the manifests you should see the following rollout, services, and ingress resources in the cluster: $ kubectl get ro NAME DESIRED CURRENT UP-TO-DATE AVAILABLE rollouts-demo 1 1 1 1 $ kubectl get svc NAME TYPE CLUSTER-IP EXTERNAL-IP PORT ( S ) AGE rollouts-demo-canary NodePort 10 .100.16.64 <none> 80 :30224/TCP 2m43s rollouts-demo-stable NodePort 10 .100.146.232 <none> 80 :31135/TCP 2m43s $ kubectl get ingress NAME HOSTS ADDRESS PORTS AGE rollouts-demo-ingress * b0548428-default-rolloutsd-6951-1972570952.ap-northeast-1.elb.amazonaws.com 80 6m36s kubectl argo rollouts get rollout rollouts-demo 2. Perform an update \u00b6 Update the rollout by changing the image, and wait for it to reach the paused state. kubectl argo rollouts set image rollouts-demo rollouts-demo = argoproj/rollouts-demo:yellow kubectl argo rollouts get rollout rollouts-demo At this point, both the canary and stable version of the Rollout are running, with 5% of the traffic directed to the canary. To understand how this works, inspect the listener rules for the ALB. When looking at the listener rules, we see that the forward action weights have been modified by the controller to reflect the current weight of the canary. The controller has added rollouts-pod-template-hash selector to the Services and attached the same label to the Pods. Therefore, you can split the traffic by simply forwarding the requests to the Services according to the weights. As the Rollout progresses through steps, the forward action weights will be adjusted to match the current setWeight of the steps.","title":"ALB"},{"location":"getting-started/alb/#getting-started-aws-alb-ingress-controller","text":"This guide covers how Argo Rollouts integrates with the AWS Application Load Balancer (ALB) for traffic shaping. This guide builds upon the concepts of the basic getting started guide .","title":"Getting Started - AWS ALB Ingress Controller"},{"location":"getting-started/alb/#requirements","text":"Kubernetes cluster with AWS ALB Ingress Controller installed Tip See the Setup ALB ingress controller on how to setup a Kubernetes cluster with AWS ALB Ingress Controller","title":"Requirements"},{"location":"getting-started/alb/#1-deploy-the-rollout-services-and-ingress","text":"When AWS ALB is used as the traffic router, the Rollout canary strategy must define the following mandatory fields: apiVersion : argoproj.io/v1alpha1 kind : Rollout metadata : name : rollouts-demo spec : strategy : canary : # Reference to a Service which the controller updates to point to the canary ReplicaSet canaryService : rollouts-demo-canary # Reference to a Service which the controller updates to point to the stable ReplicaSet stableService : rollouts-demo-stable trafficRouting : alb : # Reference to an Ingress in the same namespace of the Rollout ingress : rollouts-demo-ingress # Reference to a port of the Service servicePort : 80 ... The Ingress in trafficRouting.alb.ingress is required to have a custom action which splits between the stable and canary Services, referenced in the rollout. In this guide, those Services are named: rollouts-demo-stable and rollouts-demo-canary respectively. The weight values for these services used should be initially set to 100% stable, and 0% on the canary. During an update, these values will be modified by the controller. apiVersion : networking.k8s.io/v1beta1 kind : Ingress metadata : name : rollouts-demo-ingress annotations : kubernetes.io/ingress.class : alb alb.ingress.kubernetes.io/scheme : internet-facing alb.ingress.kubernetes.io/actions.rollouts-demo-stable : | { \"Type\":\"forward\", \"ForwardConfig\":{ \"TargetGroups\":[ { \"Weight\":0, \"ServiceName\":\"rollouts-demo-canary\", \"ServicePort\":\"80\" }, { \"Weight\":100, \"ServiceName\":\"rollouts-demo-stable\", \"ServicePort\":\"80\" } ] } } spec : rules : - http : paths : - path : /* backend : serviceName : rollouts-demo-stable servicePort : use-annotation Run the following commands to deploy: A Rollout Two Services (stable and canary) An Ingress kubectl apply -f https://raw.githubusercontent.com/argoproj/argo-rollouts/master/docs/getting-started/alb/rollout.yaml kubectl apply -f https://raw.githubusercontent.com/argoproj/argo-rollouts/master/docs/getting-started/alb/services.yaml kubectl apply -f https://raw.githubusercontent.com/argoproj/argo-rollouts/master/docs/getting-started/alb/ingress.yaml After applying the manifests you should see the following rollout, services, and ingress resources in the cluster: $ kubectl get ro NAME DESIRED CURRENT UP-TO-DATE AVAILABLE rollouts-demo 1 1 1 1 $ kubectl get svc NAME TYPE CLUSTER-IP EXTERNAL-IP PORT ( S ) AGE rollouts-demo-canary NodePort 10 .100.16.64 <none> 80 :30224/TCP 2m43s rollouts-demo-stable NodePort 10 .100.146.232 <none> 80 :31135/TCP 2m43s $ kubectl get ingress NAME HOSTS ADDRESS PORTS AGE rollouts-demo-ingress * b0548428-default-rolloutsd-6951-1972570952.ap-northeast-1.elb.amazonaws.com 80 6m36s kubectl argo rollouts get rollout rollouts-demo","title":"1. Deploy the Rollout, Services, and Ingress"},{"location":"getting-started/alb/#2-perform-an-update","text":"Update the rollout by changing the image, and wait for it to reach the paused state. kubectl argo rollouts set image rollouts-demo rollouts-demo = argoproj/rollouts-demo:yellow kubectl argo rollouts get rollout rollouts-demo At this point, both the canary and stable version of the Rollout are running, with 5% of the traffic directed to the canary. To understand how this works, inspect the listener rules for the ALB. When looking at the listener rules, we see that the forward action weights have been modified by the controller to reflect the current weight of the canary. The controller has added rollouts-pod-template-hash selector to the Services and attached the same label to the Pods. Therefore, you can split the traffic by simply forwarding the requests to the Services according to the weights. As the Rollout progresses through steps, the forward action weights will be adjusted to match the current setWeight of the steps.","title":"2. Perform an update"},{"location":"getting-started/istio/","text":"Getting Started - Istio \u00b6 This guide covers how Argo Rollouts integrates with the Istio Service Mesh for traffic shaping. This guide builds upon the concepts of the basic getting started guide . Requirements \u00b6 Kubernetes cluster with Istio installed Tip See the environment setup guide for Istio on how to setup a local minikube environment with Istio 1. Deploy the Rollout, Services, Istio VirtualService, and Istio Gateway \u00b6 When Istio is used as the traffic router, the Rollout canary strategy must define the following mandatory fields: apiVersion : argoproj.io/v1alpha1 kind : Rollout metadata : name : rollouts-demo spec : strategy : canary : # Reference to a Service which the controller updates to point to the canary ReplicaSet canaryService : rollouts-demo-canary # Reference to a Service which the controller updates to point to the stable ReplicaSet stableService : rollouts-demo-stable trafficRouting : istio : virtualService : # Reference to a VirtualService which the controller updates with canary weights name : rollouts-demo-vsvc routes : - primary # At least one route is required ... The VirtualService and route referenced in trafficRouting.istio.virtualService is required to have a HTTP route which splits between the stable and canary Services, referenced in the rollout. In this guide, those Services are named: rollouts-demo-stable and rollouts-demo-canary respectively. The weight values for these services used should be initially set to 100% stable, and 0% on the canary. During an update, these values will be modified by the controller. apiVersion : networking.istio.io/v1alpha3 kind : VirtualService metadata : name : rollouts-demo-vsvc spec : gateways : - rollouts-demo-gateway hosts : - rollouts-demo.local http : - name : primary # Should match spec.strategy.canary.trafficRouting.istio.virtualService.routes route : - destination : host : rollouts-demo-stable # Should match spec.strategy.canary.stableService weight : 100 - destination : host : rollouts-demo-canary # Should match spec.strategy.canary.canaryService weight : 0 Run the following commands to deploy: A Rollout Two Services (stable and canary) An Istio VirtualService An Istio Gateway kubectl apply -f https://raw.githubusercontent.com/argoproj/argo-rollouts/master/docs/getting-started/istio/rollout.yaml kubectl apply -f https://raw.githubusercontent.com/argoproj/argo-rollouts/master/docs/getting-started/istio/services.yaml kubectl apply -f https://raw.githubusercontent.com/argoproj/argo-rollouts/master/docs/getting-started/istio/virtualsvc.yaml kubectl apply -f https://raw.githubusercontent.com/argoproj/argo-rollouts/master/docs/getting-started/istio/gateway.yaml After applying the manifests you should see the following rollout, services, virtualservices, and gateway resources in the cluster: $ kubectl get ro NAME DESIRED CURRENT UP-TO-DATE AVAILABLE rollouts-demo 1 1 1 1 $ kubectl get svc NAME TYPE CLUSTER-IP EXTERNAL-IP PORT ( S ) AGE rollouts-demo-canary ClusterIP 10 .103.146.137 <none> 80 /TCP 37s rollouts-demo-stable ClusterIP 10 .101.158.227 <none> 80 /TCP 37s $ kubectl get virtualservice NAME GATEWAYS HOSTS AGE rollouts-demo-vsvc [ rollouts-demo-gateway ] [ rollouts-demo.local ] 54s $ kubectl get gateway NAME AGE rollouts-demo-gateway 71s kubectl argo rollouts get rollout rollouts-demo 2. Perform an update \u00b6 Update the rollout by changing the image, and wait for it to reached the paused state. kubectl argo rollouts set image rollouts-demo rollouts-demo = argoproj/rollouts-demo:yellow kubectl argo rollouts get rollout rollouts-demo At this point, both the canary and stable version of the Rollout are running, with 5% of the traffic directed to the canary. To understand how this works, inspect the VirtualService which the Rollout was referencing. When looking at the VirtualService, we see that the route destination weights have been modified by the controller to reflect the current weight of the canary. apiVersion : networking.istio.io/v1beta1 kind : VirtualService metadata : name : rollouts-demo-vsvc namespace : default spec : gateways : - rollouts-demo-gateway hosts : - rollouts-demo.local http : - name : primary route : - destination : host : rollouts-demo-stable weight : 95 - destination : host : rollouts-demo-canary weight : 5 As the Rollout progresses through steps, the HTTP route destination weights will be adjusted to match the current setWeight of the steps.","title":"Istio"},{"location":"getting-started/istio/#getting-started-istio","text":"This guide covers how Argo Rollouts integrates with the Istio Service Mesh for traffic shaping. This guide builds upon the concepts of the basic getting started guide .","title":"Getting Started - Istio"},{"location":"getting-started/istio/#requirements","text":"Kubernetes cluster with Istio installed Tip See the environment setup guide for Istio on how to setup a local minikube environment with Istio","title":"Requirements"},{"location":"getting-started/istio/#1-deploy-the-rollout-services-istio-virtualservice-and-istio-gateway","text":"When Istio is used as the traffic router, the Rollout canary strategy must define the following mandatory fields: apiVersion : argoproj.io/v1alpha1 kind : Rollout metadata : name : rollouts-demo spec : strategy : canary : # Reference to a Service which the controller updates to point to the canary ReplicaSet canaryService : rollouts-demo-canary # Reference to a Service which the controller updates to point to the stable ReplicaSet stableService : rollouts-demo-stable trafficRouting : istio : virtualService : # Reference to a VirtualService which the controller updates with canary weights name : rollouts-demo-vsvc routes : - primary # At least one route is required ... The VirtualService and route referenced in trafficRouting.istio.virtualService is required to have a HTTP route which splits between the stable and canary Services, referenced in the rollout. In this guide, those Services are named: rollouts-demo-stable and rollouts-demo-canary respectively. The weight values for these services used should be initially set to 100% stable, and 0% on the canary. During an update, these values will be modified by the controller. apiVersion : networking.istio.io/v1alpha3 kind : VirtualService metadata : name : rollouts-demo-vsvc spec : gateways : - rollouts-demo-gateway hosts : - rollouts-demo.local http : - name : primary # Should match spec.strategy.canary.trafficRouting.istio.virtualService.routes route : - destination : host : rollouts-demo-stable # Should match spec.strategy.canary.stableService weight : 100 - destination : host : rollouts-demo-canary # Should match spec.strategy.canary.canaryService weight : 0 Run the following commands to deploy: A Rollout Two Services (stable and canary) An Istio VirtualService An Istio Gateway kubectl apply -f https://raw.githubusercontent.com/argoproj/argo-rollouts/master/docs/getting-started/istio/rollout.yaml kubectl apply -f https://raw.githubusercontent.com/argoproj/argo-rollouts/master/docs/getting-started/istio/services.yaml kubectl apply -f https://raw.githubusercontent.com/argoproj/argo-rollouts/master/docs/getting-started/istio/virtualsvc.yaml kubectl apply -f https://raw.githubusercontent.com/argoproj/argo-rollouts/master/docs/getting-started/istio/gateway.yaml After applying the manifests you should see the following rollout, services, virtualservices, and gateway resources in the cluster: $ kubectl get ro NAME DESIRED CURRENT UP-TO-DATE AVAILABLE rollouts-demo 1 1 1 1 $ kubectl get svc NAME TYPE CLUSTER-IP EXTERNAL-IP PORT ( S ) AGE rollouts-demo-canary ClusterIP 10 .103.146.137 <none> 80 /TCP 37s rollouts-demo-stable ClusterIP 10 .101.158.227 <none> 80 /TCP 37s $ kubectl get virtualservice NAME GATEWAYS HOSTS AGE rollouts-demo-vsvc [ rollouts-demo-gateway ] [ rollouts-demo.local ] 54s $ kubectl get gateway NAME AGE rollouts-demo-gateway 71s kubectl argo rollouts get rollout rollouts-demo","title":"1. Deploy the Rollout, Services, Istio VirtualService, and Istio Gateway"},{"location":"getting-started/istio/#2-perform-an-update","text":"Update the rollout by changing the image, and wait for it to reached the paused state. kubectl argo rollouts set image rollouts-demo rollouts-demo = argoproj/rollouts-demo:yellow kubectl argo rollouts get rollout rollouts-demo At this point, both the canary and stable version of the Rollout are running, with 5% of the traffic directed to the canary. To understand how this works, inspect the VirtualService which the Rollout was referencing. When looking at the VirtualService, we see that the route destination weights have been modified by the controller to reflect the current weight of the canary. apiVersion : networking.istio.io/v1beta1 kind : VirtualService metadata : name : rollouts-demo-vsvc namespace : default spec : gateways : - rollouts-demo-gateway hosts : - rollouts-demo.local http : - name : primary route : - destination : host : rollouts-demo-stable weight : 95 - destination : host : rollouts-demo-canary weight : 5 As the Rollout progresses through steps, the HTTP route destination weights will be adjusted to match the current setWeight of the steps.","title":"2. Perform an update"},{"location":"getting-started/nginx/","text":"Getting Started - NGINX Ingress \u00b6 This guide covers how Argo Rollouts integrates with the NGINX Ingress Controller for traffic shaping. This guide builds upon the concepts of the basic getting started guide . Requirements \u00b6 Kubernetes cluster with NGINX ingress controller installed Tip See the environment setup guide for NGINX on how to setup a local minikube environment with nginx. 1. Deploy the Rollout, Services, and Ingress \u00b6 When NGINX Ingress is used as the traffic router, the Rollout canary strategy must define the following mandatory fields: apiVersion : argoproj.io/v1alpha1 kind : Rollout metadata : name : rollouts-demo spec : strategy : canary : # Reference to a Service which the controller will update to point to the canary ReplicaSet canaryService : rollouts-demo-canary # Reference to a Service which the controller will update to point to the stable ReplicaSet stableService : rollouts-demo-stable trafficRouting : nginx : # Reference to an Ingress which has a rule pointing to the stable service (e.g. rollouts-demo-stable) # This ingress will be cloned with a new name, in order to achieve NGINX traffic splitting. stableIngress : rollouts-demo-stable ... The Ingress referenced in canary.trafficRouting.nginx.stableIngress is required to have a host rule which has a backend targeting the Service referenced under canary.stableService . In our example, that stable Service is named: rollouts-demo-stable : apiVersion : networking.k8s.io/v1beta1 kind : Ingress metadata : name : rollouts-demo-stable annotations : kubernetes.io/ingress.class : nginx spec : rules : - host : rollouts-demo.local http : paths : - path : / backend : # Reference to a Service name, also specified in the Rollout spec.strategy.canary.stableService field serviceName : rollouts-demo-stable servicePort : 80 Run the following commands to deploy: A Rollout Two Services (stable and canary) An Ingress kubectl apply -f https://raw.githubusercontent.com/argoproj/argo-rollouts/master/docs/getting-started/nginx/rollout.yaml kubectl apply -f https://raw.githubusercontent.com/argoproj/argo-rollouts/master/docs/getting-started/nginx/services.yaml kubectl apply -f https://raw.githubusercontent.com/argoproj/argo-rollouts/master/docs/getting-started/nginx/ingress.yaml After applying the manifests you should see the following rollout, services, and ingress resources in the cluster: $ kubectl get ro NAME DESIRED CURRENT UP-TO-DATE AVAILABLE rollouts-demo 1 1 1 1 $ kubectl get svc NAME TYPE CLUSTER-IP EXTERNAL-IP PORT ( S ) AGE rollouts-demo-canary ClusterIP 10 .96.6.241 <none> 80 /TCP 33s rollouts-demo-stable ClusterIP 10 .102.229.83 <none> 80 /TCP 33s $ kubectl get ing NAME CLASS HOSTS ADDRESS PORTS AGE rollouts-demo-stable <none> rollouts-demo.local 192 .168.64.2 80 36s rollouts-demo-rollouts-demo-stable-canary <none> rollouts-demo.local 192 .168.64.2 80 35s You should also notice a second ingress created by the rollouts controller, rollouts-demo-rollouts-demo-stable-canary . This ingress is the \"canary ingress\", which is a clone of the user-managed Ingress referenced under nginx.stableIngress . It is used by nginx ingress controller to achieve canary traffic splitting. The name of the generated ingress is formulated using <ROLLOUT-NAME>-<INGRESS-NAME>-canary . More details on the second Ingress are discussed in the following section. kubectl argo rollouts get rollout rollouts-demo 2. Perform an update \u00b6 Update the rollout by changing the image, and wait for it to reached the paused state. kubectl argo rollouts set image rollouts-demo rollouts-demo = argoproj/rollouts-demo:yellow kubectl argo rollouts get rollout rollouts-demo At this point, both the canary and stable version of the Rollout are running, with 5% of the traffic directed to the canary. One thing to note, is that the rollout is able to achieve a 5% canary weight despite only running two pods. This is able to be achieved since the traffic split happens at the ingress controller (as opposed to weighted replica counts and kube-proxy in the basic guide). When inspecting the rollout controller generated Ingress copy, we see that it has the following changes over the original ingress: Two additional NGINX specific canary annotations are added to the annotations. The Ingress rules will have an rule which points the backend to the canary service. apiVersion : extensions/v1beta1 kind : Ingress metadata : name : rollouts-demo-rollouts-demo-stable-canary annotations : kubernetes.io/ingress.class : nginx nginx.ingress.kubernetes.io/canary : \"true\" nginx.ingress.kubernetes.io/canary-weight : \"5\" spec : rules : - host : rollouts-demo.local http : paths : - backend : serviceName : rollouts-demo-canary servicePort : 80 As the Rollout progresses through steps, the canary-weight annotation will be adjusted to match the current setWeight of the steps. The NGINX ingress controller examines the original Ingress, the canary Ingress, and the canary-weight annotation to determine what percentage of traffic to split between the two Ingresses.","title":"NGINX"},{"location":"getting-started/nginx/#getting-started-nginx-ingress","text":"This guide covers how Argo Rollouts integrates with the NGINX Ingress Controller for traffic shaping. This guide builds upon the concepts of the basic getting started guide .","title":"Getting Started - NGINX Ingress"},{"location":"getting-started/nginx/#requirements","text":"Kubernetes cluster with NGINX ingress controller installed Tip See the environment setup guide for NGINX on how to setup a local minikube environment with nginx.","title":"Requirements"},{"location":"getting-started/nginx/#1-deploy-the-rollout-services-and-ingress","text":"When NGINX Ingress is used as the traffic router, the Rollout canary strategy must define the following mandatory fields: apiVersion : argoproj.io/v1alpha1 kind : Rollout metadata : name : rollouts-demo spec : strategy : canary : # Reference to a Service which the controller will update to point to the canary ReplicaSet canaryService : rollouts-demo-canary # Reference to a Service which the controller will update to point to the stable ReplicaSet stableService : rollouts-demo-stable trafficRouting : nginx : # Reference to an Ingress which has a rule pointing to the stable service (e.g. rollouts-demo-stable) # This ingress will be cloned with a new name, in order to achieve NGINX traffic splitting. stableIngress : rollouts-demo-stable ... The Ingress referenced in canary.trafficRouting.nginx.stableIngress is required to have a host rule which has a backend targeting the Service referenced under canary.stableService . In our example, that stable Service is named: rollouts-demo-stable : apiVersion : networking.k8s.io/v1beta1 kind : Ingress metadata : name : rollouts-demo-stable annotations : kubernetes.io/ingress.class : nginx spec : rules : - host : rollouts-demo.local http : paths : - path : / backend : # Reference to a Service name, also specified in the Rollout spec.strategy.canary.stableService field serviceName : rollouts-demo-stable servicePort : 80 Run the following commands to deploy: A Rollout Two Services (stable and canary) An Ingress kubectl apply -f https://raw.githubusercontent.com/argoproj/argo-rollouts/master/docs/getting-started/nginx/rollout.yaml kubectl apply -f https://raw.githubusercontent.com/argoproj/argo-rollouts/master/docs/getting-started/nginx/services.yaml kubectl apply -f https://raw.githubusercontent.com/argoproj/argo-rollouts/master/docs/getting-started/nginx/ingress.yaml After applying the manifests you should see the following rollout, services, and ingress resources in the cluster: $ kubectl get ro NAME DESIRED CURRENT UP-TO-DATE AVAILABLE rollouts-demo 1 1 1 1 $ kubectl get svc NAME TYPE CLUSTER-IP EXTERNAL-IP PORT ( S ) AGE rollouts-demo-canary ClusterIP 10 .96.6.241 <none> 80 /TCP 33s rollouts-demo-stable ClusterIP 10 .102.229.83 <none> 80 /TCP 33s $ kubectl get ing NAME CLASS HOSTS ADDRESS PORTS AGE rollouts-demo-stable <none> rollouts-demo.local 192 .168.64.2 80 36s rollouts-demo-rollouts-demo-stable-canary <none> rollouts-demo.local 192 .168.64.2 80 35s You should also notice a second ingress created by the rollouts controller, rollouts-demo-rollouts-demo-stable-canary . This ingress is the \"canary ingress\", which is a clone of the user-managed Ingress referenced under nginx.stableIngress . It is used by nginx ingress controller to achieve canary traffic splitting. The name of the generated ingress is formulated using <ROLLOUT-NAME>-<INGRESS-NAME>-canary . More details on the second Ingress are discussed in the following section. kubectl argo rollouts get rollout rollouts-demo","title":"1. Deploy the Rollout, Services, and Ingress"},{"location":"getting-started/nginx/#2-perform-an-update","text":"Update the rollout by changing the image, and wait for it to reached the paused state. kubectl argo rollouts set image rollouts-demo rollouts-demo = argoproj/rollouts-demo:yellow kubectl argo rollouts get rollout rollouts-demo At this point, both the canary and stable version of the Rollout are running, with 5% of the traffic directed to the canary. One thing to note, is that the rollout is able to achieve a 5% canary weight despite only running two pods. This is able to be achieved since the traffic split happens at the ingress controller (as opposed to weighted replica counts and kube-proxy in the basic guide). When inspecting the rollout controller generated Ingress copy, we see that it has the following changes over the original ingress: Two additional NGINX specific canary annotations are added to the annotations. The Ingress rules will have an rule which points the backend to the canary service. apiVersion : extensions/v1beta1 kind : Ingress metadata : name : rollouts-demo-rollouts-demo-stable-canary annotations : kubernetes.io/ingress.class : nginx nginx.ingress.kubernetes.io/canary : \"true\" nginx.ingress.kubernetes.io/canary-weight : \"5\" spec : rules : - host : rollouts-demo.local http : paths : - backend : serviceName : rollouts-demo-canary servicePort : 80 As the Rollout progresses through steps, the canary-weight annotation will be adjusted to match the current setWeight of the steps. The NGINX ingress controller examines the original Ingress, the canary Ingress, and the canary-weight annotation to determine what percentage of traffic to split between the two Ingresses.","title":"2. Perform an update"},{"location":"getting-started/setup/","text":"Environment Set Up \u00b6 This guide shows how to set up a local environment for development, testing, learning, or demoing purposes. Helm \u00b6 Some dependencies are installable via the Helm stable repository: helm repo add stable https://kubernetes-charts.storage.googleapis.com/ helm repo update Minikube \u00b6 NGINX Ingress Controller Setup \u00b6 The following instructions describe how to configure NGINX Ingress Controller on minikube. For basic ingress support, only the \"ingress\" addon needs to be enabled: minikube addons enable ingress Optionally, Prometheus and Grafana can be installed to utilize progressive delivery functionality: # Install Prometheus kubectl create ns monitoring helm install prometheus stable/prometheus -n monitoring -f docs/getting-started/setup/values-prometheus.yaml # Patch the ingress-nginx-controller pod so that it has the required # prometheus annotations. This allows the pod to be scraped by the # prometheus server. kubectl patch deploy ingress-nginx-controller -n kube-system -p \"$(cat docs/getting-started/setup/ingress-nginx-controller-metrics-scrape.yaml)\" # Install grafana along with nginx ingress dashboards helm install grafana stable/grafana -n monitoring -f docs/getting-started/setup/values-grafana-nginx.yaml # Grafana UI can be accessed by running: minikube service grafana -n monitoring Istio Setup \u00b6 The following instructions describe how to configure Istio on minikube. # Istio on Minikube requires additional memory and CPU minikube start --memory = 8192mb --cpus = 4 # Install istio minikube addons enable istio-provisioner minikube addons enable istio # Label the default namespace to enable istio sidecar injection for the namespace kubectl label namespace default istio-injection = enabled Istio already comes with a Prometheus database ready to use. To visualize metrics about istio services, Grafana and Istio dashboards can be installed via Helm to leverage progressive delivery functionality: # Install Grafana and Istio dashboards helm install grafana stable/grafana -n istio-system -f docs/getting-started/setup/values-grafana-istio.yaml # Grafana UI can be accessed by running minikube service grafana -n istio-system In order for traffic to enter the Istio mesh, the request needs to go through an Istio ingress gateway, which is simply a normal Kubernetes Deployment and Service. One convenient way to reach the gateway using minikube, is using the minikube tunnel command which assigns Services a LoadBalancer. This command should be run in the background, usually in a separate terminal window: minikube tunnel While running minikube tunnel , the istio-ingressgateway Service will now have an external IP which can be retrieved via kubectl : $ kubectl get svc -n istio-system istio-ingressgateway NAME TYPE CLUSTER-IP EXTERNAL-IP PORT ( S ) AGE istio-ingressgateway LoadBalancer 10 .100.136.45 10 .100.136.45 15020 :31711/TCP,80:31298/TCP.... 7d22h The LoadBalancer external IP (10.100.136.45 in this example) is now reachable to access services in the Istio mesh. Istio routes requests to the correct pod based on the Host HTTP header. Follow the guide on supplying host headers to learn how to configure your client environment to supply the proper request to reach the pod. Linkerd Setup \u00b6 Linkerd can be installed using the linkerd CLI. brew install linkerd linkerd install | kubectl apply -f - Linkerd does not provide its own ingress controller, choosing instead to work alongside your ingress controller of choice. On minikube, we can use the built-in NGINX ingress addon and reconfigure it to be part of the linkerd mesh. # Install the NGINX ingress controller addon minikube addons enable ingress # Patch the nginx-ingress-controller deployment to allow injection of the linkerd proxy to the # pod, so that it will be part of the mesh. kubectl patch deploy ingress-nginx-controller -n kube-system \\ -p '{\"spec\":{\"template\":{\"metadata\":{\"annotations\":{\"linkerd.io/inject\":\"enabled\"}}}}}' Supplying Host Headers \u00b6 Most ingress controllers and service mesh implementations rely on the Host HTTP request header being supplied in the request in order to determine how to route the request to the correct pod. Determining the hostname to IP mapping \u00b6 For the Host header to be set in the request, the hostname of the service should resolve to the public IP address of the ingress or service mesh. Depending on if you are using a ingress controller or a service mesh, use one of the following techniques to determine the correct hostname to IP mapping: Ingresses \u00b6 For traffic which is reaching the cluster network via a normal Kubernetes Ingress, the hostname should map to the IP of the ingress. We can retrieve the external IP of the ingress from the Ingress object itself, using kubectl : $ kubectl get ing rollouts-demo-stable NAME CLASS HOSTS ADDRESS PORTS AGE rollouts-demo-stable <none> rollouts-demo.local 192 .168.64.2 80 80m In the example above, the hostname rollouts-demo.local should be configured to resolve to the IP 192.168.64.2 . The next section describes various ways to configure your local system to resolve the hostname to the desired IP. Istio \u00b6 In the case of Istio, traffic enters the mesh through an Ingress Gateway , which simply is a load balancer sitting at the edge of mesh. To determine the correct hostname to IP mapping, it largely depends on what was configured in the VirtualService and Gateway . If you are following the Istio getting started guide , the examples use the \"default\" istio ingress gateway, which we can obtain from kubectl: $ kubectl get svc -n istio-system istio-ingressgateway NAME TYPE CLUSTER-IP EXTERNAL-IP PORT ( S ) AGE istio-ingressgateway LoadBalancer 10 .100.136.45 10 .100.136.45 15020 :31711/TCP,80:31298/TCP.... 7d22h In the above example, the hostname rollouts-demo.local should be configured to resolve to the IP 10.100.136.45 . The next section describes various ways to configure your local system to resolve the hostname to the desired IP. Configuring local hostname resolution \u00b6 Now that you have determined the correct hostname to IP mapping, the next step involves configuring the system so that will resolve properly. There are different techniques to do this: DNS Entry \u00b6 In real, production environments, the Host header is typically achieved by adding a DNS entry for the hostname in the DNS server. However, for local development, this is typically not an easily accessible option. /etc/hosts Entry \u00b6 On local workstations, a local entry to /etc/hosts can be added to map the hostname and IP address of the ingress. For example, the following is an example of an /etc/hosts file which maps rollouts-demo.local to IP 10.100.136.45 . ## # Host Database # # localhost is used to configure the loopback interface # when the system is booting. Do not change this entry. ## 127 .0.0.1 localhost 255 .255.255.255 broadcasthost ::1 localhost 10 .100.136.45 rollouts-demo.local The advantages of using a host entry, are that it works for all clients (CLIs, browsers). On the other hand, it is harder to maintain if the IP address changes frequently. Supply Header in Curl \u00b6 Clients such as curl, have the ability to explicitly set a header (the -H flag in curl). For example: $ curl -I -H 'Host: rollouts-demo.local' http://10.100.136.45/color HTTP/1.1 200 OK content-type: text/plain ; charset = utf-8 x-content-type-options: nosniff date: Wed, 24 Jun 2020 08 :44:59 GMT content-length: 6 x-envoy-upstream-service-time: 1 server: istio-envoy Notice that the same request made without the header, fails with a 404 Not Found error. $ curl -I http://10.100.136.45/color HTTP/1.1 404 Not Found date: Wed, 24 Jun 2020 08 :46:07 GMT server: istio-envoy transfer-encoding: chunked Browser Extension \u00b6 Similar to curl's ability to explicitly set a header, browsers can also achieve this via browser extensions. One example of a browser extension which can do this, is ModHeader .","title":"Environment Setup"},{"location":"getting-started/setup/#environment-set-up","text":"This guide shows how to set up a local environment for development, testing, learning, or demoing purposes.","title":"Environment Set Up"},{"location":"getting-started/setup/#helm","text":"Some dependencies are installable via the Helm stable repository: helm repo add stable https://kubernetes-charts.storage.googleapis.com/ helm repo update","title":"Helm"},{"location":"getting-started/setup/#minikube","text":"","title":"Minikube"},{"location":"getting-started/setup/#nginx-ingress-controller-setup","text":"The following instructions describe how to configure NGINX Ingress Controller on minikube. For basic ingress support, only the \"ingress\" addon needs to be enabled: minikube addons enable ingress Optionally, Prometheus and Grafana can be installed to utilize progressive delivery functionality: # Install Prometheus kubectl create ns monitoring helm install prometheus stable/prometheus -n monitoring -f docs/getting-started/setup/values-prometheus.yaml # Patch the ingress-nginx-controller pod so that it has the required # prometheus annotations. This allows the pod to be scraped by the # prometheus server. kubectl patch deploy ingress-nginx-controller -n kube-system -p \"$(cat docs/getting-started/setup/ingress-nginx-controller-metrics-scrape.yaml)\" # Install grafana along with nginx ingress dashboards helm install grafana stable/grafana -n monitoring -f docs/getting-started/setup/values-grafana-nginx.yaml # Grafana UI can be accessed by running: minikube service grafana -n monitoring","title":"NGINX Ingress Controller Setup"},{"location":"getting-started/setup/#istio-setup","text":"The following instructions describe how to configure Istio on minikube. # Istio on Minikube requires additional memory and CPU minikube start --memory = 8192mb --cpus = 4 # Install istio minikube addons enable istio-provisioner minikube addons enable istio # Label the default namespace to enable istio sidecar injection for the namespace kubectl label namespace default istio-injection = enabled Istio already comes with a Prometheus database ready to use. To visualize metrics about istio services, Grafana and Istio dashboards can be installed via Helm to leverage progressive delivery functionality: # Install Grafana and Istio dashboards helm install grafana stable/grafana -n istio-system -f docs/getting-started/setup/values-grafana-istio.yaml # Grafana UI can be accessed by running minikube service grafana -n istio-system In order for traffic to enter the Istio mesh, the request needs to go through an Istio ingress gateway, which is simply a normal Kubernetes Deployment and Service. One convenient way to reach the gateway using minikube, is using the minikube tunnel command which assigns Services a LoadBalancer. This command should be run in the background, usually in a separate terminal window: minikube tunnel While running minikube tunnel , the istio-ingressgateway Service will now have an external IP which can be retrieved via kubectl : $ kubectl get svc -n istio-system istio-ingressgateway NAME TYPE CLUSTER-IP EXTERNAL-IP PORT ( S ) AGE istio-ingressgateway LoadBalancer 10 .100.136.45 10 .100.136.45 15020 :31711/TCP,80:31298/TCP.... 7d22h The LoadBalancer external IP (10.100.136.45 in this example) is now reachable to access services in the Istio mesh. Istio routes requests to the correct pod based on the Host HTTP header. Follow the guide on supplying host headers to learn how to configure your client environment to supply the proper request to reach the pod.","title":"Istio Setup"},{"location":"getting-started/setup/#linkerd-setup","text":"Linkerd can be installed using the linkerd CLI. brew install linkerd linkerd install | kubectl apply -f - Linkerd does not provide its own ingress controller, choosing instead to work alongside your ingress controller of choice. On minikube, we can use the built-in NGINX ingress addon and reconfigure it to be part of the linkerd mesh. # Install the NGINX ingress controller addon minikube addons enable ingress # Patch the nginx-ingress-controller deployment to allow injection of the linkerd proxy to the # pod, so that it will be part of the mesh. kubectl patch deploy ingress-nginx-controller -n kube-system \\ -p '{\"spec\":{\"template\":{\"metadata\":{\"annotations\":{\"linkerd.io/inject\":\"enabled\"}}}}}'","title":"Linkerd Setup"},{"location":"getting-started/setup/#supplying-host-headers","text":"Most ingress controllers and service mesh implementations rely on the Host HTTP request header being supplied in the request in order to determine how to route the request to the correct pod.","title":"Supplying Host Headers"},{"location":"getting-started/setup/#determining-the-hostname-to-ip-mapping","text":"For the Host header to be set in the request, the hostname of the service should resolve to the public IP address of the ingress or service mesh. Depending on if you are using a ingress controller or a service mesh, use one of the following techniques to determine the correct hostname to IP mapping:","title":"Determining the hostname to IP mapping"},{"location":"getting-started/setup/#ingresses","text":"For traffic which is reaching the cluster network via a normal Kubernetes Ingress, the hostname should map to the IP of the ingress. We can retrieve the external IP of the ingress from the Ingress object itself, using kubectl : $ kubectl get ing rollouts-demo-stable NAME CLASS HOSTS ADDRESS PORTS AGE rollouts-demo-stable <none> rollouts-demo.local 192 .168.64.2 80 80m In the example above, the hostname rollouts-demo.local should be configured to resolve to the IP 192.168.64.2 . The next section describes various ways to configure your local system to resolve the hostname to the desired IP.","title":"Ingresses"},{"location":"getting-started/setup/#istio","text":"In the case of Istio, traffic enters the mesh through an Ingress Gateway , which simply is a load balancer sitting at the edge of mesh. To determine the correct hostname to IP mapping, it largely depends on what was configured in the VirtualService and Gateway . If you are following the Istio getting started guide , the examples use the \"default\" istio ingress gateway, which we can obtain from kubectl: $ kubectl get svc -n istio-system istio-ingressgateway NAME TYPE CLUSTER-IP EXTERNAL-IP PORT ( S ) AGE istio-ingressgateway LoadBalancer 10 .100.136.45 10 .100.136.45 15020 :31711/TCP,80:31298/TCP.... 7d22h In the above example, the hostname rollouts-demo.local should be configured to resolve to the IP 10.100.136.45 . The next section describes various ways to configure your local system to resolve the hostname to the desired IP.","title":"Istio"},{"location":"getting-started/setup/#configuring-local-hostname-resolution","text":"Now that you have determined the correct hostname to IP mapping, the next step involves configuring the system so that will resolve properly. There are different techniques to do this:","title":"Configuring local hostname resolution"},{"location":"getting-started/setup/#dns-entry","text":"In real, production environments, the Host header is typically achieved by adding a DNS entry for the hostname in the DNS server. However, for local development, this is typically not an easily accessible option.","title":"DNS Entry"},{"location":"getting-started/setup/#etchosts-entry","text":"On local workstations, a local entry to /etc/hosts can be added to map the hostname and IP address of the ingress. For example, the following is an example of an /etc/hosts file which maps rollouts-demo.local to IP 10.100.136.45 . ## # Host Database # # localhost is used to configure the loopback interface # when the system is booting. Do not change this entry. ## 127 .0.0.1 localhost 255 .255.255.255 broadcasthost ::1 localhost 10 .100.136.45 rollouts-demo.local The advantages of using a host entry, are that it works for all clients (CLIs, browsers). On the other hand, it is harder to maintain if the IP address changes frequently.","title":"/etc/hosts Entry"},{"location":"getting-started/setup/#supply-header-in-curl","text":"Clients such as curl, have the ability to explicitly set a header (the -H flag in curl). For example: $ curl -I -H 'Host: rollouts-demo.local' http://10.100.136.45/color HTTP/1.1 200 OK content-type: text/plain ; charset = utf-8 x-content-type-options: nosniff date: Wed, 24 Jun 2020 08 :44:59 GMT content-length: 6 x-envoy-upstream-service-time: 1 server: istio-envoy Notice that the same request made without the header, fails with a 404 Not Found error. $ curl -I http://10.100.136.45/color HTTP/1.1 404 Not Found date: Wed, 24 Jun 2020 08 :46:07 GMT server: istio-envoy transfer-encoding: chunked","title":"Supply Header in Curl"},{"location":"getting-started/setup/#browser-extension","text":"Similar to curl's ability to explicitly set a header, browsers can also achieve this via browser extensions. One example of a browser extension which can do this, is ModHeader .","title":"Browser Extension"},{"location":"getting-started/smi/","text":"Getting Started - SMI (Service Mesh Interface) \u00b6 Important Available since v0.9 This guide covers how Argo Rollouts integrates with the Service Mesh Interface (SMI), using Linkerd and NGINX Ingress Controller for traffic shaping. Since the SMI TrafficSplit resource is supported by multiple service mesh providers, the concepts taught here are applicable to other service mesh providers that support the interface. See the SMI Ecosystem for other projects that support SMI. This guide builds upon the concepts of the basic getting started guide . Requirements \u00b6 Kubernetes cluster with Linkerd installed Kubernetes cluster with NGINX ingress controller installed and part of the mesh Tip See the environment setup guide for linkerd on how to setup a local minikube environment with linkerd and nginx. 1. Deploy the Rollout, Services, and Ingress \u00b6 When SMI is used as the traffic router, the Rollout canary strategy must define the following mandatory fields: apiVersion : argoproj.io/v1alpha1 kind : Rollout metadata : name : rollouts-demo spec : strategy : canary : # Reference to a Service which the controller will update to point to the canary ReplicaSet canaryService : rollouts-demo-canary # Reference to a Service which the controller will update to point to the stable ReplicaSet stableService : rollouts-demo-stable trafficRouting : smi : {} Run the following commands to deploy: A Rollout with the Linkerd linkerd.io/inject: enabled annotation Two Services (stable and canary) An Ingress kubectl apply -f https://raw.githubusercontent.com/argoproj/argo-rollouts/master/docs/getting-started/smi/rollout.yaml kubectl apply -f https://raw.githubusercontent.com/argoproj/argo-rollouts/master/docs/getting-started/smi/services.yaml kubectl apply -f https://raw.githubusercontent.com/argoproj/argo-rollouts/master/docs/getting-started/smi/ingress.yaml After applying the manifests you should see the following rollout, services, and ingress resources in the cluster: $ kubectl get ro NAME DESIRED CURRENT UP-TO-DATE AVAILABLE rollouts-demo 1 2 1 2 $ kubectl get svc NAME TYPE CLUSTER-IP EXTERNAL-IP PORT ( S ) AGE rollouts-demo-canary ClusterIP 10 .111.69.188 <none> 80 /TCP 23m rollouts-demo-stable ClusterIP 10 .109.175.248 <none> 80 /TCP 23m $ kubectl get ing NAME CLASS HOSTS ADDRESS PORTS AGE rollouts-demo-stable <none> rollouts-demo.local 192 .168.64.2 80 23m You should also see a TrafficSplit resource which is created automatically and owned by the rollout: $ kubectl get trafficsplit NAME SERVICE rollouts-demo rollouts-demo-stable When inspecting the generated TrafficSplit resource, the weights are automatically configured to send 100% traffic to the rollouts-demo-stable service, and 0% traffic to the rollouts-demo-canary . These values will be updated during an update. apiVersion : split.smi-spec.io/v1alpha1 kind : TrafficSplit metadata : name : rollouts-demo namespace : default spec : backends : - service : rollouts-demo-canary weight : \"0\" - service : rollouts-demo-stable weight : \"100\" service : rollouts-demo-stable 2. Perform an update \u00b6 Now perform an update the rollout by changing the image, and wait for it to reached the paused state. kubectl argo rollouts set image rollouts-demo rollouts-demo = argoproj/rollouts-demo:yellow kubectl argo rollouts get rollout rollouts-demo At this point, both the canary and stable version of the Rollout are running, with 5% of the traffic directed to the canary. When inspecting the TrafficSplit generated by the controller, we see that the weight has been updated to reflect the current setWeight: 5 step of the canary deploy. apiVersion : split.smi-spec.io/v1alpha1 kind : TrafficSplit metadata : name : rollouts-demo namespace : default spec : backends : - service : rollouts-demo-canary weight : \"5\" - service : rollouts-demo-stable weight : \"95\" service : rollouts-demo-stable As the Rollout progresses through steps, the weights in the TrafficSplit resource will be adjusted to match the current setWeight of the steps.","title":"SMI"},{"location":"getting-started/smi/#getting-started-smi-service-mesh-interface","text":"Important Available since v0.9 This guide covers how Argo Rollouts integrates with the Service Mesh Interface (SMI), using Linkerd and NGINX Ingress Controller for traffic shaping. Since the SMI TrafficSplit resource is supported by multiple service mesh providers, the concepts taught here are applicable to other service mesh providers that support the interface. See the SMI Ecosystem for other projects that support SMI. This guide builds upon the concepts of the basic getting started guide .","title":"Getting Started - SMI (Service Mesh Interface)"},{"location":"getting-started/smi/#requirements","text":"Kubernetes cluster with Linkerd installed Kubernetes cluster with NGINX ingress controller installed and part of the mesh Tip See the environment setup guide for linkerd on how to setup a local minikube environment with linkerd and nginx.","title":"Requirements"},{"location":"getting-started/smi/#1-deploy-the-rollout-services-and-ingress","text":"When SMI is used as the traffic router, the Rollout canary strategy must define the following mandatory fields: apiVersion : argoproj.io/v1alpha1 kind : Rollout metadata : name : rollouts-demo spec : strategy : canary : # Reference to a Service which the controller will update to point to the canary ReplicaSet canaryService : rollouts-demo-canary # Reference to a Service which the controller will update to point to the stable ReplicaSet stableService : rollouts-demo-stable trafficRouting : smi : {} Run the following commands to deploy: A Rollout with the Linkerd linkerd.io/inject: enabled annotation Two Services (stable and canary) An Ingress kubectl apply -f https://raw.githubusercontent.com/argoproj/argo-rollouts/master/docs/getting-started/smi/rollout.yaml kubectl apply -f https://raw.githubusercontent.com/argoproj/argo-rollouts/master/docs/getting-started/smi/services.yaml kubectl apply -f https://raw.githubusercontent.com/argoproj/argo-rollouts/master/docs/getting-started/smi/ingress.yaml After applying the manifests you should see the following rollout, services, and ingress resources in the cluster: $ kubectl get ro NAME DESIRED CURRENT UP-TO-DATE AVAILABLE rollouts-demo 1 2 1 2 $ kubectl get svc NAME TYPE CLUSTER-IP EXTERNAL-IP PORT ( S ) AGE rollouts-demo-canary ClusterIP 10 .111.69.188 <none> 80 /TCP 23m rollouts-demo-stable ClusterIP 10 .109.175.248 <none> 80 /TCP 23m $ kubectl get ing NAME CLASS HOSTS ADDRESS PORTS AGE rollouts-demo-stable <none> rollouts-demo.local 192 .168.64.2 80 23m You should also see a TrafficSplit resource which is created automatically and owned by the rollout: $ kubectl get trafficsplit NAME SERVICE rollouts-demo rollouts-demo-stable When inspecting the generated TrafficSplit resource, the weights are automatically configured to send 100% traffic to the rollouts-demo-stable service, and 0% traffic to the rollouts-demo-canary . These values will be updated during an update. apiVersion : split.smi-spec.io/v1alpha1 kind : TrafficSplit metadata : name : rollouts-demo namespace : default spec : backends : - service : rollouts-demo-canary weight : \"0\" - service : rollouts-demo-stable weight : \"100\" service : rollouts-demo-stable","title":"1. Deploy the Rollout, Services, and Ingress"},{"location":"getting-started/smi/#2-perform-an-update","text":"Now perform an update the rollout by changing the image, and wait for it to reached the paused state. kubectl argo rollouts set image rollouts-demo rollouts-demo = argoproj/rollouts-demo:yellow kubectl argo rollouts get rollout rollouts-demo At this point, both the canary and stable version of the Rollout are running, with 5% of the traffic directed to the canary. When inspecting the TrafficSplit generated by the controller, we see that the weight has been updated to reflect the current setWeight: 5 step of the canary deploy. apiVersion : split.smi-spec.io/v1alpha1 kind : TrafficSplit metadata : name : rollouts-demo namespace : default spec : backends : - service : rollouts-demo-canary weight : \"5\" - service : rollouts-demo-stable weight : \"95\" service : rollouts-demo-stable As the Rollout progresses through steps, the weights in the TrafficSplit resource will be adjusted to match the current setWeight of the steps.","title":"2. Perform an update"}]}